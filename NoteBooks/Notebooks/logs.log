2024-03-02 16:59:22,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 16:59:22,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 16:59:22,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 16:59:22,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 16:59:24,961:INFO:PyCaret ClassificationExperiment
2024-03-02 16:59:24,961:INFO:Logging name: clf-default-name
2024-03-02 16:59:24,961:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 16:59:24,961:INFO:version 3.3.0
2024-03-02 16:59:24,961:INFO:Initializing setup()
2024-03-02 16:59:24,961:INFO:self.USI: 0a50
2024-03-02 16:59:24,961:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'idx', 'X_train', 'USI', 'pipeline', 'X', 'logging_param', '_ml_usecase', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', 'y_test', 'gpu_param', 'log_plots_param', 'y_train', 'html_param', 'seed', 'n_jobs_param', 'is_multiclass', 'data', 'exp_name_log', 'exp_id', 'X_test', 'fold_shuffle_param', 'y', 'target_param', 'fold_generator'}
2024-03-02 16:59:24,961:INFO:Checking environment
2024-03-02 16:59:24,961:INFO:python_version: 3.11.5
2024-03-02 16:59:24,961:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 16:59:24,961:INFO:machine: AMD64
2024-03-02 16:59:24,961:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 16:59:24,961:INFO:Memory: svmem(total=8327905280, available=1849085952, percent=77.8, used=6478819328, free=1849085952)
2024-03-02 16:59:24,961:INFO:Physical Core: 4
2024-03-02 16:59:24,961:INFO:Logical Core: 8
2024-03-02 16:59:24,961:INFO:Checking libraries
2024-03-02 16:59:24,961:INFO:System:
2024-03-02 16:59:24,961:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 16:59:24,961:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 16:59:24,961:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 16:59:24,961:INFO:PyCaret required dependencies:
2024-03-02 16:59:26,517:INFO:                 pip: 23.2.1
2024-03-02 16:59:26,517:INFO:          setuptools: 68.0.0
2024-03-02 16:59:26,517:INFO:             pycaret: 3.3.0
2024-03-02 16:59:26,517:INFO:             IPython: 8.15.0
2024-03-02 16:59:26,517:INFO:          ipywidgets: 8.0.4
2024-03-02 16:59:26,517:INFO:                tqdm: 4.65.0
2024-03-02 16:59:26,517:INFO:               numpy: 1.24.3
2024-03-02 16:59:26,517:INFO:              pandas: 2.0.3
2024-03-02 16:59:26,517:INFO:              jinja2: 3.1.2
2024-03-02 16:59:26,517:INFO:               scipy: 1.11.1
2024-03-02 16:59:26,517:INFO:              joblib: 1.2.0
2024-03-02 16:59:26,517:INFO:             sklearn: 1.4.1.post1
2024-03-02 16:59:26,517:INFO:                pyod: 1.1.3
2024-03-02 16:59:26,517:INFO:            imblearn: 0.12.0
2024-03-02 16:59:26,517:INFO:   category_encoders: 2.6.3
2024-03-02 16:59:26,517:INFO:            lightgbm: 4.3.0
2024-03-02 16:59:26,517:INFO:               numba: 0.57.1
2024-03-02 16:59:26,517:INFO:            requests: 2.31.0
2024-03-02 16:59:26,517:INFO:          matplotlib: 3.7.2
2024-03-02 16:59:26,517:INFO:          scikitplot: 0.3.7
2024-03-02 16:59:26,517:INFO:         yellowbrick: 1.5
2024-03-02 16:59:26,517:INFO:              plotly: 5.19.0
2024-03-02 16:59:26,517:INFO:    plotly-resampler: Not installed
2024-03-02 16:59:26,517:INFO:             kaleido: 0.2.1
2024-03-02 16:59:26,517:INFO:           schemdraw: 0.15
2024-03-02 16:59:26,517:INFO:         statsmodels: 0.14.0
2024-03-02 16:59:26,517:INFO:              sktime: 0.26.1
2024-03-02 16:59:26,517:INFO:               tbats: 1.1.3
2024-03-02 16:59:26,525:INFO:            pmdarima: 2.0.4
2024-03-02 16:59:26,525:INFO:              psutil: 5.9.0
2024-03-02 16:59:26,525:INFO:          markupsafe: 2.1.1
2024-03-02 16:59:26,525:INFO:             pickle5: Not installed
2024-03-02 16:59:26,525:INFO:         cloudpickle: 2.2.1
2024-03-02 16:59:26,525:INFO:         deprecation: 2.1.0
2024-03-02 16:59:26,525:INFO:              xxhash: 2.0.2
2024-03-02 16:59:26,525:INFO:           wurlitzer: Not installed
2024-03-02 16:59:26,525:INFO:PyCaret optional dependencies:
2024-03-02 16:59:26,631:INFO:                shap: 0.44.1
2024-03-02 16:59:26,631:INFO:           interpret: Not installed
2024-03-02 16:59:26,631:INFO:                umap: Not installed
2024-03-02 16:59:26,631:INFO:     ydata_profiling: Not installed
2024-03-02 16:59:26,631:INFO:  explainerdashboard: Not installed
2024-03-02 16:59:26,631:INFO:             autoviz: Not installed
2024-03-02 16:59:26,631:INFO:           fairlearn: Not installed
2024-03-02 16:59:26,631:INFO:          deepchecks: Not installed
2024-03-02 16:59:26,631:INFO:             xgboost: 2.0.3
2024-03-02 16:59:26,631:INFO:            catboost: 1.2.2
2024-03-02 16:59:26,631:INFO:              kmodes: Not installed
2024-03-02 16:59:26,631:INFO:             mlxtend: Not installed
2024-03-02 16:59:26,631:INFO:       statsforecast: Not installed
2024-03-02 16:59:26,631:INFO:        tune_sklearn: Not installed
2024-03-02 16:59:26,631:INFO:                 ray: Not installed
2024-03-02 16:59:26,631:INFO:            hyperopt: Not installed
2024-03-02 16:59:26,631:INFO:              optuna: 3.5.0
2024-03-02 16:59:26,631:INFO:               skopt: Not installed
2024-03-02 16:59:26,631:INFO:              mlflow: Not installed
2024-03-02 16:59:26,631:INFO:              gradio: Not installed
2024-03-02 16:59:26,631:INFO:             fastapi: Not installed
2024-03-02 16:59:26,631:INFO:             uvicorn: Not installed
2024-03-02 16:59:26,631:INFO:              m2cgen: Not installed
2024-03-02 16:59:26,631:INFO:           evidently: Not installed
2024-03-02 16:59:26,631:INFO:               fugue: Not installed
2024-03-02 16:59:26,631:INFO:           streamlit: Not installed
2024-03-02 16:59:26,631:INFO:             prophet: Not installed
2024-03-02 16:59:26,631:INFO:None
2024-03-02 16:59:26,631:INFO:Set up data.
2024-03-02 16:59:26,645:INFO:Set up folding strategy.
2024-03-02 16:59:26,645:INFO:Set up train/test split.
2024-03-02 16:59:26,678:INFO:Set up index.
2024-03-02 16:59:26,678:INFO:Assigning column types.
2024-03-02 16:59:26,695:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 16:59:26,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 16:59:26,745:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 16:59:26,778:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:26,778:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:26,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 16:59:26,962:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 16:59:26,995:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:26,995:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:26,995:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 16:59:27,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 16:59:27,078:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,078:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 16:59:27,162:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,177:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,177:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 16:59:27,244:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,244:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,328:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,328:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,328:INFO:Preparing preprocessing pipeline...
2024-03-02 16:59:27,344:INFO:Set up simple imputation.
2024-03-02 16:59:27,411:INFO:Finished creating preprocessing pipeline.
2024-03-02 16:59:27,411:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-03-02 16:59:27,411:INFO:Creating final display dataframe.
2024-03-02 16:59:27,599:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 29)
4        Transformed data shape       (18380, 29)
5   Transformed train set shape       (12866, 29)
6    Transformed test set shape        (5514, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0a50
2024-03-02 16:59:27,733:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,733:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,816:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 16:59:27,816:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 16:59:27,832:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 16:59:27,832:INFO:setup() successfully completed in 3.05s...............
2024-03-02 17:00:03,946:INFO:Initializing compare_models()
2024-03-02 17:00:03,946:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 17:00:03,949:INFO:Checking exceptions
2024-03-02 17:00:03,964:INFO:Preparing display monitor
2024-03-02 17:00:03,989:INFO:Initializing Logistic Regression
2024-03-02 17:00:03,989:INFO:Total runtime is 0.0 minutes
2024-03-02 17:00:03,997:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:03,997:INFO:Initializing create_model()
2024-03-02 17:00:03,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:03,997:INFO:Checking exceptions
2024-03-02 17:00:03,997:INFO:Importing libraries
2024-03-02 17:00:03,997:INFO:Copying training dataset
2024-03-02 17:00:04,030:INFO:Defining folds
2024-03-02 17:00:04,030:INFO:Declaring metric variables
2024-03-02 17:00:04,030:INFO:Importing untrained model
2024-03-02 17:00:04,039:INFO:Logistic Regression Imported successfully
2024-03-02 17:00:04,047:INFO:Starting cross validation
2024-03-02 17:00:04,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:23,971:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,060:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,073:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,121:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,138:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,138:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,212:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,221:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,238:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,255:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,321:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,353:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,371:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,403:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:24,455:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:24,488:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:28,670:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:28,687:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:00:28,687:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:28,720:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:28,720:INFO:Calculating mean and std
2024-03-02 17:00:28,720:INFO:Creating metrics dataframe
2024-03-02 17:00:28,739:INFO:Uploading results into container
2024-03-02 17:00:28,739:INFO:Uploading model into container now
2024-03-02 17:00:28,739:INFO:_master_model_container: 1
2024-03-02 17:00:28,739:INFO:_display_container: 2
2024-03-02 17:00:28,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-02 17:00:28,739:INFO:create_model() successfully completed......................................
2024-03-02 17:00:28,920:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:28,920:INFO:Creating metrics dataframe
2024-03-02 17:00:28,927:INFO:Initializing K Neighbors Classifier
2024-03-02 17:00:28,927:INFO:Total runtime is 0.41562710603078207 minutes
2024-03-02 17:00:28,927:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:28,927:INFO:Initializing create_model()
2024-03-02 17:00:28,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:28,927:INFO:Checking exceptions
2024-03-02 17:00:28,927:INFO:Importing libraries
2024-03-02 17:00:28,927:INFO:Copying training dataset
2024-03-02 17:00:28,956:INFO:Defining folds
2024-03-02 17:00:28,956:INFO:Declaring metric variables
2024-03-02 17:00:28,956:INFO:Importing untrained model
2024-03-02 17:00:28,956:INFO:K Neighbors Classifier Imported successfully
2024-03-02 17:00:28,969:INFO:Starting cross validation
2024-03-02 17:00:28,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:31,223:INFO:Calculating mean and std
2024-03-02 17:00:31,236:INFO:Creating metrics dataframe
2024-03-02 17:00:31,239:INFO:Uploading results into container
2024-03-02 17:00:31,239:INFO:Uploading model into container now
2024-03-02 17:00:31,239:INFO:_master_model_container: 2
2024-03-02 17:00:31,239:INFO:_display_container: 2
2024-03-02 17:00:31,239:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-02 17:00:31,239:INFO:create_model() successfully completed......................................
2024-03-02 17:00:31,486:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:31,486:INFO:Creating metrics dataframe
2024-03-02 17:00:31,507:INFO:Initializing Naive Bayes
2024-03-02 17:00:31,507:INFO:Total runtime is 0.4586379369099935 minutes
2024-03-02 17:00:31,507:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:31,507:INFO:Initializing create_model()
2024-03-02 17:00:31,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:31,507:INFO:Checking exceptions
2024-03-02 17:00:31,507:INFO:Importing libraries
2024-03-02 17:00:31,507:INFO:Copying training dataset
2024-03-02 17:00:31,540:INFO:Defining folds
2024-03-02 17:00:31,540:INFO:Declaring metric variables
2024-03-02 17:00:31,552:INFO:Importing untrained model
2024-03-02 17:00:31,560:INFO:Naive Bayes Imported successfully
2024-03-02 17:00:31,575:INFO:Starting cross validation
2024-03-02 17:00:31,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:31,825:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:31,825:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:31,856:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:31,902:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:31,973:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:31,991:INFO:Calculating mean and std
2024-03-02 17:00:31,991:INFO:Creating metrics dataframe
2024-03-02 17:00:31,991:INFO:Uploading results into container
2024-03-02 17:00:32,003:INFO:Uploading model into container now
2024-03-02 17:00:32,003:INFO:_master_model_container: 3
2024-03-02 17:00:32,003:INFO:_display_container: 2
2024-03-02 17:00:32,003:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-02 17:00:32,003:INFO:create_model() successfully completed......................................
2024-03-02 17:00:32,219:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:32,219:INFO:Creating metrics dataframe
2024-03-02 17:00:32,236:INFO:Initializing Decision Tree Classifier
2024-03-02 17:00:32,236:INFO:Total runtime is 0.47077945470809934 minutes
2024-03-02 17:00:32,236:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:32,236:INFO:Initializing create_model()
2024-03-02 17:00:32,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:32,244:INFO:Checking exceptions
2024-03-02 17:00:32,244:INFO:Importing libraries
2024-03-02 17:00:32,244:INFO:Copying training dataset
2024-03-02 17:00:32,269:INFO:Defining folds
2024-03-02 17:00:32,269:INFO:Declaring metric variables
2024-03-02 17:00:32,277:INFO:Importing untrained model
2024-03-02 17:00:32,277:INFO:Decision Tree Classifier Imported successfully
2024-03-02 17:00:32,293:INFO:Starting cross validation
2024-03-02 17:00:32,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:34,257:INFO:Calculating mean and std
2024-03-02 17:00:34,257:INFO:Creating metrics dataframe
2024-03-02 17:00:34,257:INFO:Uploading results into container
2024-03-02 17:00:34,257:INFO:Uploading model into container now
2024-03-02 17:00:34,257:INFO:_master_model_container: 4
2024-03-02 17:00:34,257:INFO:_display_container: 2
2024-03-02 17:00:34,257:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-03-02 17:00:34,273:INFO:create_model() successfully completed......................................
2024-03-02 17:00:34,461:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:34,461:INFO:Creating metrics dataframe
2024-03-02 17:00:34,473:INFO:Initializing SVM - Linear Kernel
2024-03-02 17:00:34,473:INFO:Total runtime is 0.508065398534139 minutes
2024-03-02 17:00:34,473:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:34,473:INFO:Initializing create_model()
2024-03-02 17:00:34,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:34,473:INFO:Checking exceptions
2024-03-02 17:00:34,473:INFO:Importing libraries
2024-03-02 17:00:34,473:INFO:Copying training dataset
2024-03-02 17:00:34,507:INFO:Defining folds
2024-03-02 17:00:34,507:INFO:Declaring metric variables
2024-03-02 17:00:34,507:INFO:Importing untrained model
2024-03-02 17:00:34,519:INFO:SVM - Linear Kernel Imported successfully
2024-03-02 17:00:34,527:INFO:Starting cross validation
2024-03-02 17:00:34,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:35,337:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:35,369:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:35,369:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:35,384:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:35,469:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:35,615:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:36,406:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:36,437:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:36,453:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:36,469:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:36,722:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:36,722:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:36,800:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:36,853:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:36,869:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:36,885:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,038:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,054:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,138:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,138:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,154:INFO:Calculating mean and std
2024-03-02 17:00:37,154:INFO:Creating metrics dataframe
2024-03-02 17:00:37,154:INFO:Uploading results into container
2024-03-02 17:00:37,154:INFO:Uploading model into container now
2024-03-02 17:00:37,154:INFO:_master_model_container: 5
2024-03-02 17:00:37,154:INFO:_display_container: 2
2024-03-02 17:00:37,154:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-02 17:00:37,154:INFO:create_model() successfully completed......................................
2024-03-02 17:00:37,352:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:37,352:INFO:Creating metrics dataframe
2024-03-02 17:00:37,357:INFO:Initializing Ridge Classifier
2024-03-02 17:00:37,357:INFO:Total runtime is 0.5561293522516887 minutes
2024-03-02 17:00:37,369:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:37,369:INFO:Initializing create_model()
2024-03-02 17:00:37,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:37,369:INFO:Checking exceptions
2024-03-02 17:00:37,369:INFO:Importing libraries
2024-03-02 17:00:37,369:INFO:Copying training dataset
2024-03-02 17:00:37,385:INFO:Defining folds
2024-03-02 17:00:37,385:INFO:Declaring metric variables
2024-03-02 17:00:37,401:INFO:Importing untrained model
2024-03-02 17:00:37,402:INFO:Ridge Classifier Imported successfully
2024-03-02 17:00:37,402:INFO:Starting cross validation
2024-03-02 17:00:37,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:37,586:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.62559e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,586:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.73038e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,603:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.6205e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,620:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,620:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,636:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,636:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.78417e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,636:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,636:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.88532e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,636:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,661:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,661:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,669:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,669:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.41006e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,669:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.53691e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,669:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,685:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.69517e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,686:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,703:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,703:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,703:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,703:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,703:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,720:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,753:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.47239e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,774:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.67306e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:00:37,774:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,774:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:00:37,786:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,786:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:00:37,803:INFO:Calculating mean and std
2024-03-02 17:00:37,803:INFO:Creating metrics dataframe
2024-03-02 17:00:37,803:INFO:Uploading results into container
2024-03-02 17:00:37,803:INFO:Uploading model into container now
2024-03-02 17:00:37,811:INFO:_master_model_container: 6
2024-03-02 17:00:37,811:INFO:_display_container: 2
2024-03-02 17:00:37,811:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-02 17:00:37,811:INFO:create_model() successfully completed......................................
2024-03-02 17:00:38,004:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:38,004:INFO:Creating metrics dataframe
2024-03-02 17:00:38,020:INFO:Initializing Random Forest Classifier
2024-03-02 17:00:38,020:INFO:Total runtime is 0.5671764413515727 minutes
2024-03-02 17:00:38,020:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:38,020:INFO:Initializing create_model()
2024-03-02 17:00:38,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:38,020:INFO:Checking exceptions
2024-03-02 17:00:38,020:INFO:Importing libraries
2024-03-02 17:00:38,020:INFO:Copying training dataset
2024-03-02 17:00:38,051:INFO:Defining folds
2024-03-02 17:00:38,051:INFO:Declaring metric variables
2024-03-02 17:00:38,055:INFO:Importing untrained model
2024-03-02 17:00:38,061:INFO:Random Forest Classifier Imported successfully
2024-03-02 17:00:38,090:INFO:Starting cross validation
2024-03-02 17:00:38,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:55,960:INFO:Calculating mean and std
2024-03-02 17:00:55,968:INFO:Creating metrics dataframe
2024-03-02 17:00:55,968:INFO:Uploading results into container
2024-03-02 17:00:55,968:INFO:Uploading model into container now
2024-03-02 17:00:55,968:INFO:_master_model_container: 7
2024-03-02 17:00:55,968:INFO:_display_container: 2
2024-03-02 17:00:55,968:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 17:00:55,968:INFO:create_model() successfully completed......................................
2024-03-02 17:00:56,272:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:56,272:INFO:Creating metrics dataframe
2024-03-02 17:00:56,293:INFO:Initializing Quadratic Discriminant Analysis
2024-03-02 17:00:56,293:INFO:Total runtime is 0.8717274308204652 minutes
2024-03-02 17:00:56,305:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:56,305:INFO:Initializing create_model()
2024-03-02 17:00:56,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:56,305:INFO:Checking exceptions
2024-03-02 17:00:56,305:INFO:Importing libraries
2024-03-02 17:00:56,305:INFO:Copying training dataset
2024-03-02 17:00:56,349:INFO:Defining folds
2024-03-02 17:00:56,349:INFO:Declaring metric variables
2024-03-02 17:00:56,358:INFO:Importing untrained model
2024-03-02 17:00:56,366:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-02 17:00:56,382:INFO:Starting cross validation
2024-03-02 17:00:56,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:56,541:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,541:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,541:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,561:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,561:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,577:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,585:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,602:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,749:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,756:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:00:56,864:INFO:Calculating mean and std
2024-03-02 17:00:56,872:INFO:Creating metrics dataframe
2024-03-02 17:00:56,872:INFO:Uploading results into container
2024-03-02 17:00:56,872:INFO:Uploading model into container now
2024-03-02 17:00:56,872:INFO:_master_model_container: 8
2024-03-02 17:00:56,872:INFO:_display_container: 2
2024-03-02 17:00:56,872:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-02 17:00:56,872:INFO:create_model() successfully completed......................................
2024-03-02 17:00:57,225:INFO:SubProcess create_model() end ==================================
2024-03-02 17:00:57,225:INFO:Creating metrics dataframe
2024-03-02 17:00:57,236:INFO:Initializing Ada Boost Classifier
2024-03-02 17:00:57,236:INFO:Total runtime is 0.8874501268068951 minutes
2024-03-02 17:00:57,249:INFO:SubProcess create_model() called ==================================
2024-03-02 17:00:57,249:INFO:Initializing create_model()
2024-03-02 17:00:57,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:00:57,249:INFO:Checking exceptions
2024-03-02 17:00:57,249:INFO:Importing libraries
2024-03-02 17:00:57,249:INFO:Copying training dataset
2024-03-02 17:00:57,298:INFO:Defining folds
2024-03-02 17:00:57,298:INFO:Declaring metric variables
2024-03-02 17:00:57,306:INFO:Importing untrained model
2024-03-02 17:00:57,306:INFO:Ada Boost Classifier Imported successfully
2024-03-02 17:00:57,324:INFO:Starting cross validation
2024-03-02 17:00:57,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:00:57,419:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,437:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,445:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,475:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,475:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,491:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,491:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:00:57,511:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:01:01,200:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:01:01,200:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:01:01,253:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:01:01,300:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:01:01,369:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:01:01,400:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:01:01,453:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:01:03,350:INFO:Calculating mean and std
2024-03-02 17:01:03,350:INFO:Creating metrics dataframe
2024-03-02 17:01:03,350:INFO:Uploading results into container
2024-03-02 17:01:03,350:INFO:Uploading model into container now
2024-03-02 17:01:03,350:INFO:_master_model_container: 9
2024-03-02 17:01:03,350:INFO:_display_container: 2
2024-03-02 17:01:03,350:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-03-02 17:01:03,350:INFO:create_model() successfully completed......................................
2024-03-02 17:01:03,528:INFO:SubProcess create_model() end ==================================
2024-03-02 17:01:03,528:INFO:Creating metrics dataframe
2024-03-02 17:01:03,548:INFO:Initializing Gradient Boosting Classifier
2024-03-02 17:01:03,548:INFO:Total runtime is 0.9926512440045676 minutes
2024-03-02 17:01:03,556:INFO:SubProcess create_model() called ==================================
2024-03-02 17:01:03,556:INFO:Initializing create_model()
2024-03-02 17:01:03,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:01:03,556:INFO:Checking exceptions
2024-03-02 17:01:03,556:INFO:Importing libraries
2024-03-02 17:01:03,556:INFO:Copying training dataset
2024-03-02 17:01:03,590:INFO:Defining folds
2024-03-02 17:01:03,590:INFO:Declaring metric variables
2024-03-02 17:01:03,595:INFO:Importing untrained model
2024-03-02 17:01:03,598:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 17:01:03,605:INFO:Starting cross validation
2024-03-02 17:01:03,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:03:17,368:INFO:Calculating mean and std
2024-03-02 17:03:17,368:INFO:Creating metrics dataframe
2024-03-02 17:03:17,368:INFO:Uploading results into container
2024-03-02 17:03:17,368:INFO:Uploading model into container now
2024-03-02 17:03:17,368:INFO:_master_model_container: 10
2024-03-02 17:03:17,368:INFO:_display_container: 2
2024-03-02 17:03:17,368:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 17:03:17,368:INFO:create_model() successfully completed......................................
2024-03-02 17:03:17,569:INFO:SubProcess create_model() end ==================================
2024-03-02 17:03:17,569:INFO:Creating metrics dataframe
2024-03-02 17:03:17,600:INFO:Initializing Linear Discriminant Analysis
2024-03-02 17:03:17,600:INFO:Total runtime is 3.2268394192059837 minutes
2024-03-02 17:03:17,600:INFO:SubProcess create_model() called ==================================
2024-03-02 17:03:17,600:INFO:Initializing create_model()
2024-03-02 17:03:17,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:03:17,600:INFO:Checking exceptions
2024-03-02 17:03:17,600:INFO:Importing libraries
2024-03-02 17:03:17,600:INFO:Copying training dataset
2024-03-02 17:03:17,631:INFO:Defining folds
2024-03-02 17:03:17,631:INFO:Declaring metric variables
2024-03-02 17:03:17,631:INFO:Importing untrained model
2024-03-02 17:03:17,648:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 17:03:17,661:INFO:Starting cross validation
2024-03-02 17:03:17,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:03:18,335:INFO:Calculating mean and std
2024-03-02 17:03:18,335:INFO:Creating metrics dataframe
2024-03-02 17:03:18,335:INFO:Uploading results into container
2024-03-02 17:03:18,335:INFO:Uploading model into container now
2024-03-02 17:03:18,335:INFO:_master_model_container: 11
2024-03-02 17:03:18,335:INFO:_display_container: 2
2024-03-02 17:03:18,335:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 17:03:18,335:INFO:create_model() successfully completed......................................
2024-03-02 17:03:18,598:INFO:SubProcess create_model() end ==================================
2024-03-02 17:03:18,598:INFO:Creating metrics dataframe
2024-03-02 17:03:18,618:INFO:Initializing Extra Trees Classifier
2024-03-02 17:03:18,618:INFO:Total runtime is 3.243813526630402 minutes
2024-03-02 17:03:18,620:INFO:SubProcess create_model() called ==================================
2024-03-02 17:03:18,620:INFO:Initializing create_model()
2024-03-02 17:03:18,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:03:18,620:INFO:Checking exceptions
2024-03-02 17:03:18,620:INFO:Importing libraries
2024-03-02 17:03:18,620:INFO:Copying training dataset
2024-03-02 17:03:18,664:INFO:Defining folds
2024-03-02 17:03:18,664:INFO:Declaring metric variables
2024-03-02 17:03:18,668:INFO:Importing untrained model
2024-03-02 17:03:18,675:INFO:Extra Trees Classifier Imported successfully
2024-03-02 17:03:18,685:INFO:Starting cross validation
2024-03-02 17:03:18,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:03:28,032:INFO:Calculating mean and std
2024-03-02 17:03:28,047:INFO:Creating metrics dataframe
2024-03-02 17:03:28,047:INFO:Uploading results into container
2024-03-02 17:03:28,047:INFO:Uploading model into container now
2024-03-02 17:03:28,047:INFO:_master_model_container: 12
2024-03-02 17:03:28,047:INFO:_display_container: 2
2024-03-02 17:03:28,047:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 17:03:28,047:INFO:create_model() successfully completed......................................
2024-03-02 17:03:28,298:INFO:SubProcess create_model() end ==================================
2024-03-02 17:03:28,298:INFO:Creating metrics dataframe
2024-03-02 17:03:28,314:INFO:Initializing Extreme Gradient Boosting
2024-03-02 17:03:28,314:INFO:Total runtime is 3.4054146130879723 minutes
2024-03-02 17:03:28,333:INFO:SubProcess create_model() called ==================================
2024-03-02 17:03:28,333:INFO:Initializing create_model()
2024-03-02 17:03:28,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AAD865E50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0636790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:03:28,333:INFO:Checking exceptions
2024-03-02 17:03:28,333:INFO:Importing libraries
2024-03-02 17:03:28,333:INFO:Copying training dataset
2024-03-02 17:03:28,369:INFO:Defining folds
2024-03-02 17:03:28,369:INFO:Declaring metric variables
2024-03-02 17:03:28,375:INFO:Importing untrained model
2024-03-02 17:03:28,382:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 17:03:28,382:INFO:Starting cross validation
2024-03-02 17:03:28,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:05:24,532:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_12888\632799019.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train['target'] = train[["Pastry","Z_Scratch","K_Scatch","Stains","Dirtiness","Bumps","Other_Faults"]].apply(lambda row: row.idxmax(), axis=1)

2024-03-02 17:05:33,996:INFO:PyCaret ClassificationExperiment
2024-03-02 17:05:33,996:INFO:Logging name: clf-default-name
2024-03-02 17:05:33,996:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 17:05:33,996:INFO:version 3.3.0
2024-03-02 17:05:33,996:INFO:Initializing setup()
2024-03-02 17:05:33,996:INFO:self.USI: f522
2024-03-02 17:05:33,996:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'idx', 'X_train', 'USI', 'pipeline', 'X', 'logging_param', '_ml_usecase', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', 'y_test', 'gpu_param', 'log_plots_param', 'y_train', 'html_param', 'seed', 'n_jobs_param', 'is_multiclass', 'data', 'exp_name_log', 'exp_id', 'X_test', 'fold_shuffle_param', 'y', 'target_param', 'fold_generator'}
2024-03-02 17:05:33,996:INFO:Checking environment
2024-03-02 17:05:33,996:INFO:python_version: 3.11.5
2024-03-02 17:05:33,996:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 17:05:33,996:INFO:machine: AMD64
2024-03-02 17:05:33,996:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 17:05:33,996:INFO:Memory: svmem(total=8327905280, available=2545528832, percent=69.4, used=5782376448, free=2545528832)
2024-03-02 17:05:33,996:INFO:Physical Core: 4
2024-03-02 17:05:33,996:INFO:Logical Core: 8
2024-03-02 17:05:33,996:INFO:Checking libraries
2024-03-02 17:05:33,996:INFO:System:
2024-03-02 17:05:33,996:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 17:05:33,996:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 17:05:33,996:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 17:05:33,996:INFO:PyCaret required dependencies:
2024-03-02 17:05:33,996:INFO:                 pip: 23.2.1
2024-03-02 17:05:33,996:INFO:          setuptools: 68.0.0
2024-03-02 17:05:33,996:INFO:             pycaret: 3.3.0
2024-03-02 17:05:33,996:INFO:             IPython: 8.15.0
2024-03-02 17:05:33,996:INFO:          ipywidgets: 8.0.4
2024-03-02 17:05:33,996:INFO:                tqdm: 4.65.0
2024-03-02 17:05:33,996:INFO:               numpy: 1.24.3
2024-03-02 17:05:33,996:INFO:              pandas: 2.0.3
2024-03-02 17:05:33,996:INFO:              jinja2: 3.1.2
2024-03-02 17:05:33,996:INFO:               scipy: 1.11.1
2024-03-02 17:05:33,996:INFO:              joblib: 1.2.0
2024-03-02 17:05:33,996:INFO:             sklearn: 1.4.1.post1
2024-03-02 17:05:33,996:INFO:                pyod: 1.1.3
2024-03-02 17:05:33,996:INFO:            imblearn: 0.12.0
2024-03-02 17:05:33,996:INFO:   category_encoders: 2.6.3
2024-03-02 17:05:33,996:INFO:            lightgbm: 4.3.0
2024-03-02 17:05:33,996:INFO:               numba: 0.57.1
2024-03-02 17:05:33,996:INFO:            requests: 2.31.0
2024-03-02 17:05:33,996:INFO:          matplotlib: 3.7.2
2024-03-02 17:05:33,996:INFO:          scikitplot: 0.3.7
2024-03-02 17:05:33,996:INFO:         yellowbrick: 1.5
2024-03-02 17:05:33,996:INFO:              plotly: 5.19.0
2024-03-02 17:05:33,996:INFO:    plotly-resampler: Not installed
2024-03-02 17:05:33,996:INFO:             kaleido: 0.2.1
2024-03-02 17:05:33,996:INFO:           schemdraw: 0.15
2024-03-02 17:05:33,996:INFO:         statsmodels: 0.14.0
2024-03-02 17:05:33,996:INFO:              sktime: 0.26.1
2024-03-02 17:05:33,996:INFO:               tbats: 1.1.3
2024-03-02 17:05:33,996:INFO:            pmdarima: 2.0.4
2024-03-02 17:05:33,996:INFO:              psutil: 5.9.0
2024-03-02 17:05:33,996:INFO:          markupsafe: 2.1.1
2024-03-02 17:05:33,996:INFO:             pickle5: Not installed
2024-03-02 17:05:33,996:INFO:         cloudpickle: 2.2.1
2024-03-02 17:05:33,996:INFO:         deprecation: 2.1.0
2024-03-02 17:05:33,996:INFO:              xxhash: 2.0.2
2024-03-02 17:05:33,996:INFO:           wurlitzer: Not installed
2024-03-02 17:05:33,996:INFO:PyCaret optional dependencies:
2024-03-02 17:05:33,996:INFO:                shap: 0.44.1
2024-03-02 17:05:33,996:INFO:           interpret: Not installed
2024-03-02 17:05:33,996:INFO:                umap: Not installed
2024-03-02 17:05:33,996:INFO:     ydata_profiling: Not installed
2024-03-02 17:05:33,996:INFO:  explainerdashboard: Not installed
2024-03-02 17:05:33,996:INFO:             autoviz: Not installed
2024-03-02 17:05:33,996:INFO:           fairlearn: Not installed
2024-03-02 17:05:33,996:INFO:          deepchecks: Not installed
2024-03-02 17:05:33,996:INFO:             xgboost: 2.0.3
2024-03-02 17:05:33,996:INFO:            catboost: 1.2.2
2024-03-02 17:05:33,996:INFO:              kmodes: Not installed
2024-03-02 17:05:33,996:INFO:             mlxtend: Not installed
2024-03-02 17:05:33,996:INFO:       statsforecast: Not installed
2024-03-02 17:05:33,996:INFO:        tune_sklearn: Not installed
2024-03-02 17:05:33,996:INFO:                 ray: Not installed
2024-03-02 17:05:33,996:INFO:            hyperopt: Not installed
2024-03-02 17:05:33,996:INFO:              optuna: 3.5.0
2024-03-02 17:05:33,996:INFO:               skopt: Not installed
2024-03-02 17:05:33,996:INFO:              mlflow: Not installed
2024-03-02 17:05:33,996:INFO:              gradio: Not installed
2024-03-02 17:05:33,996:INFO:             fastapi: Not installed
2024-03-02 17:05:33,996:INFO:             uvicorn: Not installed
2024-03-02 17:05:33,996:INFO:              m2cgen: Not installed
2024-03-02 17:05:33,996:INFO:           evidently: Not installed
2024-03-02 17:05:33,996:INFO:               fugue: Not installed
2024-03-02 17:05:33,996:INFO:           streamlit: Not installed
2024-03-02 17:05:33,996:INFO:             prophet: Not installed
2024-03-02 17:05:33,996:INFO:None
2024-03-02 17:05:33,996:INFO:Set up data.
2024-03-02 17:05:34,028:INFO:Set up folding strategy.
2024-03-02 17:05:34,028:INFO:Set up train/test split.
2024-03-02 17:05:34,043:INFO:Set up index.
2024-03-02 17:05:34,043:INFO:Assigning column types.
2024-03-02 17:05:34,059:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 17:05:34,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,131:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,147:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,215:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,215:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,215:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 17:05:34,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,281:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,281:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 17:05:34,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,348:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,348:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 17:05:34,422:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,431:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,498:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,498:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,498:INFO:Preparing preprocessing pipeline...
2024-03-02 17:05:34,498:INFO:Set up simple imputation.
2024-03-02 17:05:34,548:INFO:Finished creating preprocessing pipeline.
2024-03-02 17:05:34,548:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-03-02 17:05:34,548:INFO:Creating final display dataframe.
2024-03-02 17:05:34,698:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (18380, 28)
5   Transformed train set shape       (12866, 28)
6    Transformed test set shape        (5514, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              f522
2024-03-02 17:05:34,781:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,781:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,848:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 17:05:34,848:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 17:05:34,848:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 17:05:34,848:INFO:setup() successfully completed in 0.94s...............
2024-03-02 17:05:40,003:INFO:Initializing compare_models()
2024-03-02 17:05:40,003:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 17:05:40,003:INFO:Checking exceptions
2024-03-02 17:05:40,021:INFO:Preparing display monitor
2024-03-02 17:05:40,096:INFO:Initializing Logistic Regression
2024-03-02 17:05:40,096:INFO:Total runtime is 0.0 minutes
2024-03-02 17:05:40,111:INFO:SubProcess create_model() called ==================================
2024-03-02 17:05:40,111:INFO:Initializing create_model()
2024-03-02 17:05:40,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:05:40,111:INFO:Checking exceptions
2024-03-02 17:05:40,111:INFO:Importing libraries
2024-03-02 17:05:40,111:INFO:Copying training dataset
2024-03-02 17:05:40,152:INFO:Defining folds
2024-03-02 17:05:40,152:INFO:Declaring metric variables
2024-03-02 17:05:40,158:INFO:Importing untrained model
2024-03-02 17:05:40,164:INFO:Logistic Regression Imported successfully
2024-03-02 17:05:40,171:INFO:Starting cross validation
2024-03-02 17:05:40,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:05:59,610:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,645:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,662:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,695:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,695:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,728:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,744:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,762:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,778:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,828:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,828:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,912:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:05:59,928:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:05:59,961:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:06:00,011:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:00,045:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:03,794:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:06:03,879:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:04,194:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-03-02 17:06:04,227:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:04,243:INFO:Calculating mean and std
2024-03-02 17:06:04,243:INFO:Creating metrics dataframe
2024-03-02 17:06:04,249:INFO:Uploading results into container
2024-03-02 17:06:04,249:INFO:Uploading model into container now
2024-03-02 17:06:04,249:INFO:_master_model_container: 1
2024-03-02 17:06:04,249:INFO:_display_container: 2
2024-03-02 17:06:04,249:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-02 17:06:04,249:INFO:create_model() successfully completed......................................
2024-03-02 17:06:04,527:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:04,527:INFO:Creating metrics dataframe
2024-03-02 17:06:04,545:INFO:Initializing K Neighbors Classifier
2024-03-02 17:06:04,545:INFO:Total runtime is 0.4074714263280233 minutes
2024-03-02 17:06:04,553:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:04,553:INFO:Initializing create_model()
2024-03-02 17:06:04,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:04,553:INFO:Checking exceptions
2024-03-02 17:06:04,553:INFO:Importing libraries
2024-03-02 17:06:04,553:INFO:Copying training dataset
2024-03-02 17:06:04,593:INFO:Defining folds
2024-03-02 17:06:04,593:INFO:Declaring metric variables
2024-03-02 17:06:04,603:INFO:Importing untrained model
2024-03-02 17:06:04,603:INFO:K Neighbors Classifier Imported successfully
2024-03-02 17:06:04,615:INFO:Starting cross validation
2024-03-02 17:06:04,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:06,460:INFO:Calculating mean and std
2024-03-02 17:06:06,460:INFO:Creating metrics dataframe
2024-03-02 17:06:06,460:INFO:Uploading results into container
2024-03-02 17:06:06,460:INFO:Uploading model into container now
2024-03-02 17:06:06,460:INFO:_master_model_container: 2
2024-03-02 17:06:06,460:INFO:_display_container: 2
2024-03-02 17:06:06,476:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-02 17:06:06,476:INFO:create_model() successfully completed......................................
2024-03-02 17:06:06,743:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:06,743:INFO:Creating metrics dataframe
2024-03-02 17:06:06,760:INFO:Initializing Naive Bayes
2024-03-02 17:06:06,760:INFO:Total runtime is 0.44439729054768884 minutes
2024-03-02 17:06:06,760:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:06,760:INFO:Initializing create_model()
2024-03-02 17:06:06,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:06,760:INFO:Checking exceptions
2024-03-02 17:06:06,760:INFO:Importing libraries
2024-03-02 17:06:06,760:INFO:Copying training dataset
2024-03-02 17:06:06,801:INFO:Defining folds
2024-03-02 17:06:06,802:INFO:Declaring metric variables
2024-03-02 17:06:06,811:INFO:Importing untrained model
2024-03-02 17:06:06,815:INFO:Naive Bayes Imported successfully
2024-03-02 17:06:06,831:INFO:Starting cross validation
2024-03-02 17:06:06,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:07,044:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:07,060:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:07,060:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:07,127:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:07,210:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:07,227:INFO:Calculating mean and std
2024-03-02 17:06:07,227:INFO:Creating metrics dataframe
2024-03-02 17:06:07,227:INFO:Uploading results into container
2024-03-02 17:06:07,227:INFO:Uploading model into container now
2024-03-02 17:06:07,227:INFO:_master_model_container: 3
2024-03-02 17:06:07,227:INFO:_display_container: 2
2024-03-02 17:06:07,227:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-02 17:06:07,227:INFO:create_model() successfully completed......................................
2024-03-02 17:06:07,527:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:07,527:INFO:Creating metrics dataframe
2024-03-02 17:06:07,543:INFO:Initializing Decision Tree Classifier
2024-03-02 17:06:07,543:INFO:Total runtime is 0.45744545459747316 minutes
2024-03-02 17:06:07,551:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:07,551:INFO:Initializing create_model()
2024-03-02 17:06:07,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:07,551:INFO:Checking exceptions
2024-03-02 17:06:07,551:INFO:Importing libraries
2024-03-02 17:06:07,551:INFO:Copying training dataset
2024-03-02 17:06:07,579:INFO:Defining folds
2024-03-02 17:06:07,584:INFO:Declaring metric variables
2024-03-02 17:06:07,585:INFO:Importing untrained model
2024-03-02 17:06:07,593:INFO:Decision Tree Classifier Imported successfully
2024-03-02 17:06:07,603:INFO:Starting cross validation
2024-03-02 17:06:07,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:09,277:INFO:Calculating mean and std
2024-03-02 17:06:09,277:INFO:Creating metrics dataframe
2024-03-02 17:06:09,277:INFO:Uploading results into container
2024-03-02 17:06:09,277:INFO:Uploading model into container now
2024-03-02 17:06:09,277:INFO:_master_model_container: 4
2024-03-02 17:06:09,277:INFO:_display_container: 2
2024-03-02 17:06:09,277:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-03-02 17:06:09,277:INFO:create_model() successfully completed......................................
2024-03-02 17:06:09,510:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:09,510:INFO:Creating metrics dataframe
2024-03-02 17:06:09,510:INFO:Initializing SVM - Linear Kernel
2024-03-02 17:06:09,510:INFO:Total runtime is 0.49022206862767537 minutes
2024-03-02 17:06:09,528:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:09,528:INFO:Initializing create_model()
2024-03-02 17:06:09,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:09,528:INFO:Checking exceptions
2024-03-02 17:06:09,528:INFO:Importing libraries
2024-03-02 17:06:09,528:INFO:Copying training dataset
2024-03-02 17:06:09,580:INFO:Defining folds
2024-03-02 17:06:09,592:INFO:Declaring metric variables
2024-03-02 17:06:09,601:INFO:Importing untrained model
2024-03-02 17:06:09,609:INFO:SVM - Linear Kernel Imported successfully
2024-03-02 17:06:09,626:INFO:Starting cross validation
2024-03-02 17:06:09,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:10,910:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,026:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,426:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,451:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,476:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,493:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,510:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,526:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,551:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,594:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,641:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,676:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,693:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,693:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:11,810:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:11,843:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,176:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,193:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,226:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,242:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,250:INFO:Calculating mean and std
2024-03-02 17:06:12,250:INFO:Creating metrics dataframe
2024-03-02 17:06:12,259:INFO:Uploading results into container
2024-03-02 17:06:12,259:INFO:Uploading model into container now
2024-03-02 17:06:12,259:INFO:_master_model_container: 5
2024-03-02 17:06:12,259:INFO:_display_container: 2
2024-03-02 17:06:12,259:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-02 17:06:12,259:INFO:create_model() successfully completed......................................
2024-03-02 17:06:12,493:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:12,493:INFO:Creating metrics dataframe
2024-03-02 17:06:12,511:INFO:Initializing Ridge Classifier
2024-03-02 17:06:12,511:INFO:Total runtime is 0.5402479728062948 minutes
2024-03-02 17:06:12,511:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:12,511:INFO:Initializing create_model()
2024-03-02 17:06:12,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:12,511:INFO:Checking exceptions
2024-03-02 17:06:12,511:INFO:Importing libraries
2024-03-02 17:06:12,511:INFO:Copying training dataset
2024-03-02 17:06:12,554:INFO:Defining folds
2024-03-02 17:06:12,554:INFO:Declaring metric variables
2024-03-02 17:06:12,559:INFO:Importing untrained model
2024-03-02 17:06:12,564:INFO:Ridge Classifier Imported successfully
2024-03-02 17:06:12,575:INFO:Starting cross validation
2024-03-02 17:06:12,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:12,693:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.62597e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,710:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.73054e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,727:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.62047e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,727:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,727:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.78436e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,742:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,742:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,750:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.88529e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,750:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,750:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,760:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.69563e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,760:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,760:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,760:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,760:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.53708e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.41048e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,793:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,793:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,808:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,809:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,826:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.67351e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,848:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,848:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.47238e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-02 17:06:12,856:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,863:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-02 17:06:12,863:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:12,876:INFO:Calculating mean and std
2024-03-02 17:06:12,876:INFO:Creating metrics dataframe
2024-03-02 17:06:12,876:INFO:Uploading results into container
2024-03-02 17:06:12,876:INFO:Uploading model into container now
2024-03-02 17:06:12,876:INFO:_master_model_container: 6
2024-03-02 17:06:12,876:INFO:_display_container: 2
2024-03-02 17:06:12,876:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-03-02 17:06:12,876:INFO:create_model() successfully completed......................................
2024-03-02 17:06:13,109:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:13,109:INFO:Creating metrics dataframe
2024-03-02 17:06:13,128:INFO:Initializing Random Forest Classifier
2024-03-02 17:06:13,128:INFO:Total runtime is 0.5505244652430217 minutes
2024-03-02 17:06:13,128:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:13,128:INFO:Initializing create_model()
2024-03-02 17:06:13,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:13,128:INFO:Checking exceptions
2024-03-02 17:06:13,128:INFO:Importing libraries
2024-03-02 17:06:13,128:INFO:Copying training dataset
2024-03-02 17:06:13,158:INFO:Defining folds
2024-03-02 17:06:13,158:INFO:Declaring metric variables
2024-03-02 17:06:13,166:INFO:Importing untrained model
2024-03-02 17:06:13,166:INFO:Random Forest Classifier Imported successfully
2024-03-02 17:06:13,178:INFO:Starting cross validation
2024-03-02 17:06:13,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:29,608:INFO:Calculating mean and std
2024-03-02 17:06:29,608:INFO:Creating metrics dataframe
2024-03-02 17:06:29,621:INFO:Uploading results into container
2024-03-02 17:06:29,623:INFO:Uploading model into container now
2024-03-02 17:06:29,623:INFO:_master_model_container: 7
2024-03-02 17:06:29,623:INFO:_display_container: 2
2024-03-02 17:06:29,623:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 17:06:29,623:INFO:create_model() successfully completed......................................
2024-03-02 17:06:29,957:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:29,959:INFO:Creating metrics dataframe
2024-03-02 17:06:29,975:INFO:Initializing Quadratic Discriminant Analysis
2024-03-02 17:06:29,975:INFO:Total runtime is 0.8313055475552877 minutes
2024-03-02 17:06:29,975:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:29,975:INFO:Initializing create_model()
2024-03-02 17:06:29,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:29,975:INFO:Checking exceptions
2024-03-02 17:06:29,975:INFO:Importing libraries
2024-03-02 17:06:29,983:INFO:Copying training dataset
2024-03-02 17:06:30,007:INFO:Defining folds
2024-03-02 17:06:30,007:INFO:Declaring metric variables
2024-03-02 17:06:30,007:INFO:Importing untrained model
2024-03-02 17:06:30,024:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-02 17:06:30,040:INFO:Starting cross validation
2024-03-02 17:06:30,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:30,191:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,191:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,191:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,208:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,224:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,240:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,248:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,264:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,391:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,408:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-02 17:06:30,474:INFO:Calculating mean and std
2024-03-02 17:06:30,474:INFO:Creating metrics dataframe
2024-03-02 17:06:30,474:INFO:Uploading results into container
2024-03-02 17:06:30,474:INFO:Uploading model into container now
2024-03-02 17:06:30,474:INFO:_master_model_container: 8
2024-03-02 17:06:30,474:INFO:_display_container: 2
2024-03-02 17:06:30,490:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-02 17:06:30,490:INFO:create_model() successfully completed......................................
2024-03-02 17:06:30,795:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:30,795:INFO:Creating metrics dataframe
2024-03-02 17:06:30,807:INFO:Initializing Ada Boost Classifier
2024-03-02 17:06:30,807:INFO:Total runtime is 0.8451800584793091 minutes
2024-03-02 17:06:30,807:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:30,807:INFO:Initializing create_model()
2024-03-02 17:06:30,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:30,807:INFO:Checking exceptions
2024-03-02 17:06:30,807:INFO:Importing libraries
2024-03-02 17:06:30,807:INFO:Copying training dataset
2024-03-02 17:06:30,857:INFO:Defining folds
2024-03-02 17:06:30,857:INFO:Declaring metric variables
2024-03-02 17:06:30,866:INFO:Importing untrained model
2024-03-02 17:06:30,878:INFO:Ada Boost Classifier Imported successfully
2024-03-02 17:06:30,896:INFO:Starting cross validation
2024-03-02 17:06:30,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:06:31,023:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,033:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,040:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,057:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,057:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,074:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,074:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:31,091:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:33,940:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:34,040:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:34,040:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:34,056:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:34,074:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:34,124:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-02 17:06:34,124:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:06:35,873:INFO:Calculating mean and std
2024-03-02 17:06:35,873:INFO:Creating metrics dataframe
2024-03-02 17:06:35,873:INFO:Uploading results into container
2024-03-02 17:06:35,873:INFO:Uploading model into container now
2024-03-02 17:06:35,873:INFO:_master_model_container: 9
2024-03-02 17:06:35,873:INFO:_display_container: 2
2024-03-02 17:06:35,873:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-03-02 17:06:35,873:INFO:create_model() successfully completed......................................
2024-03-02 17:06:36,106:INFO:SubProcess create_model() end ==================================
2024-03-02 17:06:36,106:INFO:Creating metrics dataframe
2024-03-02 17:06:36,123:INFO:Initializing Gradient Boosting Classifier
2024-03-02 17:06:36,123:INFO:Total runtime is 0.9337776462237041 minutes
2024-03-02 17:06:36,128:INFO:SubProcess create_model() called ==================================
2024-03-02 17:06:36,128:INFO:Initializing create_model()
2024-03-02 17:06:36,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:06:36,128:INFO:Checking exceptions
2024-03-02 17:06:36,128:INFO:Importing libraries
2024-03-02 17:06:36,128:INFO:Copying training dataset
2024-03-02 17:06:36,156:INFO:Defining folds
2024-03-02 17:06:36,156:INFO:Declaring metric variables
2024-03-02 17:06:36,156:INFO:Importing untrained model
2024-03-02 17:06:36,168:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 17:06:36,178:INFO:Starting cross validation
2024-03-02 17:06:36,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:08:36,749:INFO:Calculating mean and std
2024-03-02 17:08:36,749:INFO:Creating metrics dataframe
2024-03-02 17:08:36,749:INFO:Uploading results into container
2024-03-02 17:08:36,749:INFO:Uploading model into container now
2024-03-02 17:08:36,749:INFO:_master_model_container: 10
2024-03-02 17:08:36,749:INFO:_display_container: 2
2024-03-02 17:08:36,749:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 17:08:36,749:INFO:create_model() successfully completed......................................
2024-03-02 17:08:36,958:INFO:SubProcess create_model() end ==================================
2024-03-02 17:08:36,958:INFO:Creating metrics dataframe
2024-03-02 17:08:36,978:INFO:Initializing Linear Discriminant Analysis
2024-03-02 17:08:36,978:INFO:Total runtime is 2.948026259740194 minutes
2024-03-02 17:08:36,978:INFO:SubProcess create_model() called ==================================
2024-03-02 17:08:36,978:INFO:Initializing create_model()
2024-03-02 17:08:36,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:08:36,978:INFO:Checking exceptions
2024-03-02 17:08:36,978:INFO:Importing libraries
2024-03-02 17:08:36,978:INFO:Copying training dataset
2024-03-02 17:08:37,011:INFO:Defining folds
2024-03-02 17:08:37,011:INFO:Declaring metric variables
2024-03-02 17:08:37,011:INFO:Importing untrained model
2024-03-02 17:08:37,019:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 17:08:37,029:INFO:Starting cross validation
2024-03-02 17:08:37,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:08:37,458:INFO:Calculating mean and std
2024-03-02 17:08:37,458:INFO:Creating metrics dataframe
2024-03-02 17:08:37,474:INFO:Uploading results into container
2024-03-02 17:08:37,474:INFO:Uploading model into container now
2024-03-02 17:08:37,474:INFO:_master_model_container: 11
2024-03-02 17:08:37,474:INFO:_display_container: 2
2024-03-02 17:08:37,474:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 17:08:37,474:INFO:create_model() successfully completed......................................
2024-03-02 17:08:37,691:INFO:SubProcess create_model() end ==================================
2024-03-02 17:08:37,691:INFO:Creating metrics dataframe
2024-03-02 17:08:37,709:INFO:Initializing Extra Trees Classifier
2024-03-02 17:08:37,709:INFO:Total runtime is 2.9602172573407493 minutes
2024-03-02 17:08:37,711:INFO:SubProcess create_model() called ==================================
2024-03-02 17:08:37,711:INFO:Initializing create_model()
2024-03-02 17:08:37,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:08:37,711:INFO:Checking exceptions
2024-03-02 17:08:37,711:INFO:Importing libraries
2024-03-02 17:08:37,711:INFO:Copying training dataset
2024-03-02 17:08:37,741:INFO:Defining folds
2024-03-02 17:08:37,741:INFO:Declaring metric variables
2024-03-02 17:08:37,743:INFO:Importing untrained model
2024-03-02 17:08:37,751:INFO:Extra Trees Classifier Imported successfully
2024-03-02 17:08:37,757:INFO:Starting cross validation
2024-03-02 17:08:37,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:08:46,295:INFO:Calculating mean and std
2024-03-02 17:08:46,295:INFO:Creating metrics dataframe
2024-03-02 17:08:46,295:INFO:Uploading results into container
2024-03-02 17:08:46,295:INFO:Uploading model into container now
2024-03-02 17:08:46,295:INFO:_master_model_container: 12
2024-03-02 17:08:46,295:INFO:_display_container: 2
2024-03-02 17:08:46,295:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 17:08:46,295:INFO:create_model() successfully completed......................................
2024-03-02 17:08:46,640:INFO:SubProcess create_model() end ==================================
2024-03-02 17:08:46,640:INFO:Creating metrics dataframe
2024-03-02 17:08:46,656:INFO:Initializing Extreme Gradient Boosting
2024-03-02 17:08:46,656:INFO:Total runtime is 3.1093279480934144 minutes
2024-03-02 17:08:46,672:INFO:SubProcess create_model() called ==================================
2024-03-02 17:08:46,672:INFO:Initializing create_model()
2024-03-02 17:08:46,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:08:46,672:INFO:Checking exceptions
2024-03-02 17:08:46,672:INFO:Importing libraries
2024-03-02 17:08:46,672:INFO:Copying training dataset
2024-03-02 17:08:46,702:INFO:Defining folds
2024-03-02 17:08:46,703:INFO:Declaring metric variables
2024-03-02 17:08:46,706:INFO:Importing untrained model
2024-03-02 17:08:46,713:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 17:08:46,727:INFO:Starting cross validation
2024-03-02 17:08:46,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:09:02,905:INFO:Calculating mean and std
2024-03-02 17:09:02,905:INFO:Creating metrics dataframe
2024-03-02 17:09:02,905:INFO:Uploading results into container
2024-03-02 17:09:02,905:INFO:Uploading model into container now
2024-03-02 17:09:02,905:INFO:_master_model_container: 13
2024-03-02 17:09:02,905:INFO:_display_container: 2
2024-03-02 17:09:02,905:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-02 17:09:02,905:INFO:create_model() successfully completed......................................
2024-03-02 17:09:03,122:INFO:SubProcess create_model() end ==================================
2024-03-02 17:09:03,122:INFO:Creating metrics dataframe
2024-03-02 17:09:03,139:INFO:Initializing Light Gradient Boosting Machine
2024-03-02 17:09:03,139:INFO:Total runtime is 3.3840470472971598 minutes
2024-03-02 17:09:03,139:INFO:SubProcess create_model() called ==================================
2024-03-02 17:09:03,139:INFO:Initializing create_model()
2024-03-02 17:09:03,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:09:03,139:INFO:Checking exceptions
2024-03-02 17:09:03,139:INFO:Importing libraries
2024-03-02 17:09:03,139:INFO:Copying training dataset
2024-03-02 17:09:03,162:INFO:Defining folds
2024-03-02 17:09:03,162:INFO:Declaring metric variables
2024-03-02 17:09:03,171:INFO:Importing untrained model
2024-03-02 17:09:03,171:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 17:09:03,187:INFO:Starting cross validation
2024-03-02 17:09:03,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:09:19,536:INFO:Calculating mean and std
2024-03-02 17:09:19,536:INFO:Creating metrics dataframe
2024-03-02 17:09:19,544:INFO:Uploading results into container
2024-03-02 17:09:19,545:INFO:Uploading model into container now
2024-03-02 17:09:19,545:INFO:_master_model_container: 14
2024-03-02 17:09:19,545:INFO:_display_container: 2
2024-03-02 17:09:19,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 17:09:19,547:INFO:create_model() successfully completed......................................
2024-03-02 17:09:19,822:INFO:SubProcess create_model() end ==================================
2024-03-02 17:09:19,822:INFO:Creating metrics dataframe
2024-03-02 17:09:19,837:INFO:Initializing CatBoost Classifier
2024-03-02 17:09:19,837:INFO:Total runtime is 3.662348349889119 minutes
2024-03-02 17:09:19,837:INFO:SubProcess create_model() called ==================================
2024-03-02 17:09:19,837:INFO:Initializing create_model()
2024-03-02 17:09:19,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:09:19,837:INFO:Checking exceptions
2024-03-02 17:09:19,837:INFO:Importing libraries
2024-03-02 17:09:19,837:INFO:Copying training dataset
2024-03-02 17:09:19,868:INFO:Defining folds
2024-03-02 17:09:19,868:INFO:Declaring metric variables
2024-03-02 17:09:19,872:INFO:Importing untrained model
2024-03-02 17:09:19,878:INFO:CatBoost Classifier Imported successfully
2024-03-02 17:09:19,885:INFO:Starting cross validation
2024-03-02 17:09:19,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:11:46,618:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\Janith\anaconda3\Lib\site-packages\catboost\core.py", line 2319, in _fit
    self._train(
  File "c:\Users\Janith\anaconda3\Lib\site-packages\catboost\core.py", line 1723, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4645, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4694, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-03-02 17:11:46,618:INFO:Calculating mean and std
2024-03-02 17:11:46,618:INFO:Creating metrics dataframe
2024-03-02 17:11:46,634:INFO:Uploading results into container
2024-03-02 17:11:46,634:INFO:Uploading model into container now
2024-03-02 17:11:46,638:INFO:_master_model_container: 15
2024-03-02 17:11:46,638:INFO:_display_container: 2
2024-03-02 17:11:46,638:INFO:<catboost.core.CatBoostClassifier object at 0x0000021AB5163F50>
2024-03-02 17:11:46,638:INFO:create_model() successfully completed......................................
2024-03-02 17:11:46,918:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000021AB5163F50> raised an exception or returned all 0.0, trying without fit_kwargs:
2024-03-02 17:11:46,934:WARNING:Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-03-02 17:11:46,934:INFO:Initializing create_model()
2024-03-02 17:11:46,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:11:46,934:INFO:Checking exceptions
2024-03-02 17:11:46,934:INFO:Importing libraries
2024-03-02 17:11:46,934:INFO:Copying training dataset
2024-03-02 17:11:46,951:INFO:Defining folds
2024-03-02 17:11:46,951:INFO:Declaring metric variables
2024-03-02 17:11:46,951:INFO:Importing untrained model
2024-03-02 17:11:46,973:INFO:CatBoost Classifier Imported successfully
2024-03-02 17:11:46,987:INFO:Starting cross validation
2024-03-02 17:11:46,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:16:21,832:INFO:Calculating mean and std
2024-03-02 17:16:21,833:INFO:Creating metrics dataframe
2024-03-02 17:16:21,838:INFO:Uploading results into container
2024-03-02 17:16:21,838:INFO:Uploading model into container now
2024-03-02 17:16:21,841:INFO:_master_model_container: 16
2024-03-02 17:16:21,841:INFO:_display_container: 2
2024-03-02 17:16:21,841:INFO:<catboost.core.CatBoostClassifier object at 0x0000021AB5574850>
2024-03-02 17:16:21,841:INFO:create_model() successfully completed......................................
2024-03-02 17:16:22,133:INFO:SubProcess create_model() end ==================================
2024-03-02 17:16:22,133:INFO:Creating metrics dataframe
2024-03-02 17:16:22,149:INFO:Initializing Dummy Classifier
2024-03-02 17:16:22,149:INFO:Total runtime is 10.700885224342347 minutes
2024-03-02 17:16:22,149:INFO:SubProcess create_model() called ==================================
2024-03-02 17:16:22,166:INFO:Initializing create_model()
2024-03-02 17:16:22,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AB0BD65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:16:22,166:INFO:Checking exceptions
2024-03-02 17:16:22,166:INFO:Importing libraries
2024-03-02 17:16:22,166:INFO:Copying training dataset
2024-03-02 17:16:22,195:INFO:Defining folds
2024-03-02 17:16:22,195:INFO:Declaring metric variables
2024-03-02 17:16:22,199:INFO:Importing untrained model
2024-03-02 17:16:22,208:INFO:Dummy Classifier Imported successfully
2024-03-02 17:16:22,221:INFO:Starting cross validation
2024-03-02 17:16:22,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 17:16:22,384:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,400:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,433:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,433:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,456:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,467:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,484:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,535:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,535:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,583:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-02 17:16:22,600:INFO:Calculating mean and std
2024-03-02 17:16:22,608:INFO:Creating metrics dataframe
2024-03-02 17:16:22,608:INFO:Uploading results into container
2024-03-02 17:16:22,608:INFO:Uploading model into container now
2024-03-02 17:16:22,608:INFO:_master_model_container: 17
2024-03-02 17:16:22,608:INFO:_display_container: 2
2024-03-02 17:16:22,608:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-03-02 17:16:22,608:INFO:create_model() successfully completed......................................
2024-03-02 17:16:22,982:INFO:SubProcess create_model() end ==================================
2024-03-02 17:16:22,982:INFO:Creating metrics dataframe
2024-03-02 17:16:23,020:INFO:Initializing create_model()
2024-03-02 17:16:23,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 17:16:23,020:INFO:Checking exceptions
2024-03-02 17:16:23,020:INFO:Importing libraries
2024-03-02 17:16:23,020:INFO:Copying training dataset
2024-03-02 17:16:23,070:INFO:Defining folds
2024-03-02 17:16:23,070:INFO:Declaring metric variables
2024-03-02 17:16:23,070:INFO:Importing untrained model
2024-03-02 17:16:23,070:INFO:Declaring custom model
2024-03-02 17:16:23,070:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 17:16:23,070:INFO:Cross validation set to False
2024-03-02 17:16:23,070:INFO:Fitting Model
2024-03-02 17:17:00,928:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 17:17:00,928:INFO:create_model() successfully completed......................................
2024-03-02 17:17:01,169:INFO:_master_model_container: 17
2024-03-02 17:17:01,169:INFO:_display_container: 2
2024-03-02 17:17:01,169:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 17:17:01,169:INFO:compare_models() successfully completed......................................
2024-03-02 17:17:06,813:INFO:Initializing predict_model()
2024-03-02 17:17:06,813:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021AB5E57D80>)
2024-03-02 17:17:06,813:INFO:Checking exceptions
2024-03-02 17:17:06,813:INFO:Preloading libraries
2024-03-02 17:21:24,845:INFO:Initializing predict_model()
2024-03-02 17:21:24,846:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021AA88C3690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021AB5E576A0>)
2024-03-02 17:21:24,846:INFO:Checking exceptions
2024-03-02 17:21:24,847:INFO:Preloading libraries
2024-03-02 17:21:24,852:INFO:Set up data.
2024-03-02 17:21:24,877:INFO:Set up index.
2024-03-02 17:30:26,874:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_12888\2757464014.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  testpred["id"] = testid

2024-03-02 17:33:03,624:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_12888\2992806858.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  submitFile["id"] = testid

2024-03-02 17:33:08,974:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_12888\2528973048.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  submitFile["id"] = testid

2024-03-02 17:40:39,068:INFO:Initializing save_model()
2024-03-02 17:40:39,069:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=../Models/BasedModel, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-03-02 17:40:39,069:INFO:Adding model into prep_pipe
2024-03-02 17:41:16,331:INFO:Initializing save_model()
2024-03-02 17:41:16,335:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=../Models/BasedModel, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-03-02 17:41:16,335:INFO:Adding model into prep_pipe
2024-03-02 17:41:16,394:INFO:../Models/BasedModel.pkl saved in current working directory
2024-03-02 17:41:16,397:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'TypeOfSteel_A400',
                                             'Steel_Plate_Thickness',
                                             '...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-03-02 17:41:16,405:INFO:save_model() successfully completed......................................
2024-03-02 21:31:52,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:31:52,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:31:52,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:31:52,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:31:53,176:INFO:PyCaret ClassificationExperiment
2024-03-02 21:31:53,182:INFO:Logging name: clf-default-name
2024-03-02 21:31:53,182:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 21:31:53,182:INFO:version 3.3.0
2024-03-02 21:31:53,182:INFO:Initializing setup()
2024-03-02 21:31:53,182:INFO:self.USI: 7b5e
2024-03-02 21:31:53,182:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'y_train', 'fold_generator', 'fold_shuffle_param', 'USI', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'target_param', 'y_test', '_available_plots', 'data', 'seed', 'memory', 'X_train', 'X_test', 'exp_name_log', 'log_plots_param', 'X', 'idx', 'is_multiclass', 'y'}
2024-03-02 21:31:53,182:INFO:Checking environment
2024-03-02 21:31:53,182:INFO:python_version: 3.11.5
2024-03-02 21:31:53,182:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 21:31:53,182:INFO:machine: AMD64
2024-03-02 21:31:53,182:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 21:31:53,182:INFO:Memory: svmem(total=8327905280, available=2191974400, percent=73.7, used=6135930880, free=2191974400)
2024-03-02 21:31:53,182:INFO:Physical Core: 4
2024-03-02 21:31:53,183:INFO:Logical Core: 8
2024-03-02 21:31:53,183:INFO:Checking libraries
2024-03-02 21:31:53,183:INFO:System:
2024-03-02 21:31:53,183:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 21:31:53,183:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 21:31:53,183:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 21:31:53,183:INFO:PyCaret required dependencies:
2024-03-02 21:31:54,571:INFO:                 pip: 23.2.1
2024-03-02 21:31:54,571:INFO:          setuptools: 68.0.0
2024-03-02 21:31:54,571:INFO:             pycaret: 3.3.0
2024-03-02 21:31:54,571:INFO:             IPython: 8.15.0
2024-03-02 21:31:54,571:INFO:          ipywidgets: 8.0.4
2024-03-02 21:31:54,571:INFO:                tqdm: 4.65.0
2024-03-02 21:31:54,571:INFO:               numpy: 1.24.3
2024-03-02 21:31:54,571:INFO:              pandas: 2.0.3
2024-03-02 21:31:54,571:INFO:              jinja2: 3.1.2
2024-03-02 21:31:54,571:INFO:               scipy: 1.11.1
2024-03-02 21:31:54,571:INFO:              joblib: 1.2.0
2024-03-02 21:31:54,571:INFO:             sklearn: 1.4.1.post1
2024-03-02 21:31:54,572:INFO:                pyod: 1.1.3
2024-03-02 21:31:54,572:INFO:            imblearn: 0.12.0
2024-03-02 21:31:54,572:INFO:   category_encoders: 2.6.3
2024-03-02 21:31:54,572:INFO:            lightgbm: 4.3.0
2024-03-02 21:31:54,572:INFO:               numba: 0.57.1
2024-03-02 21:31:54,572:INFO:            requests: 2.31.0
2024-03-02 21:31:54,573:INFO:          matplotlib: 3.7.2
2024-03-02 21:31:54,573:INFO:          scikitplot: 0.3.7
2024-03-02 21:31:54,573:INFO:         yellowbrick: 1.5
2024-03-02 21:31:54,573:INFO:              plotly: 5.19.0
2024-03-02 21:31:54,573:INFO:    plotly-resampler: Not installed
2024-03-02 21:31:54,573:INFO:             kaleido: 0.2.1
2024-03-02 21:31:54,573:INFO:           schemdraw: 0.15
2024-03-02 21:31:54,573:INFO:         statsmodels: 0.14.0
2024-03-02 21:31:54,573:INFO:              sktime: 0.26.1
2024-03-02 21:31:54,573:INFO:               tbats: 1.1.3
2024-03-02 21:31:54,573:INFO:            pmdarima: 2.0.4
2024-03-02 21:31:54,573:INFO:              psutil: 5.9.0
2024-03-02 21:31:54,573:INFO:          markupsafe: 2.1.1
2024-03-02 21:31:54,574:INFO:             pickle5: Not installed
2024-03-02 21:31:54,574:INFO:         cloudpickle: 2.2.1
2024-03-02 21:31:54,574:INFO:         deprecation: 2.1.0
2024-03-02 21:31:54,574:INFO:              xxhash: 2.0.2
2024-03-02 21:31:54,574:INFO:           wurlitzer: Not installed
2024-03-02 21:31:54,574:INFO:PyCaret optional dependencies:
2024-03-02 21:31:54,659:INFO:                shap: 0.44.1
2024-03-02 21:31:54,659:INFO:           interpret: Not installed
2024-03-02 21:31:54,659:INFO:                umap: Not installed
2024-03-02 21:31:54,659:INFO:     ydata_profiling: Not installed
2024-03-02 21:31:54,659:INFO:  explainerdashboard: Not installed
2024-03-02 21:31:54,659:INFO:             autoviz: Not installed
2024-03-02 21:31:54,659:INFO:           fairlearn: Not installed
2024-03-02 21:31:54,659:INFO:          deepchecks: Not installed
2024-03-02 21:31:54,659:INFO:             xgboost: 2.0.3
2024-03-02 21:31:54,659:INFO:            catboost: 1.2.2
2024-03-02 21:31:54,659:INFO:              kmodes: Not installed
2024-03-02 21:31:54,659:INFO:             mlxtend: Not installed
2024-03-02 21:31:54,659:INFO:       statsforecast: Not installed
2024-03-02 21:31:54,659:INFO:        tune_sklearn: Not installed
2024-03-02 21:31:54,659:INFO:                 ray: Not installed
2024-03-02 21:31:54,659:INFO:            hyperopt: Not installed
2024-03-02 21:31:54,659:INFO:              optuna: 3.5.0
2024-03-02 21:31:54,659:INFO:               skopt: Not installed
2024-03-02 21:31:54,659:INFO:              mlflow: Not installed
2024-03-02 21:31:54,659:INFO:              gradio: Not installed
2024-03-02 21:31:54,659:INFO:             fastapi: Not installed
2024-03-02 21:31:54,659:INFO:             uvicorn: Not installed
2024-03-02 21:31:54,659:INFO:              m2cgen: Not installed
2024-03-02 21:31:54,659:INFO:           evidently: Not installed
2024-03-02 21:31:54,659:INFO:               fugue: Not installed
2024-03-02 21:31:54,659:INFO:           streamlit: Not installed
2024-03-02 21:31:54,659:INFO:             prophet: Not installed
2024-03-02 21:31:54,659:INFO:None
2024-03-02 21:31:54,659:INFO:Set up data.
2024-03-02 21:31:54,699:INFO:Set up folding strategy.
2024-03-02 21:31:54,699:INFO:Set up train/test split.
2024-03-02 21:31:54,730:INFO:Set up index.
2024-03-02 21:31:54,730:INFO:Assigning column types.
2024-03-02 21:31:54,758:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 21:31:54,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 21:31:54,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 21:31:54,862:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:54,862:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 21:31:55,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 21:31:55,108:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,108:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,108:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 21:31:55,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 21:31:55,191:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,191:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 21:31:55,275:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,275:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,275:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 21:31:55,362:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,362:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,424:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,441:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,441:INFO:Preparing preprocessing pipeline...
2024-03-02 21:31:55,441:INFO:Set up simple imputation.
2024-03-02 21:31:55,490:INFO:Finished creating preprocessing pipeline.
2024-03-02 21:31:55,509:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-03-02 21:31:55,509:INFO:Creating final display dataframe.
2024-03-02 21:31:55,691:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (18380, 28)
5   Transformed train set shape       (12866, 28)
6    Transformed test set shape        (5514, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7b5e
2024-03-02 21:31:55,823:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,828:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,913:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 21:31:55,922:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 21:31:55,927:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 21:31:55,928:INFO:setup() successfully completed in 2.85s...............
2024-03-02 21:35:46,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:35:46,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:35:46,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:35:46,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-02 21:36:07,821:INFO:Initializing compare_models()
2024-03-02 21:36:07,821:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, include=['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, 'include': ['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 21:36:07,822:INFO:Checking exceptions
2024-03-02 21:36:07,845:INFO:Preparing display monitor
2024-03-02 21:36:07,889:INFO:Initializing Linear Discriminant Analysis
2024-03-02 21:36:07,889:INFO:Total runtime is 7.363160451253255e-06 minutes
2024-03-02 21:36:07,896:INFO:SubProcess create_model() called ==================================
2024-03-02 21:36:07,897:INFO:Initializing create_model()
2024-03-02 21:36:07,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:36:07,897:INFO:Checking exceptions
2024-03-02 21:36:07,897:INFO:Importing libraries
2024-03-02 21:36:07,897:INFO:Copying training dataset
2024-03-02 21:36:07,932:INFO:Defining folds
2024-03-02 21:36:07,933:INFO:Declaring metric variables
2024-03-02 21:36:07,939:INFO:Importing untrained model
2024-03-02 21:36:07,945:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 21:36:07,959:INFO:Starting cross validation
2024-03-02 21:36:07,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:36:18,690:INFO:Calculating mean and std
2024-03-02 21:36:18,693:INFO:Creating metrics dataframe
2024-03-02 21:36:18,695:INFO:Uploading results into container
2024-03-02 21:36:18,695:INFO:Uploading model into container now
2024-03-02 21:36:18,696:INFO:_master_model_container: 1
2024-03-02 21:36:18,696:INFO:_display_container: 2
2024-03-02 21:36:18,696:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 21:36:18,696:INFO:create_model() successfully completed......................................
2024-03-02 21:36:18,815:INFO:SubProcess create_model() end ==================================
2024-03-02 21:36:18,815:INFO:Creating metrics dataframe
2024-03-02 21:36:18,827:INFO:Initializing Extra Trees Classifier
2024-03-02 21:36:18,827:INFO:Total runtime is 0.18230775197347004 minutes
2024-03-02 21:36:18,832:INFO:SubProcess create_model() called ==================================
2024-03-02 21:36:18,832:INFO:Initializing create_model()
2024-03-02 21:36:18,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:36:18,833:INFO:Checking exceptions
2024-03-02 21:36:18,833:INFO:Importing libraries
2024-03-02 21:36:18,833:INFO:Copying training dataset
2024-03-02 21:36:18,858:INFO:Defining folds
2024-03-02 21:36:18,859:INFO:Declaring metric variables
2024-03-02 21:36:18,864:INFO:Importing untrained model
2024-03-02 21:36:18,870:INFO:Extra Trees Classifier Imported successfully
2024-03-02 21:36:18,879:INFO:Starting cross validation
2024-03-02 21:36:18,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:36:26,154:INFO:Calculating mean and std
2024-03-02 21:36:26,156:INFO:Creating metrics dataframe
2024-03-02 21:36:26,160:INFO:Uploading results into container
2024-03-02 21:36:26,161:INFO:Uploading model into container now
2024-03-02 21:36:26,162:INFO:_master_model_container: 2
2024-03-02 21:36:26,163:INFO:_display_container: 2
2024-03-02 21:36:26,163:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 21:36:26,164:INFO:create_model() successfully completed......................................
2024-03-02 21:36:26,327:INFO:SubProcess create_model() end ==================================
2024-03-02 21:36:26,327:INFO:Creating metrics dataframe
2024-03-02 21:36:26,342:INFO:Initializing Extreme Gradient Boosting
2024-03-02 21:36:26,343:INFO:Total runtime is 0.3075612465540568 minutes
2024-03-02 21:36:26,349:INFO:SubProcess create_model() called ==================================
2024-03-02 21:36:26,349:INFO:Initializing create_model()
2024-03-02 21:36:26,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:36:26,349:INFO:Checking exceptions
2024-03-02 21:36:26,350:INFO:Importing libraries
2024-03-02 21:36:26,350:INFO:Copying training dataset
2024-03-02 21:36:26,382:INFO:Defining folds
2024-03-02 21:36:26,382:INFO:Declaring metric variables
2024-03-02 21:36:26,388:INFO:Importing untrained model
2024-03-02 21:36:26,394:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 21:36:26,404:INFO:Starting cross validation
2024-03-02 21:36:26,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:36:41,970:INFO:Calculating mean and std
2024-03-02 21:36:41,972:INFO:Creating metrics dataframe
2024-03-02 21:36:41,975:INFO:Uploading results into container
2024-03-02 21:36:41,976:INFO:Uploading model into container now
2024-03-02 21:36:41,976:INFO:_master_model_container: 3
2024-03-02 21:36:41,977:INFO:_display_container: 2
2024-03-02 21:36:41,978:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-02 21:36:41,978:INFO:create_model() successfully completed......................................
2024-03-02 21:36:42,073:INFO:SubProcess create_model() end ==================================
2024-03-02 21:36:42,073:INFO:Creating metrics dataframe
2024-03-02 21:36:42,083:INFO:Initializing Random Forest Classifier
2024-03-02 21:36:42,083:INFO:Total runtime is 0.5699080069859823 minutes
2024-03-02 21:36:42,088:INFO:SubProcess create_model() called ==================================
2024-03-02 21:36:42,088:INFO:Initializing create_model()
2024-03-02 21:36:42,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:36:42,088:INFO:Checking exceptions
2024-03-02 21:36:42,088:INFO:Importing libraries
2024-03-02 21:36:42,088:INFO:Copying training dataset
2024-03-02 21:36:42,112:INFO:Defining folds
2024-03-02 21:36:42,112:INFO:Declaring metric variables
2024-03-02 21:36:42,115:INFO:Importing untrained model
2024-03-02 21:36:42,122:INFO:Random Forest Classifier Imported successfully
2024-03-02 21:36:42,130:INFO:Starting cross validation
2024-03-02 21:36:42,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:36:56,185:INFO:Calculating mean and std
2024-03-02 21:36:56,187:INFO:Creating metrics dataframe
2024-03-02 21:36:56,189:INFO:Uploading results into container
2024-03-02 21:36:56,189:INFO:Uploading model into container now
2024-03-02 21:36:56,190:INFO:_master_model_container: 4
2024-03-02 21:36:56,190:INFO:_display_container: 2
2024-03-02 21:36:56,191:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 21:36:56,191:INFO:create_model() successfully completed......................................
2024-03-02 21:36:56,299:INFO:SubProcess create_model() end ==================================
2024-03-02 21:36:56,299:INFO:Creating metrics dataframe
2024-03-02 21:36:56,308:INFO:Initializing CatBoost Classifier
2024-03-02 21:36:56,308:INFO:Total runtime is 0.8069901863733928 minutes
2024-03-02 21:36:56,313:INFO:SubProcess create_model() called ==================================
2024-03-02 21:36:56,313:INFO:Initializing create_model()
2024-03-02 21:36:56,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:36:56,313:INFO:Checking exceptions
2024-03-02 21:36:56,313:INFO:Importing libraries
2024-03-02 21:36:56,313:INFO:Copying training dataset
2024-03-02 21:36:56,340:INFO:Defining folds
2024-03-02 21:36:56,340:INFO:Declaring metric variables
2024-03-02 21:36:56,344:INFO:Importing untrained model
2024-03-02 21:36:56,348:INFO:CatBoost Classifier Imported successfully
2024-03-02 21:36:56,355:INFO:Starting cross validation
2024-03-02 21:36:56,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:41:55,478:INFO:Calculating mean and std
2024-03-02 21:41:55,481:INFO:Creating metrics dataframe
2024-03-02 21:41:55,485:INFO:Uploading results into container
2024-03-02 21:41:55,486:INFO:Uploading model into container now
2024-03-02 21:41:55,487:INFO:_master_model_container: 5
2024-03-02 21:41:55,487:INFO:_display_container: 2
2024-03-02 21:41:55,487:INFO:<catboost.core.CatBoostClassifier object at 0x0000026E3C6FFBD0>
2024-03-02 21:41:55,487:INFO:create_model() successfully completed......................................
2024-03-02 21:41:55,626:INFO:SubProcess create_model() end ==================================
2024-03-02 21:41:55,626:INFO:Creating metrics dataframe
2024-03-02 21:41:55,644:INFO:Initializing Light Gradient Boosting Machine
2024-03-02 21:41:55,644:INFO:Total runtime is 5.795908530553183 minutes
2024-03-02 21:41:55,648:INFO:SubProcess create_model() called ==================================
2024-03-02 21:41:55,648:INFO:Initializing create_model()
2024-03-02 21:41:55,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:41:55,648:INFO:Checking exceptions
2024-03-02 21:41:55,648:INFO:Importing libraries
2024-03-02 21:41:55,648:INFO:Copying training dataset
2024-03-02 21:41:55,688:INFO:Defining folds
2024-03-02 21:41:55,689:INFO:Declaring metric variables
2024-03-02 21:41:55,697:INFO:Importing untrained model
2024-03-02 21:41:55,702:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 21:41:55,722:INFO:Starting cross validation
2024-03-02 21:41:55,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:42:11,027:INFO:Calculating mean and std
2024-03-02 21:42:11,027:INFO:Creating metrics dataframe
2024-03-02 21:42:11,034:INFO:Uploading results into container
2024-03-02 21:42:11,036:INFO:Uploading model into container now
2024-03-02 21:42:11,036:INFO:_master_model_container: 6
2024-03-02 21:42:11,036:INFO:_display_container: 2
2024-03-02 21:42:11,036:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 21:42:11,036:INFO:create_model() successfully completed......................................
2024-03-02 21:42:11,180:INFO:SubProcess create_model() end ==================================
2024-03-02 21:42:11,180:INFO:Creating metrics dataframe
2024-03-02 21:42:11,196:INFO:Initializing Gradient Boosting Classifier
2024-03-02 21:42:11,197:INFO:Total runtime is 6.055136386553447 minutes
2024-03-02 21:42:11,202:INFO:SubProcess create_model() called ==================================
2024-03-02 21:42:11,203:INFO:Initializing create_model()
2024-03-02 21:42:11,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E3C4A9350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:42:11,203:INFO:Checking exceptions
2024-03-02 21:42:11,203:INFO:Importing libraries
2024-03-02 21:42:11,203:INFO:Copying training dataset
2024-03-02 21:42:11,243:INFO:Defining folds
2024-03-02 21:42:11,244:INFO:Declaring metric variables
2024-03-02 21:42:11,250:INFO:Importing untrained model
2024-03-02 21:42:11,258:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 21:42:11,272:INFO:Starting cross validation
2024-03-02 21:42:11,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:44:14,844:INFO:Calculating mean and std
2024-03-02 21:44:14,860:INFO:Creating metrics dataframe
2024-03-02 21:44:14,860:INFO:Uploading results into container
2024-03-02 21:44:14,860:INFO:Uploading model into container now
2024-03-02 21:44:14,860:INFO:_master_model_container: 7
2024-03-02 21:44:14,860:INFO:_display_container: 2
2024-03-02 21:44:14,860:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 21:44:14,860:INFO:create_model() successfully completed......................................
2024-03-02 21:44:14,955:INFO:SubProcess create_model() end ==================================
2024-03-02 21:44:14,955:INFO:Creating metrics dataframe
2024-03-02 21:44:14,988:INFO:Initializing create_model()
2024-03-02 21:44:14,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:44:14,988:INFO:Checking exceptions
2024-03-02 21:44:15,007:INFO:Importing libraries
2024-03-02 21:44:15,007:INFO:Copying training dataset
2024-03-02 21:44:15,045:INFO:Defining folds
2024-03-02 21:44:15,045:INFO:Declaring metric variables
2024-03-02 21:44:15,045:INFO:Importing untrained model
2024-03-02 21:44:15,045:INFO:Declaring custom model
2024-03-02 21:44:15,045:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 21:44:15,045:INFO:Cross validation set to False
2024-03-02 21:44:15,045:INFO:Fitting Model
2024-03-02 21:44:52,881:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 21:44:52,881:INFO:create_model() successfully completed......................................
2024-03-02 21:44:53,028:INFO:_master_model_container: 7
2024-03-02 21:44:53,028:INFO:_display_container: 2
2024-03-02 21:44:53,028:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 21:44:53,028:INFO:compare_models() successfully completed......................................
2024-03-02 21:46:21,389:INFO:Initializing create_model()
2024-03-02 21:46:21,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 21:46:21,389:INFO:Checking exceptions
2024-03-02 21:46:21,413:INFO:Importing libraries
2024-03-02 21:46:21,413:INFO:Copying training dataset
2024-03-02 21:46:21,446:INFO:Defining folds
2024-03-02 21:46:21,446:INFO:Declaring metric variables
2024-03-02 21:46:21,475:INFO:Importing untrained model
2024-03-02 21:46:21,482:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 21:46:21,499:INFO:Starting cross validation
2024-03-02 21:46:21,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 21:48:22,731:INFO:Calculating mean and std
2024-03-02 21:48:22,733:INFO:Creating metrics dataframe
2024-03-02 21:48:22,738:INFO:Finalizing model
2024-03-02 21:49:10,464:INFO:Uploading results into container
2024-03-02 21:49:10,467:INFO:Uploading model into container now
2024-03-02 21:49:10,483:INFO:_master_model_container: 8
2024-03-02 21:49:10,484:INFO:_display_container: 3
2024-03-02 21:49:10,484:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 21:49:10,484:INFO:create_model() successfully completed......................................
2024-03-02 21:49:58,498:INFO:Initializing tune_model()
2024-03-02 21:49:58,498:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-03-02 21:49:58,498:INFO:Checking exceptions
2024-03-02 21:49:58,531:INFO:Copying training dataset
2024-03-02 21:49:58,552:INFO:Checking base model
2024-03-02 21:49:58,553:INFO:Base model : Gradient Boosting Classifier
2024-03-02 21:49:58,557:INFO:Declaring metric variables
2024-03-02 21:49:58,561:INFO:Defining Hyperparameters
2024-03-02 21:49:58,787:INFO:Tuning with n_jobs=-1
2024-03-02 21:49:58,787:INFO:Initializing RandomizedSearchCV
2024-03-02 22:06:22,723:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2024-03-02 22:06:22,724:INFO:Hyperparameter search completed
2024-03-02 22:06:22,724:INFO:SubProcess create_model() called ==================================
2024-03-02 22:06:22,725:INFO:Initializing create_model()
2024-03-02 22:06:22,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EA7090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2024-03-02 22:06:22,725:INFO:Checking exceptions
2024-03-02 22:06:22,725:INFO:Importing libraries
2024-03-02 22:06:22,725:INFO:Copying training dataset
2024-03-02 22:06:22,746:INFO:Defining folds
2024-03-02 22:06:22,746:INFO:Declaring metric variables
2024-03-02 22:06:22,749:INFO:Importing untrained model
2024-03-02 22:06:22,749:INFO:Declaring custom model
2024-03-02 22:06:22,753:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 22:06:22,760:INFO:Starting cross validation
2024-03-02 22:06:22,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:07:17,453:INFO:Calculating mean and std
2024-03-02 22:07:17,468:INFO:Creating metrics dataframe
2024-03-02 22:07:17,474:INFO:Finalizing model
2024-03-02 22:07:32,402:INFO:Uploading results into container
2024-03-02 22:07:32,404:INFO:Uploading model into container now
2024-03-02 22:07:32,404:INFO:_master_model_container: 9
2024-03-02 22:07:32,404:INFO:_display_container: 4
2024-03-02 22:07:32,405:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 22:07:32,405:INFO:create_model() successfully completed......................................
2024-03-02 22:07:32,523:INFO:SubProcess create_model() end ==================================
2024-03-02 22:07:32,523:INFO:choose_better activated
2024-03-02 22:07:32,528:INFO:SubProcess create_model() called ==================================
2024-03-02 22:07:32,529:INFO:Initializing create_model()
2024-03-02 22:07:32,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:07:32,529:INFO:Checking exceptions
2024-03-02 22:07:32,531:INFO:Importing libraries
2024-03-02 22:07:32,532:INFO:Copying training dataset
2024-03-02 22:07:32,556:INFO:Defining folds
2024-03-02 22:07:32,556:INFO:Declaring metric variables
2024-03-02 22:07:32,556:INFO:Importing untrained model
2024-03-02 22:07:32,556:INFO:Declaring custom model
2024-03-02 22:07:32,556:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 22:07:32,556:INFO:Starting cross validation
2024-03-02 22:07:32,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:09:33,520:INFO:Calculating mean and std
2024-03-02 22:09:33,520:INFO:Creating metrics dataframe
2024-03-02 22:09:33,520:INFO:Finalizing model
2024-03-02 22:10:10,181:INFO:Uploading results into container
2024-03-02 22:10:10,181:INFO:Uploading model into container now
2024-03-02 22:10:10,181:INFO:_master_model_container: 10
2024-03-02 22:10:10,181:INFO:_display_container: 5
2024-03-02 22:10:10,181:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 22:10:10,181:INFO:create_model() successfully completed......................................
2024-03-02 22:10:10,283:INFO:SubProcess create_model() end ==================================
2024-03-02 22:10:10,285:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8296
2024-03-02 22:10:10,285:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8273
2024-03-02 22:10:10,286:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-03-02 22:10:10,286:INFO:choose_better completed
2024-03-02 22:10:10,286:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-03-02 22:10:10,302:INFO:_master_model_container: 10
2024-03-02 22:10:10,302:INFO:_display_container: 4
2024-03-02 22:10:10,303:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 22:10:10,303:INFO:tune_model() successfully completed......................................
2024-03-02 22:22:33,703:INFO:Initializing predict_model()
2024-03-02 22:22:33,703:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E37D7EA90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026E3C4B1A80>)
2024-03-02 22:22:33,703:INFO:Checking exceptions
2024-03-02 22:22:33,703:INFO:Preloading libraries
2024-03-02 22:22:33,705:INFO:Set up data.
2024-03-02 22:22:33,716:INFO:Set up index.
2024-03-02 22:22:34,073:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\2669236348.py:9: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  submitFile["id"] = testid

2024-03-02 22:22:54,983:INFO:Initializing save_model()
2024-03-02 22:22:54,983:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=../Models/002BasedModel, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-03-02 22:22:54,983:INFO:Adding model into prep_pipe
2024-03-02 22:22:55,019:INFO:../Models/002BasedModel.pkl saved in current working directory
2024-03-02 22:22:55,024:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'TypeOfSteel_A400',
                                             'Steel_Plate_Thickness',
                                             '...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-03-02 22:22:55,024:INFO:save_model() successfully completed......................................
2024-03-02 22:39:10,773:INFO:PyCaret ClassificationExperiment
2024-03-02 22:39:10,773:INFO:Logging name: clf-default-name
2024-03-02 22:39:10,774:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 22:39:10,774:INFO:version 3.3.0
2024-03-02 22:39:10,774:INFO:Initializing setup()
2024-03-02 22:39:10,774:INFO:self.USI: 1f4d
2024-03-02 22:39:10,774:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'y_train', 'fold_generator', 'fold_shuffle_param', 'USI', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'target_param', 'y_test', '_available_plots', 'data', 'seed', 'memory', 'X_train', 'X_test', 'exp_name_log', 'log_plots_param', 'X', 'idx', 'is_multiclass', 'y'}
2024-03-02 22:39:10,774:INFO:Checking environment
2024-03-02 22:39:10,774:INFO:python_version: 3.11.5
2024-03-02 22:39:10,774:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 22:39:10,774:INFO:machine: AMD64
2024-03-02 22:39:10,774:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 22:39:10,774:INFO:Memory: svmem(total=8327905280, available=2485985280, percent=70.1, used=5841920000, free=2485985280)
2024-03-02 22:39:10,775:INFO:Physical Core: 4
2024-03-02 22:39:10,775:INFO:Logical Core: 8
2024-03-02 22:39:10,775:INFO:Checking libraries
2024-03-02 22:39:10,775:INFO:System:
2024-03-02 22:39:10,775:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 22:39:10,775:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 22:39:10,775:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 22:39:10,775:INFO:PyCaret required dependencies:
2024-03-02 22:39:10,775:INFO:                 pip: 23.2.1
2024-03-02 22:39:10,776:INFO:          setuptools: 68.0.0
2024-03-02 22:39:10,776:INFO:             pycaret: 3.3.0
2024-03-02 22:39:10,776:INFO:             IPython: 8.15.0
2024-03-02 22:39:10,776:INFO:          ipywidgets: 8.0.4
2024-03-02 22:39:10,776:INFO:                tqdm: 4.65.0
2024-03-02 22:39:10,776:INFO:               numpy: 1.24.3
2024-03-02 22:39:10,776:INFO:              pandas: 2.0.3
2024-03-02 22:39:10,776:INFO:              jinja2: 3.1.2
2024-03-02 22:39:10,776:INFO:               scipy: 1.11.1
2024-03-02 22:39:10,776:INFO:              joblib: 1.2.0
2024-03-02 22:39:10,776:INFO:             sklearn: 1.4.1.post1
2024-03-02 22:39:10,776:INFO:                pyod: 1.1.3
2024-03-02 22:39:10,777:INFO:            imblearn: 0.12.0
2024-03-02 22:39:10,777:INFO:   category_encoders: 2.6.3
2024-03-02 22:39:10,777:INFO:            lightgbm: 4.3.0
2024-03-02 22:39:10,777:INFO:               numba: 0.57.1
2024-03-02 22:39:10,777:INFO:            requests: 2.31.0
2024-03-02 22:39:10,777:INFO:          matplotlib: 3.7.2
2024-03-02 22:39:10,777:INFO:          scikitplot: 0.3.7
2024-03-02 22:39:10,777:INFO:         yellowbrick: 1.5
2024-03-02 22:39:10,777:INFO:              plotly: 5.19.0
2024-03-02 22:39:10,777:INFO:    plotly-resampler: Not installed
2024-03-02 22:39:10,777:INFO:             kaleido: 0.2.1
2024-03-02 22:39:10,777:INFO:           schemdraw: 0.15
2024-03-02 22:39:10,777:INFO:         statsmodels: 0.14.0
2024-03-02 22:39:10,778:INFO:              sktime: 0.26.1
2024-03-02 22:39:10,778:INFO:               tbats: 1.1.3
2024-03-02 22:39:10,778:INFO:            pmdarima: 2.0.4
2024-03-02 22:39:10,778:INFO:              psutil: 5.9.0
2024-03-02 22:39:10,778:INFO:          markupsafe: 2.1.1
2024-03-02 22:39:10,778:INFO:             pickle5: Not installed
2024-03-02 22:39:10,778:INFO:         cloudpickle: 2.2.1
2024-03-02 22:39:10,778:INFO:         deprecation: 2.1.0
2024-03-02 22:39:10,778:INFO:              xxhash: 2.0.2
2024-03-02 22:39:10,778:INFO:           wurlitzer: Not installed
2024-03-02 22:39:10,778:INFO:PyCaret optional dependencies:
2024-03-02 22:39:10,779:INFO:                shap: 0.44.1
2024-03-02 22:39:10,779:INFO:           interpret: Not installed
2024-03-02 22:39:10,779:INFO:                umap: Not installed
2024-03-02 22:39:10,779:INFO:     ydata_profiling: Not installed
2024-03-02 22:39:10,779:INFO:  explainerdashboard: Not installed
2024-03-02 22:39:10,779:INFO:             autoviz: Not installed
2024-03-02 22:39:10,779:INFO:           fairlearn: Not installed
2024-03-02 22:39:10,779:INFO:          deepchecks: Not installed
2024-03-02 22:39:10,779:INFO:             xgboost: 2.0.3
2024-03-02 22:39:10,779:INFO:            catboost: 1.2.2
2024-03-02 22:39:10,779:INFO:              kmodes: Not installed
2024-03-02 22:39:10,779:INFO:             mlxtend: Not installed
2024-03-02 22:39:10,779:INFO:       statsforecast: Not installed
2024-03-02 22:39:10,779:INFO:        tune_sklearn: Not installed
2024-03-02 22:39:10,779:INFO:                 ray: Not installed
2024-03-02 22:39:10,779:INFO:            hyperopt: Not installed
2024-03-02 22:39:10,779:INFO:              optuna: 3.5.0
2024-03-02 22:39:10,780:INFO:               skopt: Not installed
2024-03-02 22:39:10,780:INFO:              mlflow: Not installed
2024-03-02 22:39:10,780:INFO:              gradio: Not installed
2024-03-02 22:39:10,780:INFO:             fastapi: Not installed
2024-03-02 22:39:10,780:INFO:             uvicorn: Not installed
2024-03-02 22:39:10,780:INFO:              m2cgen: Not installed
2024-03-02 22:39:10,780:INFO:           evidently: Not installed
2024-03-02 22:39:10,780:INFO:               fugue: Not installed
2024-03-02 22:39:10,780:INFO:           streamlit: Not installed
2024-03-02 22:39:10,780:INFO:             prophet: Not installed
2024-03-02 22:39:10,780:INFO:None
2024-03-02 22:39:10,780:INFO:Set up data.
2024-03-02 22:39:10,799:INFO:Set up folding strategy.
2024-03-02 22:39:10,799:INFO:Set up train/test split.
2024-03-02 22:39:10,812:INFO:Set up index.
2024-03-02 22:39:10,812:INFO:Assigning column types.
2024-03-02 22:39:10,828:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 22:39:10,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 22:39:10,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 22:39:10,903:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:10,906:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:10,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 22:39:10,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 22:39:10,974:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:10,990:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:10,991:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 22:39:11,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 22:39:11,059:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:11,074:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:11,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 22:39:11,144:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:11,144:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:11,144:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 22:39:11,208:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:11,208:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:11,274:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:11,274:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:11,291:INFO:Preparing preprocessing pipeline...
2024-03-02 22:39:11,291:INFO:Set up simple imputation.
2024-03-02 22:39:11,291:INFO:Set up encoding of ordinal features.
2024-03-02 22:39:11,309:INFO:Set up encoding of categorical features.
2024-03-02 22:39:11,309:INFO:Set up removing outliers.
2024-03-02 22:39:11,309:INFO:Set up imbalanced handling.
2024-03-02 22:39:11,309:INFO:Set up column transformation.
2024-03-02 22:39:13,283:INFO:Finished creating preprocessing pipeline.
2024-03-02 22:39:13,323:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'Steel_Plate_Thickness...
                                                               random_state=123,
                                                               threshold=0.05))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2024-03-02 22:39:13,323:INFO:Creating final display dataframe.
2024-03-02 22:39:15,491:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (36125, 30)
5   Transformed train set shape       (30611, 30)
6    Transformed test set shape        (5514, 30)
7              Numeric features                24
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Transformation              True
20        Transformation method       yeo-johnson
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              1f4d
2024-03-02 22:39:15,591:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:15,593:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:15,658:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 22:39:15,658:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 22:39:15,658:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 22:39:15,658:INFO:setup() successfully completed in 4.97s...............
2024-03-02 22:39:39,524:INFO:Initializing compare_models()
2024-03-02 22:39:39,524:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, include=['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, 'include': ['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 22:39:39,525:INFO:Checking exceptions
2024-03-02 22:39:39,546:INFO:Preparing display monitor
2024-03-02 22:39:39,579:INFO:Initializing Linear Discriminant Analysis
2024-03-02 22:39:39,580:INFO:Total runtime is 1.6780694325764976e-05 minutes
2024-03-02 22:39:39,583:INFO:SubProcess create_model() called ==================================
2024-03-02 22:39:39,583:INFO:Initializing create_model()
2024-03-02 22:39:39,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:39:39,584:INFO:Checking exceptions
2024-03-02 22:39:39,584:INFO:Importing libraries
2024-03-02 22:39:39,584:INFO:Copying training dataset
2024-03-02 22:39:39,615:INFO:Defining folds
2024-03-02 22:39:39,615:INFO:Declaring metric variables
2024-03-02 22:39:39,618:INFO:Importing untrained model
2024-03-02 22:39:39,622:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 22:39:39,630:INFO:Starting cross validation
2024-03-02 22:39:39,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:39:54,100:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,121:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,158:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,168:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,176:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,224:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,267:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:54,356:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:56,488:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:56,492:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:39:56,505:INFO:Calculating mean and std
2024-03-02 22:39:56,507:INFO:Creating metrics dataframe
2024-03-02 22:39:56,509:INFO:Uploading results into container
2024-03-02 22:39:56,509:INFO:Uploading model into container now
2024-03-02 22:39:56,509:INFO:_master_model_container: 1
2024-03-02 22:39:56,510:INFO:_display_container: 2
2024-03-02 22:39:56,510:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 22:39:56,510:INFO:create_model() successfully completed......................................
2024-03-02 22:39:56,669:INFO:SubProcess create_model() end ==================================
2024-03-02 22:39:56,669:INFO:Creating metrics dataframe
2024-03-02 22:39:56,691:INFO:Initializing Extra Trees Classifier
2024-03-02 22:39:56,691:INFO:Total runtime is 0.28520652453104656 minutes
2024-03-02 22:39:56,695:INFO:SubProcess create_model() called ==================================
2024-03-02 22:39:56,696:INFO:Initializing create_model()
2024-03-02 22:39:56,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:39:56,696:INFO:Checking exceptions
2024-03-02 22:39:56,696:INFO:Importing libraries
2024-03-02 22:39:56,697:INFO:Copying training dataset
2024-03-02 22:39:56,721:INFO:Defining folds
2024-03-02 22:39:56,721:INFO:Declaring metric variables
2024-03-02 22:39:56,725:INFO:Importing untrained model
2024-03-02 22:39:56,728:INFO:Extra Trees Classifier Imported successfully
2024-03-02 22:39:56,737:INFO:Starting cross validation
2024-03-02 22:39:56,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:40:12,728:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:12,731:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:12,986:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:12,992:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:13,039:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:13,084:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:13,161:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:13,201:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:17,933:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:18,047:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:18,064:INFO:Calculating mean and std
2024-03-02 22:40:18,067:INFO:Creating metrics dataframe
2024-03-02 22:40:18,069:INFO:Uploading results into container
2024-03-02 22:40:18,070:INFO:Uploading model into container now
2024-03-02 22:40:18,070:INFO:_master_model_container: 2
2024-03-02 22:40:18,070:INFO:_display_container: 2
2024-03-02 22:40:18,071:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 22:40:18,071:INFO:create_model() successfully completed......................................
2024-03-02 22:40:18,272:INFO:SubProcess create_model() end ==================================
2024-03-02 22:40:18,272:INFO:Creating metrics dataframe
2024-03-02 22:40:18,288:INFO:Initializing Extreme Gradient Boosting
2024-03-02 22:40:18,288:INFO:Total runtime is 0.6451505184173585 minutes
2024-03-02 22:40:18,294:INFO:SubProcess create_model() called ==================================
2024-03-02 22:40:18,295:INFO:Initializing create_model()
2024-03-02 22:40:18,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:40:18,295:INFO:Checking exceptions
2024-03-02 22:40:18,295:INFO:Importing libraries
2024-03-02 22:40:18,295:INFO:Copying training dataset
2024-03-02 22:40:18,323:INFO:Defining folds
2024-03-02 22:40:18,323:INFO:Declaring metric variables
2024-03-02 22:40:18,326:INFO:Importing untrained model
2024-03-02 22:40:18,332:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 22:40:18,342:INFO:Starting cross validation
2024-03-02 22:40:18,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:40:42,553:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:42,675:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:42,734:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:42,797:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:42,854:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:42,914:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:43,153:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:43,164:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:54,298:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:54,382:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:40:54,394:INFO:Calculating mean and std
2024-03-02 22:40:54,399:INFO:Creating metrics dataframe
2024-03-02 22:40:54,402:INFO:Uploading results into container
2024-03-02 22:40:54,402:INFO:Uploading model into container now
2024-03-02 22:40:54,403:INFO:_master_model_container: 3
2024-03-02 22:40:54,403:INFO:_display_container: 2
2024-03-02 22:40:54,404:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-02 22:40:54,404:INFO:create_model() successfully completed......................................
2024-03-02 22:40:54,574:INFO:SubProcess create_model() end ==================================
2024-03-02 22:40:54,574:INFO:Creating metrics dataframe
2024-03-02 22:40:54,588:INFO:Initializing Random Forest Classifier
2024-03-02 22:40:54,588:INFO:Total runtime is 1.2501506090164185 minutes
2024-03-02 22:40:54,592:INFO:SubProcess create_model() called ==================================
2024-03-02 22:40:54,593:INFO:Initializing create_model()
2024-03-02 22:40:54,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:40:54,594:INFO:Checking exceptions
2024-03-02 22:40:54,594:INFO:Importing libraries
2024-03-02 22:40:54,594:INFO:Copying training dataset
2024-03-02 22:40:54,623:INFO:Defining folds
2024-03-02 22:40:54,623:INFO:Declaring metric variables
2024-03-02 22:40:54,626:INFO:Importing untrained model
2024-03-02 22:40:54,632:INFO:Random Forest Classifier Imported successfully
2024-03-02 22:40:54,641:INFO:Starting cross validation
2024-03-02 22:40:54,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:41:40,323:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,444:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,918:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,926:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,929:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,929:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:40,999:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:41,306:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:54,003:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:54,005:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:41:54,026:INFO:Calculating mean and std
2024-03-02 22:41:54,033:INFO:Creating metrics dataframe
2024-03-02 22:41:54,037:INFO:Uploading results into container
2024-03-02 22:41:54,039:INFO:Uploading model into container now
2024-03-02 22:41:54,039:INFO:_master_model_container: 4
2024-03-02 22:41:54,040:INFO:_display_container: 2
2024-03-02 22:41:54,040:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 22:41:54,040:INFO:create_model() successfully completed......................................
2024-03-02 22:41:54,227:INFO:SubProcess create_model() end ==================================
2024-03-02 22:41:54,227:INFO:Creating metrics dataframe
2024-03-02 22:41:54,240:INFO:Initializing CatBoost Classifier
2024-03-02 22:41:54,240:INFO:Total runtime is 2.2443562865257265 minutes
2024-03-02 22:41:54,244:INFO:SubProcess create_model() called ==================================
2024-03-02 22:41:54,245:INFO:Initializing create_model()
2024-03-02 22:41:54,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:41:54,245:INFO:Checking exceptions
2024-03-02 22:41:54,245:INFO:Importing libraries
2024-03-02 22:41:54,245:INFO:Copying training dataset
2024-03-02 22:41:54,275:INFO:Defining folds
2024-03-02 22:41:54,275:INFO:Declaring metric variables
2024-03-02 22:41:54,280:INFO:Importing untrained model
2024-03-02 22:41:54,285:INFO:CatBoost Classifier Imported successfully
2024-03-02 22:41:54,298:INFO:Starting cross validation
2024-03-02 22:41:54,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:47:52,001:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:47:59,559:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:07,794:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:08,485:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:10,806:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:11,305:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:11,925:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:48:12,929:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:49:45,423:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:49:46,652:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:49:46,675:INFO:Calculating mean and std
2024-03-02 22:49:46,679:INFO:Creating metrics dataframe
2024-03-02 22:49:46,683:INFO:Uploading results into container
2024-03-02 22:49:46,684:INFO:Uploading model into container now
2024-03-02 22:49:46,685:INFO:_master_model_container: 5
2024-03-02 22:49:46,685:INFO:_display_container: 2
2024-03-02 22:49:46,685:INFO:<catboost.core.CatBoostClassifier object at 0x0000026E4180CE90>
2024-03-02 22:49:46,685:INFO:create_model() successfully completed......................................
2024-03-02 22:49:46,926:INFO:SubProcess create_model() end ==================================
2024-03-02 22:49:46,926:INFO:Creating metrics dataframe
2024-03-02 22:49:46,948:INFO:Initializing Light Gradient Boosting Machine
2024-03-02 22:49:46,948:INFO:Total runtime is 10.122825475533803 minutes
2024-03-02 22:49:46,957:INFO:SubProcess create_model() called ==================================
2024-03-02 22:49:46,958:INFO:Initializing create_model()
2024-03-02 22:49:46,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:49:46,958:INFO:Checking exceptions
2024-03-02 22:49:46,958:INFO:Importing libraries
2024-03-02 22:49:46,959:INFO:Copying training dataset
2024-03-02 22:49:47,013:INFO:Defining folds
2024-03-02 22:49:47,014:INFO:Declaring metric variables
2024-03-02 22:49:47,022:INFO:Importing untrained model
2024-03-02 22:49:47,032:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 22:49:47,051:INFO:Starting cross validation
2024-03-02 22:49:47,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:50:13,404:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:14,598:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:14,701:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:15,555:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:15,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:16,178:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:16,288:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:17,467:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:23,329:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:23,957:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:50:23,989:INFO:Calculating mean and std
2024-03-02 22:50:23,997:INFO:Creating metrics dataframe
2024-03-02 22:50:24,003:INFO:Uploading results into container
2024-03-02 22:50:24,004:INFO:Uploading model into container now
2024-03-02 22:50:24,004:INFO:_master_model_container: 6
2024-03-02 22:50:24,004:INFO:_display_container: 2
2024-03-02 22:50:24,007:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 22:50:24,007:INFO:create_model() successfully completed......................................
2024-03-02 22:50:24,191:INFO:SubProcess create_model() end ==================================
2024-03-02 22:50:24,191:INFO:Creating metrics dataframe
2024-03-02 22:50:24,205:INFO:Initializing Gradient Boosting Classifier
2024-03-02 22:50:24,205:INFO:Total runtime is 10.743777990341187 minutes
2024-03-02 22:50:24,209:INFO:SubProcess create_model() called ==================================
2024-03-02 22:50:24,210:INFO:Initializing create_model()
2024-03-02 22:50:24,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:50:24,210:INFO:Checking exceptions
2024-03-02 22:50:24,210:INFO:Importing libraries
2024-03-02 22:50:24,211:INFO:Copying training dataset
2024-03-02 22:50:24,239:INFO:Defining folds
2024-03-02 22:50:24,239:INFO:Declaring metric variables
2024-03-02 22:50:24,244:INFO:Importing untrained model
2024-03-02 22:50:24,249:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 22:50:24,259:INFO:Starting cross validation
2024-03-02 22:50:24,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 22:56:38,675:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:43,780:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:43,790:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:44,325:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:44,880:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:45,906:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:47,761:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:56:49,523:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:59:49,426:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:59:51,892:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 22:59:51,911:INFO:Calculating mean and std
2024-03-02 22:59:51,916:INFO:Creating metrics dataframe
2024-03-02 22:59:51,918:INFO:Uploading results into container
2024-03-02 22:59:51,918:INFO:Uploading model into container now
2024-03-02 22:59:51,918:INFO:_master_model_container: 7
2024-03-02 22:59:51,918:INFO:_display_container: 2
2024-03-02 22:59:51,919:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 22:59:51,920:INFO:create_model() successfully completed......................................
2024-03-02 22:59:52,102:INFO:SubProcess create_model() end ==================================
2024-03-02 22:59:52,102:INFO:Creating metrics dataframe
2024-03-02 22:59:52,133:INFO:Initializing create_model()
2024-03-02 22:59:52,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 22:59:52,134:INFO:Checking exceptions
2024-03-02 22:59:52,136:INFO:Importing libraries
2024-03-02 22:59:52,136:INFO:Copying training dataset
2024-03-02 22:59:52,159:INFO:Defining folds
2024-03-02 22:59:52,159:INFO:Declaring metric variables
2024-03-02 22:59:52,160:INFO:Importing untrained model
2024-03-02 22:59:52,160:INFO:Declaring custom model
2024-03-02 22:59:52,160:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 22:59:52,173:INFO:Cross validation set to False
2024-03-02 22:59:52,173:INFO:Fitting Model
2024-03-02 22:59:54,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003590 seconds.
2024-03-02 22:59:54,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-02 22:59:54,151:INFO:[LightGBM] [Info] Total Bins 7140
2024-03-02 22:59:54,153:INFO:[LightGBM] [Info] Number of data points in the train set: 30611, number of used features: 28
2024-03-02 22:59:54,155:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,155:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,155:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,155:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,156:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,156:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:54,156:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 22:59:56,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 22:59:56,599:INFO:create_model() successfully completed......................................
2024-03-02 22:59:56,846:INFO:_master_model_container: 7
2024-03-02 22:59:56,846:INFO:_display_container: 2
2024-03-02 22:59:56,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 22:59:56,847:INFO:compare_models() successfully completed......................................
2024-03-02 23:06:06,490:INFO:Initializing create_model()
2024-03-02 23:06:06,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:06:06,490:INFO:Checking exceptions
2024-03-02 23:06:06,510:INFO:Importing libraries
2024-03-02 23:06:06,510:INFO:Copying training dataset
2024-03-02 23:06:06,544:INFO:Defining folds
2024-03-02 23:06:06,544:INFO:Declaring metric variables
2024-03-02 23:06:06,550:INFO:Importing untrained model
2024-03-02 23:06:06,554:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 23:06:06,561:INFO:Starting cross validation
2024-03-02 23:06:06,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:06:35,059:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:35,196:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:35,253:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:36,274:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:36,309:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:36,339:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:36,822:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:37,477:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:42,867:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:43,027:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:06:43,058:INFO:Calculating mean and std
2024-03-02 23:06:43,061:INFO:Creating metrics dataframe
2024-03-02 23:06:43,073:INFO:Finalizing model
2024-03-02 23:06:45,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004301 seconds.
2024-03-02 23:06:45,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-02 23:06:45,136:INFO:[LightGBM] [Info] Total Bins 7140
2024-03-02 23:06:45,136:INFO:[LightGBM] [Info] Number of data points in the train set: 30611, number of used features: 28
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:45,138:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:06:47,251:INFO:Uploading results into container
2024-03-02 23:06:47,254:INFO:Uploading model into container now
2024-03-02 23:06:47,274:INFO:_master_model_container: 8
2024-03-02 23:06:47,274:INFO:_display_container: 3
2024-03-02 23:06:47,274:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:06:47,274:INFO:create_model() successfully completed......................................
2024-03-02 23:07:48,673:INFO:Initializing tune_model()
2024-03-02 23:07:48,673:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-03-02 23:07:48,673:INFO:Checking exceptions
2024-03-02 23:07:48,738:INFO:Copying training dataset
2024-03-02 23:07:48,760:INFO:Checking base model
2024-03-02 23:07:48,761:INFO:Base model : Light Gradient Boosting Machine
2024-03-02 23:07:48,767:INFO:Declaring metric variables
2024-03-02 23:07:48,774:INFO:Defining Hyperparameters
2024-03-02 23:07:49,000:INFO:Tuning with n_jobs=-1
2024-03-02 23:07:49,000:INFO:Initializing RandomizedSearchCV
2024-03-02 23:14:29,953:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2024-03-02 23:14:29,955:INFO:Hyperparameter search completed
2024-03-02 23:14:29,956:INFO:SubProcess create_model() called ==================================
2024-03-02 23:14:29,957:INFO:Initializing create_model()
2024-03-02 23:14:29,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E2F53F090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2024-03-02 23:14:29,958:INFO:Checking exceptions
2024-03-02 23:14:29,958:INFO:Importing libraries
2024-03-02 23:14:29,958:INFO:Copying training dataset
2024-03-02 23:14:30,013:INFO:Defining folds
2024-03-02 23:14:30,014:INFO:Declaring metric variables
2024-03-02 23:14:30,022:INFO:Importing untrained model
2024-03-02 23:14:30,022:INFO:Declaring custom model
2024-03-02 23:14:30,034:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 23:14:30,050:INFO:Starting cross validation
2024-03-02 23:14:30,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:14:51,842:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:51,988:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:52,025:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:52,318:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:52,450:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:52,838:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:52,993:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:53,186:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:59,467:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:59,910:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:14:59,949:INFO:Calculating mean and std
2024-03-02 23:14:59,949:INFO:Creating metrics dataframe
2024-03-02 23:14:59,969:INFO:Finalizing model
2024-03-02 23:15:02,308:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-03-02 23:15:02,308:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-03-02 23:15:02,308:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-03-02 23:15:02,359:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-03-02 23:15:02,359:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-03-02 23:15:02,359:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-03-02 23:15:02,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004139 seconds.
2024-03-02 23:15:02,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-02 23:15:02,361:INFO:[LightGBM] [Info] Total Bins 7140
2024-03-02 23:15:02,361:INFO:[LightGBM] [Info] Number of data points in the train set: 30611, number of used features: 28
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:02,367:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:04,902:INFO:Uploading results into container
2024-03-02 23:15:04,904:INFO:Uploading model into container now
2024-03-02 23:15:04,904:INFO:_master_model_container: 9
2024-03-02 23:15:04,908:INFO:_display_container: 4
2024-03-02 23:15:04,910:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:15:04,910:INFO:create_model() successfully completed......................................
2024-03-02 23:15:05,139:INFO:SubProcess create_model() end ==================================
2024-03-02 23:15:05,139:INFO:choose_better activated
2024-03-02 23:15:05,148:INFO:SubProcess create_model() called ==================================
2024-03-02 23:15:05,149:INFO:Initializing create_model()
2024-03-02 23:15:05,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3E5EAC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:15:05,149:INFO:Checking exceptions
2024-03-02 23:15:05,152:INFO:Importing libraries
2024-03-02 23:15:05,153:INFO:Copying training dataset
2024-03-02 23:15:05,182:INFO:Defining folds
2024-03-02 23:15:05,182:INFO:Declaring metric variables
2024-03-02 23:15:05,182:INFO:Importing untrained model
2024-03-02 23:15:05,182:INFO:Declaring custom model
2024-03-02 23:15:05,189:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 23:15:05,190:INFO:Starting cross validation
2024-03-02 23:15:05,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:15:29,588:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:30,047:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:30,240:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:30,579:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:31,018:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:31,157:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:31,299:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:32,339:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:38,609:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:39,012:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:15:39,049:INFO:Calculating mean and std
2024-03-02 23:15:39,049:INFO:Creating metrics dataframe
2024-03-02 23:15:39,053:INFO:Finalizing model
2024-03-02 23:15:41,269:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004564 seconds.
2024-03-02 23:15:41,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-02 23:15:41,277:INFO:[LightGBM] [Info] Total Bins 7140
2024-03-02 23:15:41,277:INFO:[LightGBM] [Info] Number of data points in the train set: 30611, number of used features: 28
2024-03-02 23:15:41,278:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,278:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,278:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,279:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,279:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,279:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:41,279:INFO:[LightGBM] [Info] Start training from score -1.945910
2024-03-02 23:15:43,738:INFO:Uploading results into container
2024-03-02 23:15:43,738:INFO:Uploading model into container now
2024-03-02 23:15:43,738:INFO:_master_model_container: 10
2024-03-02 23:15:43,738:INFO:_display_container: 5
2024-03-02 23:15:43,738:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:15:43,738:INFO:create_model() successfully completed......................................
2024-03-02 23:15:43,953:INFO:SubProcess create_model() end ==================================
2024-03-02 23:15:43,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.0
2024-03-02 23:15:43,954:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.0
2024-03-02 23:15:43,954:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-03-02 23:15:43,954:INFO:choose_better completed
2024-03-02 23:15:43,954:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-03-02 23:15:43,973:INFO:_master_model_container: 10
2024-03-02 23:15:43,974:INFO:_display_container: 4
2024-03-02 23:15:43,974:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:15:43,975:INFO:tune_model() successfully completed......................................
2024-03-02 23:22:33,716:INFO:PyCaret ClassificationExperiment
2024-03-02 23:22:33,716:INFO:Logging name: clf-default-name
2024-03-02 23:22:33,716:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 23:22:33,716:INFO:version 3.3.0
2024-03-02 23:22:33,716:INFO:Initializing setup()
2024-03-02 23:22:33,718:INFO:self.USI: 3e51
2024-03-02 23:22:33,718:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'y_train', 'fold_generator', 'fold_shuffle_param', 'USI', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'target_param', 'y_test', '_available_plots', 'data', 'seed', 'memory', 'X_train', 'X_test', 'exp_name_log', 'log_plots_param', 'X', 'idx', 'is_multiclass', 'y'}
2024-03-02 23:22:33,718:INFO:Checking environment
2024-03-02 23:22:33,718:INFO:python_version: 3.11.5
2024-03-02 23:22:33,718:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 23:22:33,718:INFO:machine: AMD64
2024-03-02 23:22:33,718:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 23:22:33,718:INFO:Memory: svmem(total=8327905280, available=3368787968, percent=59.5, used=4959117312, free=3368787968)
2024-03-02 23:22:33,718:INFO:Physical Core: 4
2024-03-02 23:22:33,718:INFO:Logical Core: 8
2024-03-02 23:22:33,718:INFO:Checking libraries
2024-03-02 23:22:33,718:INFO:System:
2024-03-02 23:22:33,718:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 23:22:33,718:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 23:22:33,718:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 23:22:33,718:INFO:PyCaret required dependencies:
2024-03-02 23:22:33,718:INFO:                 pip: 23.2.1
2024-03-02 23:22:33,719:INFO:          setuptools: 68.0.0
2024-03-02 23:22:33,719:INFO:             pycaret: 3.3.0
2024-03-02 23:22:33,719:INFO:             IPython: 8.15.0
2024-03-02 23:22:33,719:INFO:          ipywidgets: 8.0.4
2024-03-02 23:22:33,719:INFO:                tqdm: 4.65.0
2024-03-02 23:22:33,719:INFO:               numpy: 1.24.3
2024-03-02 23:22:33,719:INFO:              pandas: 2.0.3
2024-03-02 23:22:33,719:INFO:              jinja2: 3.1.2
2024-03-02 23:22:33,719:INFO:               scipy: 1.11.1
2024-03-02 23:22:33,719:INFO:              joblib: 1.2.0
2024-03-02 23:22:33,719:INFO:             sklearn: 1.4.1.post1
2024-03-02 23:22:33,719:INFO:                pyod: 1.1.3
2024-03-02 23:22:33,719:INFO:            imblearn: 0.12.0
2024-03-02 23:22:33,719:INFO:   category_encoders: 2.6.3
2024-03-02 23:22:33,719:INFO:            lightgbm: 4.3.0
2024-03-02 23:22:33,719:INFO:               numba: 0.57.1
2024-03-02 23:22:33,719:INFO:            requests: 2.31.0
2024-03-02 23:22:33,719:INFO:          matplotlib: 3.7.2
2024-03-02 23:22:33,719:INFO:          scikitplot: 0.3.7
2024-03-02 23:22:33,719:INFO:         yellowbrick: 1.5
2024-03-02 23:22:33,719:INFO:              plotly: 5.19.0
2024-03-02 23:22:33,719:INFO:    plotly-resampler: Not installed
2024-03-02 23:22:33,719:INFO:             kaleido: 0.2.1
2024-03-02 23:22:33,719:INFO:           schemdraw: 0.15
2024-03-02 23:22:33,719:INFO:         statsmodels: 0.14.0
2024-03-02 23:22:33,719:INFO:              sktime: 0.26.1
2024-03-02 23:22:33,719:INFO:               tbats: 1.1.3
2024-03-02 23:22:33,719:INFO:            pmdarima: 2.0.4
2024-03-02 23:22:33,719:INFO:              psutil: 5.9.0
2024-03-02 23:22:33,719:INFO:          markupsafe: 2.1.1
2024-03-02 23:22:33,719:INFO:             pickle5: Not installed
2024-03-02 23:22:33,719:INFO:         cloudpickle: 2.2.1
2024-03-02 23:22:33,719:INFO:         deprecation: 2.1.0
2024-03-02 23:22:33,719:INFO:              xxhash: 2.0.2
2024-03-02 23:22:33,719:INFO:           wurlitzer: Not installed
2024-03-02 23:22:33,719:INFO:PyCaret optional dependencies:
2024-03-02 23:22:33,719:INFO:                shap: 0.44.1
2024-03-02 23:22:33,719:INFO:           interpret: Not installed
2024-03-02 23:22:33,719:INFO:                umap: Not installed
2024-03-02 23:22:33,719:INFO:     ydata_profiling: Not installed
2024-03-02 23:22:33,719:INFO:  explainerdashboard: Not installed
2024-03-02 23:22:33,719:INFO:             autoviz: Not installed
2024-03-02 23:22:33,719:INFO:           fairlearn: Not installed
2024-03-02 23:22:33,719:INFO:          deepchecks: Not installed
2024-03-02 23:22:33,719:INFO:             xgboost: 2.0.3
2024-03-02 23:22:33,719:INFO:            catboost: 1.2.2
2024-03-02 23:22:33,719:INFO:              kmodes: Not installed
2024-03-02 23:22:33,719:INFO:             mlxtend: Not installed
2024-03-02 23:22:33,719:INFO:       statsforecast: Not installed
2024-03-02 23:22:33,719:INFO:        tune_sklearn: Not installed
2024-03-02 23:22:33,719:INFO:                 ray: Not installed
2024-03-02 23:22:33,719:INFO:            hyperopt: Not installed
2024-03-02 23:22:33,719:INFO:              optuna: 3.5.0
2024-03-02 23:22:33,719:INFO:               skopt: Not installed
2024-03-02 23:22:33,719:INFO:              mlflow: Not installed
2024-03-02 23:22:33,719:INFO:              gradio: Not installed
2024-03-02 23:22:33,719:INFO:             fastapi: Not installed
2024-03-02 23:22:33,719:INFO:             uvicorn: Not installed
2024-03-02 23:22:33,719:INFO:              m2cgen: Not installed
2024-03-02 23:22:33,719:INFO:           evidently: Not installed
2024-03-02 23:22:33,719:INFO:               fugue: Not installed
2024-03-02 23:22:33,719:INFO:           streamlit: Not installed
2024-03-02 23:22:33,719:INFO:             prophet: Not installed
2024-03-02 23:22:33,719:INFO:None
2024-03-02 23:22:33,719:INFO:Set up data.
2024-03-02 23:22:33,859:INFO:Set up folding strategy.
2024-03-02 23:22:33,859:INFO:Set up train/test split.
2024-03-02 23:22:33,882:INFO:Set up index.
2024-03-02 23:22:33,883:INFO:Assigning column types.
2024-03-02 23:22:33,895:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 23:22:33,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:22:33,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:22:33,958:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:33,958:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:22:34,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:22:34,040:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:34,042:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,042:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 23:22:34,085:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:22:34,111:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:34,111:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:22:34,193:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:34,193:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,193:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 23:22:34,260:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:34,260:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,327:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:34,327:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:34,327:INFO:Preparing preprocessing pipeline...
2024-03-02 23:22:34,341:INFO:Set up simple imputation.
2024-03-02 23:22:34,343:INFO:Set up encoding of ordinal features.
2024-03-02 23:22:34,359:INFO:Set up encoding of categorical features.
2024-03-02 23:22:34,359:INFO:Set up removing outliers.
2024-03-02 23:22:34,359:INFO:Set up column transformation.
2024-03-02 23:22:34,934:INFO:Finished creating preprocessing pipeline.
2024-03-02 23:22:34,958:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'Steel_Plate_Thickness...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2024-03-02 23:22:34,958:INFO:Creating final display dataframe.
2024-03-02 23:22:35,528:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 30)
5   Transformed train set shape       (12222, 30)
6    Transformed test set shape        (5514, 30)
7              Numeric features                24
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17               Transformation              True
18        Transformation method       yeo-johnson
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              3e51
2024-03-02 23:22:35,604:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:35,609:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:35,698:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:22:35,701:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:22:35,702:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 23:22:35,702:INFO:setup() successfully completed in 2.16s...............
2024-03-02 23:23:06,215:INFO:Initializing compare_models()
2024-03-02 23:23:06,215:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, include=['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, 'include': ['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 23:23:06,215:INFO:Checking exceptions
2024-03-02 23:23:06,232:INFO:Preparing display monitor
2024-03-02 23:23:06,257:INFO:Initializing Linear Discriminant Analysis
2024-03-02 23:23:06,257:INFO:Total runtime is 0.0 minutes
2024-03-02 23:23:06,260:INFO:SubProcess create_model() called ==================================
2024-03-02 23:23:06,260:INFO:Initializing create_model()
2024-03-02 23:23:06,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:23:06,261:INFO:Checking exceptions
2024-03-02 23:23:06,261:INFO:Importing libraries
2024-03-02 23:23:06,261:INFO:Copying training dataset
2024-03-02 23:23:06,287:INFO:Defining folds
2024-03-02 23:23:06,287:INFO:Declaring metric variables
2024-03-02 23:23:06,293:INFO:Importing untrained model
2024-03-02 23:23:06,297:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 23:23:06,305:INFO:Starting cross validation
2024-03-02 23:23:06,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:23:17,923:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:17,944:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:17,948:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:17,962:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:17,986:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:17,999:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:18,002:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:18,005:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:19,224:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:19,252:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:19,254:INFO:Calculating mean and std
2024-03-02 23:23:19,267:INFO:Creating metrics dataframe
2024-03-02 23:23:19,269:INFO:Uploading results into container
2024-03-02 23:23:19,270:INFO:Uploading model into container now
2024-03-02 23:23:19,271:INFO:_master_model_container: 1
2024-03-02 23:23:19,271:INFO:_display_container: 2
2024-03-02 23:23:19,271:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 23:23:19,271:INFO:create_model() successfully completed......................................
2024-03-02 23:23:19,439:INFO:SubProcess create_model() end ==================================
2024-03-02 23:23:19,439:INFO:Creating metrics dataframe
2024-03-02 23:23:19,449:INFO:Initializing Extra Trees Classifier
2024-03-02 23:23:19,450:INFO:Total runtime is 0.2198816696802775 minutes
2024-03-02 23:23:19,456:INFO:SubProcess create_model() called ==================================
2024-03-02 23:23:19,456:INFO:Initializing create_model()
2024-03-02 23:23:19,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:23:19,457:INFO:Checking exceptions
2024-03-02 23:23:19,457:INFO:Importing libraries
2024-03-02 23:23:19,457:INFO:Copying training dataset
2024-03-02 23:23:19,481:INFO:Defining folds
2024-03-02 23:23:19,481:INFO:Declaring metric variables
2024-03-02 23:23:19,485:INFO:Importing untrained model
2024-03-02 23:23:19,490:INFO:Extra Trees Classifier Imported successfully
2024-03-02 23:23:19,496:INFO:Starting cross validation
2024-03-02 23:23:19,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:23:26,039:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,039:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,083:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,121:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,173:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,201:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,245:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:26,295:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:28,335:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:28,350:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:28,362:INFO:Calculating mean and std
2024-03-02 23:23:28,364:INFO:Creating metrics dataframe
2024-03-02 23:23:28,368:INFO:Uploading results into container
2024-03-02 23:23:28,369:INFO:Uploading model into container now
2024-03-02 23:23:28,370:INFO:_master_model_container: 2
2024-03-02 23:23:28,370:INFO:_display_container: 2
2024-03-02 23:23:28,370:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 23:23:28,370:INFO:create_model() successfully completed......................................
2024-03-02 23:23:28,535:INFO:SubProcess create_model() end ==================================
2024-03-02 23:23:28,535:INFO:Creating metrics dataframe
2024-03-02 23:23:28,560:INFO:Initializing Extreme Gradient Boosting
2024-03-02 23:23:28,561:INFO:Total runtime is 0.37173908948898315 minutes
2024-03-02 23:23:28,566:INFO:SubProcess create_model() called ==================================
2024-03-02 23:23:28,566:INFO:Initializing create_model()
2024-03-02 23:23:28,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:23:28,568:INFO:Checking exceptions
2024-03-02 23:23:28,568:INFO:Importing libraries
2024-03-02 23:23:28,568:INFO:Copying training dataset
2024-03-02 23:23:28,594:INFO:Defining folds
2024-03-02 23:23:28,594:INFO:Declaring metric variables
2024-03-02 23:23:28,597:INFO:Importing untrained model
2024-03-02 23:23:28,604:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 23:23:28,610:INFO:Starting cross validation
2024-03-02 23:23:28,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:23:42,267:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:42,285:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:42,594:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:42,835:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:42,835:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:42,933:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:43,100:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:43,170:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:48,633:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:48,665:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:23:48,684:INFO:Calculating mean and std
2024-03-02 23:23:48,685:INFO:Creating metrics dataframe
2024-03-02 23:23:48,686:INFO:Uploading results into container
2024-03-02 23:23:48,688:INFO:Uploading model into container now
2024-03-02 23:23:48,688:INFO:_master_model_container: 3
2024-03-02 23:23:48,688:INFO:_display_container: 2
2024-03-02 23:23:48,689:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-02 23:23:48,689:INFO:create_model() successfully completed......................................
2024-03-02 23:23:48,846:INFO:SubProcess create_model() end ==================================
2024-03-02 23:23:48,846:INFO:Creating metrics dataframe
2024-03-02 23:23:48,861:INFO:Initializing Random Forest Classifier
2024-03-02 23:23:48,861:INFO:Total runtime is 0.7100617965062459 minutes
2024-03-02 23:23:48,867:INFO:SubProcess create_model() called ==================================
2024-03-02 23:23:48,867:INFO:Initializing create_model()
2024-03-02 23:23:48,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:23:48,867:INFO:Checking exceptions
2024-03-02 23:23:48,867:INFO:Importing libraries
2024-03-02 23:23:48,867:INFO:Copying training dataset
2024-03-02 23:23:48,892:INFO:Defining folds
2024-03-02 23:23:48,892:INFO:Declaring metric variables
2024-03-02 23:23:48,895:INFO:Importing untrained model
2024-03-02 23:23:48,901:INFO:Random Forest Classifier Imported successfully
2024-03-02 23:23:48,950:INFO:Starting cross validation
2024-03-02 23:23:48,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:24:00,902:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:00,908:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:00,980:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:00,983:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:01,101:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:01,148:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:01,160:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:04,417:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:04,498:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:24:04,514:INFO:Calculating mean and std
2024-03-02 23:24:04,524:INFO:Creating metrics dataframe
2024-03-02 23:24:04,526:INFO:Uploading results into container
2024-03-02 23:24:04,526:INFO:Uploading model into container now
2024-03-02 23:24:04,528:INFO:_master_model_container: 4
2024-03-02 23:24:04,528:INFO:_display_container: 2
2024-03-02 23:24:04,529:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 23:24:04,530:INFO:create_model() successfully completed......................................
2024-03-02 23:24:04,708:INFO:SubProcess create_model() end ==================================
2024-03-02 23:24:04,708:INFO:Creating metrics dataframe
2024-03-02 23:24:04,722:INFO:Initializing CatBoost Classifier
2024-03-02 23:24:04,722:INFO:Total runtime is 0.9744184851646422 minutes
2024-03-02 23:24:04,728:INFO:SubProcess create_model() called ==================================
2024-03-02 23:24:04,730:INFO:Initializing create_model()
2024-03-02 23:24:04,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:24:04,731:INFO:Checking exceptions
2024-03-02 23:24:04,732:INFO:Importing libraries
2024-03-02 23:24:04,732:INFO:Copying training dataset
2024-03-02 23:24:04,754:INFO:Defining folds
2024-03-02 23:24:04,768:INFO:Declaring metric variables
2024-03-02 23:24:04,772:INFO:Importing untrained model
2024-03-02 23:24:04,778:INFO:CatBoost Classifier Imported successfully
2024-03-02 23:24:04,790:INFO:Starting cross validation
2024-03-02 23:24:04,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:27:22,487:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:35,973:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:38,852:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:39,188:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:39,336:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:40,777:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:41,290:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:27:41,536:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:33,963:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:36,518:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:36,540:INFO:Calculating mean and std
2024-03-02 23:28:36,544:INFO:Creating metrics dataframe
2024-03-02 23:28:36,550:INFO:Uploading results into container
2024-03-02 23:28:36,552:INFO:Uploading model into container now
2024-03-02 23:28:36,552:INFO:_master_model_container: 5
2024-03-02 23:28:36,552:INFO:_display_container: 2
2024-03-02 23:28:36,553:INFO:<catboost.core.CatBoostClassifier object at 0x0000026E4233E6D0>
2024-03-02 23:28:36,553:INFO:create_model() successfully completed......................................
2024-03-02 23:28:36,798:INFO:SubProcess create_model() end ==================================
2024-03-02 23:28:36,798:INFO:Creating metrics dataframe
2024-03-02 23:28:36,811:INFO:Initializing Light Gradient Boosting Machine
2024-03-02 23:28:36,811:INFO:Total runtime is 5.509229838848114 minutes
2024-03-02 23:28:36,815:INFO:SubProcess create_model() called ==================================
2024-03-02 23:28:36,816:INFO:Initializing create_model()
2024-03-02 23:28:36,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:28:36,816:INFO:Checking exceptions
2024-03-02 23:28:36,816:INFO:Importing libraries
2024-03-02 23:28:36,817:INFO:Copying training dataset
2024-03-02 23:28:36,899:INFO:Defining folds
2024-03-02 23:28:36,899:INFO:Declaring metric variables
2024-03-02 23:28:36,906:INFO:Importing untrained model
2024-03-02 23:28:36,915:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 23:28:36,938:INFO:Starting cross validation
2024-03-02 23:28:36,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:28:50,887:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:50,945:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:52,035:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:52,117:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:52,197:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:52,562:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:52,617:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:53,317:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:56,096:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:56,467:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:28:56,502:INFO:Calculating mean and std
2024-03-02 23:28:56,504:INFO:Creating metrics dataframe
2024-03-02 23:28:56,508:INFO:Uploading results into container
2024-03-02 23:28:56,510:INFO:Uploading model into container now
2024-03-02 23:28:56,510:INFO:_master_model_container: 6
2024-03-02 23:28:56,511:INFO:_display_container: 2
2024-03-02 23:28:56,511:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:28:56,511:INFO:create_model() successfully completed......................................
2024-03-02 23:28:56,698:INFO:SubProcess create_model() end ==================================
2024-03-02 23:28:56,698:INFO:Creating metrics dataframe
2024-03-02 23:28:56,712:INFO:Initializing Gradient Boosting Classifier
2024-03-02 23:28:56,712:INFO:Total runtime is 5.84090838432312 minutes
2024-03-02 23:28:56,716:INFO:SubProcess create_model() called ==================================
2024-03-02 23:28:56,716:INFO:Initializing create_model()
2024-03-02 23:28:56,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E398DDED0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E30EB24D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:28:56,717:INFO:Checking exceptions
2024-03-02 23:28:56,717:INFO:Importing libraries
2024-03-02 23:28:56,717:INFO:Copying training dataset
2024-03-02 23:28:56,743:INFO:Defining folds
2024-03-02 23:28:56,743:INFO:Declaring metric variables
2024-03-02 23:28:56,747:INFO:Importing untrained model
2024-03-02 23:28:56,753:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 23:28:56,761:INFO:Starting cross validation
2024-03-02 23:28:56,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:30:14,410:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:14,726:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:14,797:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:15,164:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:15,410:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:15,640:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:16,012:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:16,021:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:56,365:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5941, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Outside_Global_Index'] not in index"

  warnings.warn(

2024-03-02 23:30:57,896:INFO:PyCaret ClassificationExperiment
2024-03-02 23:30:57,896:INFO:Logging name: clf-default-name
2024-03-02 23:30:57,896:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 23:30:57,896:INFO:version 3.3.0
2024-03-02 23:30:57,896:INFO:Initializing setup()
2024-03-02 23:30:57,896:INFO:self.USI: 7acd
2024-03-02 23:30:57,896:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'y_train', 'fold_generator', 'fold_shuffle_param', 'USI', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'target_param', 'y_test', '_available_plots', 'data', 'seed', 'memory', 'X_train', 'X_test', 'exp_name_log', 'log_plots_param', 'X', 'idx', 'is_multiclass', 'y'}
2024-03-02 23:30:57,896:INFO:Checking environment
2024-03-02 23:30:57,896:INFO:python_version: 3.11.5
2024-03-02 23:30:57,896:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 23:30:57,896:INFO:machine: AMD64
2024-03-02 23:30:57,897:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 23:30:57,897:INFO:Memory: svmem(total=8327905280, available=3523903488, percent=57.7, used=4804001792, free=3523903488)
2024-03-02 23:30:57,897:INFO:Physical Core: 4
2024-03-02 23:30:57,897:INFO:Logical Core: 8
2024-03-02 23:30:57,897:INFO:Checking libraries
2024-03-02 23:30:57,897:INFO:System:
2024-03-02 23:30:57,897:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 23:30:57,897:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 23:30:57,897:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 23:30:57,897:INFO:PyCaret required dependencies:
2024-03-02 23:30:57,897:INFO:                 pip: 23.2.1
2024-03-02 23:30:57,897:INFO:          setuptools: 68.0.0
2024-03-02 23:30:57,897:INFO:             pycaret: 3.3.0
2024-03-02 23:30:57,897:INFO:             IPython: 8.15.0
2024-03-02 23:30:57,898:INFO:          ipywidgets: 8.0.4
2024-03-02 23:30:57,898:INFO:                tqdm: 4.65.0
2024-03-02 23:30:57,898:INFO:               numpy: 1.24.3
2024-03-02 23:30:57,898:INFO:              pandas: 2.0.3
2024-03-02 23:30:57,898:INFO:              jinja2: 3.1.2
2024-03-02 23:30:57,898:INFO:               scipy: 1.11.1
2024-03-02 23:30:57,898:INFO:              joblib: 1.2.0
2024-03-02 23:30:57,898:INFO:             sklearn: 1.4.1.post1
2024-03-02 23:30:57,898:INFO:                pyod: 1.1.3
2024-03-02 23:30:57,898:INFO:            imblearn: 0.12.0
2024-03-02 23:30:57,898:INFO:   category_encoders: 2.6.3
2024-03-02 23:30:57,898:INFO:            lightgbm: 4.3.0
2024-03-02 23:30:57,898:INFO:               numba: 0.57.1
2024-03-02 23:30:57,898:INFO:            requests: 2.31.0
2024-03-02 23:30:57,898:INFO:          matplotlib: 3.7.2
2024-03-02 23:30:57,898:INFO:          scikitplot: 0.3.7
2024-03-02 23:30:57,898:INFO:         yellowbrick: 1.5
2024-03-02 23:30:57,898:INFO:              plotly: 5.19.0
2024-03-02 23:30:57,899:INFO:    plotly-resampler: Not installed
2024-03-02 23:30:57,899:INFO:             kaleido: 0.2.1
2024-03-02 23:30:57,899:INFO:           schemdraw: 0.15
2024-03-02 23:30:57,899:INFO:         statsmodels: 0.14.0
2024-03-02 23:30:57,899:INFO:              sktime: 0.26.1
2024-03-02 23:30:57,899:INFO:               tbats: 1.1.3
2024-03-02 23:30:57,899:INFO:            pmdarima: 2.0.4
2024-03-02 23:30:57,899:INFO:              psutil: 5.9.0
2024-03-02 23:30:57,899:INFO:          markupsafe: 2.1.1
2024-03-02 23:30:57,899:INFO:             pickle5: Not installed
2024-03-02 23:30:57,899:INFO:         cloudpickle: 2.2.1
2024-03-02 23:30:57,899:INFO:         deprecation: 2.1.0
2024-03-02 23:30:57,899:INFO:              xxhash: 2.0.2
2024-03-02 23:30:57,899:INFO:           wurlitzer: Not installed
2024-03-02 23:30:57,899:INFO:PyCaret optional dependencies:
2024-03-02 23:30:57,899:INFO:                shap: 0.44.1
2024-03-02 23:30:57,900:INFO:           interpret: Not installed
2024-03-02 23:30:57,900:INFO:                umap: Not installed
2024-03-02 23:30:57,900:INFO:     ydata_profiling: Not installed
2024-03-02 23:30:57,900:INFO:  explainerdashboard: Not installed
2024-03-02 23:30:57,900:INFO:             autoviz: Not installed
2024-03-02 23:30:57,900:INFO:           fairlearn: Not installed
2024-03-02 23:30:57,900:INFO:          deepchecks: Not installed
2024-03-02 23:30:57,900:INFO:             xgboost: 2.0.3
2024-03-02 23:30:57,900:INFO:            catboost: 1.2.2
2024-03-02 23:30:57,900:INFO:              kmodes: Not installed
2024-03-02 23:30:57,900:INFO:             mlxtend: Not installed
2024-03-02 23:30:57,900:INFO:       statsforecast: Not installed
2024-03-02 23:30:57,900:INFO:        tune_sklearn: Not installed
2024-03-02 23:30:57,900:INFO:                 ray: Not installed
2024-03-02 23:30:57,900:INFO:            hyperopt: Not installed
2024-03-02 23:30:57,900:INFO:              optuna: 3.5.0
2024-03-02 23:30:57,900:INFO:               skopt: Not installed
2024-03-02 23:30:57,901:INFO:              mlflow: Not installed
2024-03-02 23:30:57,901:INFO:              gradio: Not installed
2024-03-02 23:30:57,901:INFO:             fastapi: Not installed
2024-03-02 23:30:57,901:INFO:             uvicorn: Not installed
2024-03-02 23:30:57,901:INFO:              m2cgen: Not installed
2024-03-02 23:30:57,901:INFO:           evidently: Not installed
2024-03-02 23:30:57,901:INFO:               fugue: Not installed
2024-03-02 23:30:57,901:INFO:           streamlit: Not installed
2024-03-02 23:30:57,901:INFO:             prophet: Not installed
2024-03-02 23:30:57,901:INFO:None
2024-03-02 23:30:57,901:INFO:Set up data.
2024-03-02 23:30:57,935:INFO:Set up folding strategy.
2024-03-02 23:30:57,936:INFO:Set up train/test split.
2024-03-02 23:30:57,959:INFO:Set up index.
2024-03-02 23:30:57,959:INFO:Assigning column types.
2024-03-02 23:30:57,978:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 23:30:58,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,033:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,069:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,154:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,157:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,158:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 23:30:58,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,226:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,226:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:30:58,310:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,310:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,310:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 23:30:58,399:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,409:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,487:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:30:58,494:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:30:58,495:INFO:Preparing preprocessing pipeline...
2024-03-02 23:30:58,497:INFO:Set up simple imputation.
2024-03-02 23:30:58,497:INFO:Set up removing outliers.
2024-03-02 23:30:58,572:INFO:Finished creating preprocessing pipeline.
2024-03-02 23:30:58,579:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-02 23:30:58,579:INFO:Creating final display dataframe.
2024-03-02 23:31:00,002:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 28)
5   Transformed train set shape       (12222, 28)
6    Transformed test set shape        (5514, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              7acd
2024-03-02 23:31:00,141:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:00,148:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:00,266:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:00,270:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:00,271:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 23:31:00,272:INFO:setup() successfully completed in 2.5s...............
2024-03-02 23:31:05,347:INFO:PyCaret ClassificationExperiment
2024-03-02 23:31:05,351:INFO:Logging name: clf-default-name
2024-03-02 23:31:05,351:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-02 23:31:05,351:INFO:version 3.3.0
2024-03-02 23:31:05,351:INFO:Initializing setup()
2024-03-02 23:31:05,351:INFO:self.USI: 3ea1
2024-03-02 23:31:05,351:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'pipeline', 'html_param', 'n_jobs_param', 'y_train', 'fold_generator', 'fold_shuffle_param', 'USI', 'logging_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'target_param', 'y_test', '_available_plots', 'data', 'seed', 'memory', 'X_train', 'X_test', 'exp_name_log', 'log_plots_param', 'X', 'idx', 'is_multiclass', 'y'}
2024-03-02 23:31:05,351:INFO:Checking environment
2024-03-02 23:31:05,351:INFO:python_version: 3.11.5
2024-03-02 23:31:05,351:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-02 23:31:05,351:INFO:machine: AMD64
2024-03-02 23:31:05,351:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-02 23:31:05,351:INFO:Memory: svmem(total=8327905280, available=3507322880, percent=57.9, used=4820582400, free=3507322880)
2024-03-02 23:31:05,351:INFO:Physical Core: 4
2024-03-02 23:31:05,351:INFO:Logical Core: 8
2024-03-02 23:31:05,351:INFO:Checking libraries
2024-03-02 23:31:05,351:INFO:System:
2024-03-02 23:31:05,351:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-02 23:31:05,351:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-02 23:31:05,352:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-02 23:31:05,352:INFO:PyCaret required dependencies:
2024-03-02 23:31:05,352:INFO:                 pip: 23.2.1
2024-03-02 23:31:05,352:INFO:          setuptools: 68.0.0
2024-03-02 23:31:05,352:INFO:             pycaret: 3.3.0
2024-03-02 23:31:05,352:INFO:             IPython: 8.15.0
2024-03-02 23:31:05,352:INFO:          ipywidgets: 8.0.4
2024-03-02 23:31:05,352:INFO:                tqdm: 4.65.0
2024-03-02 23:31:05,352:INFO:               numpy: 1.24.3
2024-03-02 23:31:05,352:INFO:              pandas: 2.0.3
2024-03-02 23:31:05,352:INFO:              jinja2: 3.1.2
2024-03-02 23:31:05,352:INFO:               scipy: 1.11.1
2024-03-02 23:31:05,352:INFO:              joblib: 1.2.0
2024-03-02 23:31:05,352:INFO:             sklearn: 1.4.1.post1
2024-03-02 23:31:05,352:INFO:                pyod: 1.1.3
2024-03-02 23:31:05,352:INFO:            imblearn: 0.12.0
2024-03-02 23:31:05,352:INFO:   category_encoders: 2.6.3
2024-03-02 23:31:05,352:INFO:            lightgbm: 4.3.0
2024-03-02 23:31:05,352:INFO:               numba: 0.57.1
2024-03-02 23:31:05,352:INFO:            requests: 2.31.0
2024-03-02 23:31:05,352:INFO:          matplotlib: 3.7.2
2024-03-02 23:31:05,352:INFO:          scikitplot: 0.3.7
2024-03-02 23:31:05,352:INFO:         yellowbrick: 1.5
2024-03-02 23:31:05,352:INFO:              plotly: 5.19.0
2024-03-02 23:31:05,352:INFO:    plotly-resampler: Not installed
2024-03-02 23:31:05,352:INFO:             kaleido: 0.2.1
2024-03-02 23:31:05,352:INFO:           schemdraw: 0.15
2024-03-02 23:31:05,352:INFO:         statsmodels: 0.14.0
2024-03-02 23:31:05,352:INFO:              sktime: 0.26.1
2024-03-02 23:31:05,352:INFO:               tbats: 1.1.3
2024-03-02 23:31:05,352:INFO:            pmdarima: 2.0.4
2024-03-02 23:31:05,352:INFO:              psutil: 5.9.0
2024-03-02 23:31:05,352:INFO:          markupsafe: 2.1.1
2024-03-02 23:31:05,352:INFO:             pickle5: Not installed
2024-03-02 23:31:05,352:INFO:         cloudpickle: 2.2.1
2024-03-02 23:31:05,352:INFO:         deprecation: 2.1.0
2024-03-02 23:31:05,352:INFO:              xxhash: 2.0.2
2024-03-02 23:31:05,352:INFO:           wurlitzer: Not installed
2024-03-02 23:31:05,352:INFO:PyCaret optional dependencies:
2024-03-02 23:31:05,352:INFO:                shap: 0.44.1
2024-03-02 23:31:05,352:INFO:           interpret: Not installed
2024-03-02 23:31:05,352:INFO:                umap: Not installed
2024-03-02 23:31:05,352:INFO:     ydata_profiling: Not installed
2024-03-02 23:31:05,352:INFO:  explainerdashboard: Not installed
2024-03-02 23:31:05,352:INFO:             autoviz: Not installed
2024-03-02 23:31:05,352:INFO:           fairlearn: Not installed
2024-03-02 23:31:05,352:INFO:          deepchecks: Not installed
2024-03-02 23:31:05,352:INFO:             xgboost: 2.0.3
2024-03-02 23:31:05,352:INFO:            catboost: 1.2.2
2024-03-02 23:31:05,352:INFO:              kmodes: Not installed
2024-03-02 23:31:05,352:INFO:             mlxtend: Not installed
2024-03-02 23:31:05,352:INFO:       statsforecast: Not installed
2024-03-02 23:31:05,352:INFO:        tune_sklearn: Not installed
2024-03-02 23:31:05,352:INFO:                 ray: Not installed
2024-03-02 23:31:05,352:INFO:            hyperopt: Not installed
2024-03-02 23:31:05,352:INFO:              optuna: 3.5.0
2024-03-02 23:31:05,352:INFO:               skopt: Not installed
2024-03-02 23:31:05,352:INFO:              mlflow: Not installed
2024-03-02 23:31:05,352:INFO:              gradio: Not installed
2024-03-02 23:31:05,352:INFO:             fastapi: Not installed
2024-03-02 23:31:05,352:INFO:             uvicorn: Not installed
2024-03-02 23:31:05,352:INFO:              m2cgen: Not installed
2024-03-02 23:31:05,352:INFO:           evidently: Not installed
2024-03-02 23:31:05,352:INFO:               fugue: Not installed
2024-03-02 23:31:05,352:INFO:           streamlit: Not installed
2024-03-02 23:31:05,352:INFO:             prophet: Not installed
2024-03-02 23:31:05,352:INFO:None
2024-03-02 23:31:05,352:INFO:Set up data.
2024-03-02 23:31:05,379:INFO:Set up folding strategy.
2024-03-02 23:31:05,380:INFO:Set up train/test split.
2024-03-02 23:31:05,398:INFO:Set up index.
2024-03-02 23:31:05,398:INFO:Assigning column types.
2024-03-02 23:31:05,415:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-02 23:31:05,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,464:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,498:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:05,498:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:05,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,560:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,594:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:05,598:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:05,598:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-02 23:31:05,648:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,680:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:05,691:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:05,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-02 23:31:05,782:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:05,792:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:05,795:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-02 23:31:05,915:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:05,916:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:06,015:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:06,015:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:06,015:INFO:Preparing preprocessing pipeline...
2024-03-02 23:31:06,029:INFO:Set up simple imputation.
2024-03-02 23:31:06,029:INFO:Set up removing outliers.
2024-03-02 23:31:06,096:INFO:Finished creating preprocessing pipeline.
2024-03-02 23:31:06,096:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-02 23:31:06,096:INFO:Creating final display dataframe.
2024-03-02 23:31:06,243:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 28)
5   Transformed train set shape       (12222, 28)
6    Transformed test set shape        (5514, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12              Remove outliers              True
13           Outliers threshold              0.05
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3ea1
2024-03-02 23:31:06,314:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:06,325:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:06,396:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-02 23:31:06,396:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-02 23:31:06,396:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-02 23:31:06,396:INFO:setup() successfully completed in 1.13s...............
2024-03-02 23:31:12,903:INFO:Initializing compare_models()
2024-03-02 23:31:12,903:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, include=['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, 'include': ['lda', 'et', 'xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-02 23:31:12,903:INFO:Checking exceptions
2024-03-02 23:31:12,919:INFO:Preparing display monitor
2024-03-02 23:31:12,942:INFO:Initializing Linear Discriminant Analysis
2024-03-02 23:31:12,942:INFO:Total runtime is 0.0 minutes
2024-03-02 23:31:12,949:INFO:SubProcess create_model() called ==================================
2024-03-02 23:31:12,949:INFO:Initializing create_model()
2024-03-02 23:31:12,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:31:12,949:INFO:Checking exceptions
2024-03-02 23:31:12,949:INFO:Importing libraries
2024-03-02 23:31:12,950:INFO:Copying training dataset
2024-03-02 23:31:12,972:INFO:Defining folds
2024-03-02 23:31:12,973:INFO:Declaring metric variables
2024-03-02 23:31:12,979:INFO:Importing untrained model
2024-03-02 23:31:12,982:INFO:Linear Discriminant Analysis Imported successfully
2024-03-02 23:31:12,993:INFO:Starting cross validation
2024-03-02 23:31:12,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:31:25,925:INFO:Calculating mean and std
2024-03-02 23:31:25,932:INFO:Creating metrics dataframe
2024-03-02 23:31:25,935:INFO:Uploading results into container
2024-03-02 23:31:25,935:INFO:Uploading model into container now
2024-03-02 23:31:25,936:INFO:_master_model_container: 1
2024-03-02 23:31:25,936:INFO:_display_container: 2
2024-03-02 23:31:25,936:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-02 23:31:25,936:INFO:create_model() successfully completed......................................
2024-03-02 23:31:26,154:INFO:SubProcess create_model() end ==================================
2024-03-02 23:31:26,154:INFO:Creating metrics dataframe
2024-03-02 23:31:26,167:INFO:Initializing Extra Trees Classifier
2024-03-02 23:31:26,168:INFO:Total runtime is 0.22042668263117474 minutes
2024-03-02 23:31:26,173:INFO:SubProcess create_model() called ==================================
2024-03-02 23:31:26,173:INFO:Initializing create_model()
2024-03-02 23:31:26,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:31:26,173:INFO:Checking exceptions
2024-03-02 23:31:26,174:INFO:Importing libraries
2024-03-02 23:31:26,174:INFO:Copying training dataset
2024-03-02 23:31:26,200:INFO:Defining folds
2024-03-02 23:31:26,200:INFO:Declaring metric variables
2024-03-02 23:31:26,203:INFO:Importing untrained model
2024-03-02 23:31:26,208:INFO:Extra Trees Classifier Imported successfully
2024-03-02 23:31:26,216:INFO:Starting cross validation
2024-03-02 23:31:26,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:31:35,264:INFO:Calculating mean and std
2024-03-02 23:31:35,267:INFO:Creating metrics dataframe
2024-03-02 23:31:35,270:INFO:Uploading results into container
2024-03-02 23:31:35,270:INFO:Uploading model into container now
2024-03-02 23:31:35,272:INFO:_master_model_container: 2
2024-03-02 23:31:35,272:INFO:_display_container: 2
2024-03-02 23:31:35,274:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-03-02 23:31:35,274:INFO:create_model() successfully completed......................................
2024-03-02 23:31:35,517:INFO:SubProcess create_model() end ==================================
2024-03-02 23:31:35,517:INFO:Creating metrics dataframe
2024-03-02 23:31:35,531:INFO:Initializing Extreme Gradient Boosting
2024-03-02 23:31:35,531:INFO:Total runtime is 0.3764711181322734 minutes
2024-03-02 23:31:35,536:INFO:SubProcess create_model() called ==================================
2024-03-02 23:31:35,536:INFO:Initializing create_model()
2024-03-02 23:31:35,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:31:35,537:INFO:Checking exceptions
2024-03-02 23:31:35,537:INFO:Importing libraries
2024-03-02 23:31:35,537:INFO:Copying training dataset
2024-03-02 23:31:35,567:INFO:Defining folds
2024-03-02 23:31:35,567:INFO:Declaring metric variables
2024-03-02 23:31:35,571:INFO:Importing untrained model
2024-03-02 23:31:35,577:INFO:Extreme Gradient Boosting Imported successfully
2024-03-02 23:31:35,586:INFO:Starting cross validation
2024-03-02 23:31:35,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:31:52,128:INFO:Calculating mean and std
2024-03-02 23:31:52,130:INFO:Creating metrics dataframe
2024-03-02 23:31:52,131:INFO:Uploading results into container
2024-03-02 23:31:52,132:INFO:Uploading model into container now
2024-03-02 23:31:52,132:INFO:_master_model_container: 3
2024-03-02 23:31:52,132:INFO:_display_container: 2
2024-03-02 23:31:52,133:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-02 23:31:52,133:INFO:create_model() successfully completed......................................
2024-03-02 23:31:52,341:INFO:SubProcess create_model() end ==================================
2024-03-02 23:31:52,341:INFO:Creating metrics dataframe
2024-03-02 23:31:52,354:INFO:Initializing Random Forest Classifier
2024-03-02 23:31:52,356:INFO:Total runtime is 0.6568925301233928 minutes
2024-03-02 23:31:52,361:INFO:SubProcess create_model() called ==================================
2024-03-02 23:31:52,362:INFO:Initializing create_model()
2024-03-02 23:31:52,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:31:52,362:INFO:Checking exceptions
2024-03-02 23:31:52,362:INFO:Importing libraries
2024-03-02 23:31:52,362:INFO:Copying training dataset
2024-03-02 23:31:52,390:INFO:Defining folds
2024-03-02 23:31:52,391:INFO:Declaring metric variables
2024-03-02 23:31:52,397:INFO:Importing untrained model
2024-03-02 23:31:52,400:INFO:Random Forest Classifier Imported successfully
2024-03-02 23:31:52,411:INFO:Starting cross validation
2024-03-02 23:31:52,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:32:08,587:INFO:Calculating mean and std
2024-03-02 23:32:08,593:INFO:Creating metrics dataframe
2024-03-02 23:32:08,596:INFO:Uploading results into container
2024-03-02 23:32:08,597:INFO:Uploading model into container now
2024-03-02 23:32:08,598:INFO:_master_model_container: 4
2024-03-02 23:32:08,598:INFO:_display_container: 2
2024-03-02 23:32:08,598:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-02 23:32:08,598:INFO:create_model() successfully completed......................................
2024-03-02 23:32:08,818:INFO:SubProcess create_model() end ==================================
2024-03-02 23:32:08,819:INFO:Creating metrics dataframe
2024-03-02 23:32:08,833:INFO:Initializing CatBoost Classifier
2024-03-02 23:32:08,833:INFO:Total runtime is 0.9315041104952495 minutes
2024-03-02 23:32:08,840:INFO:SubProcess create_model() called ==================================
2024-03-02 23:32:08,841:INFO:Initializing create_model()
2024-03-02 23:32:08,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:32:08,841:INFO:Checking exceptions
2024-03-02 23:32:08,841:INFO:Importing libraries
2024-03-02 23:32:08,841:INFO:Copying training dataset
2024-03-02 23:32:08,870:INFO:Defining folds
2024-03-02 23:32:08,870:INFO:Declaring metric variables
2024-03-02 23:32:08,875:INFO:Importing untrained model
2024-03-02 23:32:08,879:INFO:CatBoost Classifier Imported successfully
2024-03-02 23:32:08,891:INFO:Starting cross validation
2024-03-02 23:32:08,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:36:40,651:INFO:Calculating mean and std
2024-03-02 23:36:40,652:INFO:Creating metrics dataframe
2024-03-02 23:36:40,655:INFO:Uploading results into container
2024-03-02 23:36:40,656:INFO:Uploading model into container now
2024-03-02 23:36:40,656:INFO:_master_model_container: 5
2024-03-02 23:36:40,656:INFO:_display_container: 2
2024-03-02 23:36:40,656:INFO:<catboost.core.CatBoostClassifier object at 0x0000026E43194E90>
2024-03-02 23:36:40,657:INFO:create_model() successfully completed......................................
2024-03-02 23:36:40,849:INFO:SubProcess create_model() end ==================================
2024-03-02 23:36:40,849:INFO:Creating metrics dataframe
2024-03-02 23:36:40,860:INFO:Initializing Light Gradient Boosting Machine
2024-03-02 23:36:40,861:INFO:Total runtime is 5.465307780106863 minutes
2024-03-02 23:36:40,866:INFO:SubProcess create_model() called ==================================
2024-03-02 23:36:40,867:INFO:Initializing create_model()
2024-03-02 23:36:40,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:36:40,867:INFO:Checking exceptions
2024-03-02 23:36:40,867:INFO:Importing libraries
2024-03-02 23:36:40,867:INFO:Copying training dataset
2024-03-02 23:36:40,892:INFO:Defining folds
2024-03-02 23:36:40,892:INFO:Declaring metric variables
2024-03-02 23:36:40,896:INFO:Importing untrained model
2024-03-02 23:36:40,900:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-02 23:36:40,909:INFO:Starting cross validation
2024-03-02 23:36:40,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:36:56,487:INFO:Calculating mean and std
2024-03-02 23:36:56,488:INFO:Creating metrics dataframe
2024-03-02 23:36:56,493:INFO:Uploading results into container
2024-03-02 23:36:56,494:INFO:Uploading model into container now
2024-03-02 23:36:56,494:INFO:_master_model_container: 6
2024-03-02 23:36:56,495:INFO:_display_container: 2
2024-03-02 23:36:56,496:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-02 23:36:56,496:INFO:create_model() successfully completed......................................
2024-03-02 23:36:56,722:INFO:SubProcess create_model() end ==================================
2024-03-02 23:36:56,722:INFO:Creating metrics dataframe
2024-03-02 23:36:56,734:INFO:Initializing Gradient Boosting Classifier
2024-03-02 23:36:56,735:INFO:Total runtime is 5.72988327741623 minutes
2024-03-02 23:36:56,740:INFO:SubProcess create_model() called ==================================
2024-03-02 23:36:56,740:INFO:Initializing create_model()
2024-03-02 23:36:56,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026E4757C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:36:56,740:INFO:Checking exceptions
2024-03-02 23:36:56,741:INFO:Importing libraries
2024-03-02 23:36:56,741:INFO:Copying training dataset
2024-03-02 23:36:56,769:INFO:Defining folds
2024-03-02 23:36:56,769:INFO:Declaring metric variables
2024-03-02 23:36:56,774:INFO:Importing untrained model
2024-03-02 23:36:56,781:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 23:36:56,790:INFO:Starting cross validation
2024-03-02 23:36:56,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:38:51,888:INFO:Calculating mean and std
2024-03-02 23:38:51,897:INFO:Creating metrics dataframe
2024-03-02 23:38:51,899:INFO:Uploading results into container
2024-03-02 23:38:51,900:INFO:Uploading model into container now
2024-03-02 23:38:51,900:INFO:_master_model_container: 7
2024-03-02 23:38:51,900:INFO:_display_container: 2
2024-03-02 23:38:51,901:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 23:38:51,901:INFO:create_model() successfully completed......................................
2024-03-02 23:38:52,111:INFO:SubProcess create_model() end ==================================
2024-03-02 23:38:52,111:INFO:Creating metrics dataframe
2024-03-02 23:38:52,140:INFO:Initializing create_model()
2024-03-02 23:38:52,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:38:52,141:INFO:Checking exceptions
2024-03-02 23:38:52,142:INFO:Importing libraries
2024-03-02 23:38:52,142:INFO:Copying training dataset
2024-03-02 23:38:52,166:INFO:Defining folds
2024-03-02 23:38:52,166:INFO:Declaring metric variables
2024-03-02 23:38:52,167:INFO:Importing untrained model
2024-03-02 23:38:52,167:INFO:Declaring custom model
2024-03-02 23:38:52,168:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 23:38:52,169:INFO:Cross validation set to False
2024-03-02 23:38:52,169:INFO:Fitting Model
2024-03-02 23:39:26,046:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 23:39:26,046:INFO:create_model() successfully completed......................................
2024-03-02 23:39:26,275:INFO:_master_model_container: 7
2024-03-02 23:39:26,276:INFO:_display_container: 2
2024-03-02 23:39:26,277:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 23:39:26,277:INFO:compare_models() successfully completed......................................
2024-03-02 23:39:58,425:INFO:Initializing create_model()
2024-03-02 23:39:58,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-02 23:39:58,425:INFO:Checking exceptions
2024-03-02 23:39:58,442:INFO:Importing libraries
2024-03-02 23:39:58,442:INFO:Copying training dataset
2024-03-02 23:39:58,470:INFO:Defining folds
2024-03-02 23:39:58,470:INFO:Declaring metric variables
2024-03-02 23:39:58,474:INFO:Importing untrained model
2024-03-02 23:39:58,480:INFO:Gradient Boosting Classifier Imported successfully
2024-03-02 23:39:58,486:INFO:Starting cross validation
2024-03-02 23:39:58,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-02 23:41:47,878:INFO:Calculating mean and std
2024-03-02 23:41:47,887:INFO:Creating metrics dataframe
2024-03-02 23:41:47,892:INFO:Finalizing model
2024-03-02 23:42:27,599:INFO:Uploading results into container
2024-03-02 23:42:27,600:INFO:Uploading model into container now
2024-03-02 23:42:27,615:INFO:_master_model_container: 8
2024-03-02 23:42:27,615:INFO:_display_container: 3
2024-03-02 23:42:27,616:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-02 23:42:27,616:INFO:create_model() successfully completed......................................
2024-03-02 23:43:01,263:INFO:Initializing tune_model()
2024-03-02 23:43:01,263:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-03-02 23:43:01,263:INFO:Checking exceptions
2024-03-02 23:43:01,289:INFO:Copying training dataset
2024-03-02 23:43:01,302:INFO:Checking base model
2024-03-02 23:43:01,302:INFO:Base model : Gradient Boosting Classifier
2024-03-02 23:43:01,309:INFO:Declaring metric variables
2024-03-02 23:43:01,313:INFO:Defining Hyperparameters
2024-03-02 23:43:01,534:INFO:Tuning with n_jobs=-1
2024-03-02 23:43:01,535:INFO:Initializing RandomizedSearchCV
2024-03-02 23:48:18,116:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\2765420497.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:49:04,200:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1934487689.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:49:44,022:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1651788119.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:52:07,288:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\658149245.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:52:19,467:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\2139342444.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:54:55,624:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\2224723029.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-02 23:56:26,644:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1546821738.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-03 00:02:19,820:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1546821738.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-03 00:04:32,338:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1546821738.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-03 00:05:48,545:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1546821738.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-03 00:06:33,214:WARNING:C:\Users\Janith\AppData\Local\Temp\ipykernel_3400\1546821738.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),

2024-03-03 07:49:34,970:INFO:Initializing tune_model()
2024-03-03 07:49:34,970:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026E3C123690>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-03-03 07:49:34,970:INFO:Checking exceptions
2024-03-03 07:49:34,970:INFO:Soft dependency imported: optuna: 3.5.0
2024-03-03 07:49:35,003:INFO:Copying training dataset
2024-03-03 07:49:35,020:INFO:Checking base model
2024-03-03 07:49:35,028:INFO:Base model : Gradient Boosting Classifier
2024-03-03 07:49:35,031:INFO:Declaring metric variables
2024-03-03 07:49:35,036:INFO:Defining Hyperparameters
2024-03-03 07:49:35,385:INFO:Tuning with n_jobs=-1
2024-03-03 07:49:35,387:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\optuna\samplers\_tpe\sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2024-03-03 07:49:35,387:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\optuna\samplers\_tpe\sampler.py:338: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2024-03-03 07:49:35,387:INFO:Initializing optuna.integration.OptunaSearchCV
2024-03-03 07:49:35,403:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2458: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2024-03-03 07:49:35,411:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,423:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,423:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,423:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,423:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,442:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,443:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:49:35,443:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:53:40,131:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 07:56:23,585:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\model_selection\_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(

2024-03-03 08:19:06,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-03 08:19:06,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-03 08:19:06,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-03 08:19:06,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-03 08:19:48,375:INFO:PyCaret ClassificationExperiment
2024-03-03 08:19:48,375:INFO:Logging name: clf-default-name
2024-03-03 08:19:48,375:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:19:48,375:INFO:version 3.3.0
2024-03-03 08:19:48,375:INFO:Initializing setup()
2024-03-03 08:19:48,375:INFO:self.USI: 377b
2024-03-03 08:19:48,375:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:19:48,375:INFO:Checking environment
2024-03-03 08:19:48,375:INFO:python_version: 3.11.5
2024-03-03 08:19:48,375:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:19:48,375:INFO:machine: AMD64
2024-03-03 08:19:48,375:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:19:48,375:INFO:Memory: svmem(total=8327905280, available=2253721600, percent=72.9, used=6074183680, free=2253721600)
2024-03-03 08:19:48,375:INFO:Physical Core: 4
2024-03-03 08:19:48,375:INFO:Logical Core: 8
2024-03-03 08:19:48,375:INFO:Checking libraries
2024-03-03 08:19:48,375:INFO:System:
2024-03-03 08:19:48,375:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:19:48,375:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:19:48,375:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:19:48,375:INFO:PyCaret required dependencies:
2024-03-03 08:19:50,137:INFO:                 pip: 23.2.1
2024-03-03 08:19:50,141:INFO:          setuptools: 68.0.0
2024-03-03 08:19:50,141:INFO:             pycaret: 3.3.0
2024-03-03 08:19:50,141:INFO:             IPython: 8.15.0
2024-03-03 08:19:50,141:INFO:          ipywidgets: 8.0.4
2024-03-03 08:19:50,141:INFO:                tqdm: 4.65.0
2024-03-03 08:19:50,141:INFO:               numpy: 1.24.3
2024-03-03 08:19:50,141:INFO:              pandas: 2.0.3
2024-03-03 08:19:50,141:INFO:              jinja2: 3.1.2
2024-03-03 08:19:50,141:INFO:               scipy: 1.11.1
2024-03-03 08:19:50,141:INFO:              joblib: 1.2.0
2024-03-03 08:19:50,141:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:19:50,141:INFO:                pyod: 1.1.3
2024-03-03 08:19:50,141:INFO:            imblearn: 0.12.0
2024-03-03 08:19:50,141:INFO:   category_encoders: 2.6.3
2024-03-03 08:19:50,141:INFO:            lightgbm: 4.3.0
2024-03-03 08:19:50,141:INFO:               numba: 0.57.1
2024-03-03 08:19:50,141:INFO:            requests: 2.31.0
2024-03-03 08:19:50,141:INFO:          matplotlib: 3.7.2
2024-03-03 08:19:50,141:INFO:          scikitplot: 0.3.7
2024-03-03 08:19:50,141:INFO:         yellowbrick: 1.5
2024-03-03 08:19:50,141:INFO:              plotly: 5.19.0
2024-03-03 08:19:50,141:INFO:    plotly-resampler: Not installed
2024-03-03 08:19:50,141:INFO:             kaleido: 0.2.1
2024-03-03 08:19:50,141:INFO:           schemdraw: 0.15
2024-03-03 08:19:50,141:INFO:         statsmodels: 0.14.0
2024-03-03 08:19:50,141:INFO:              sktime: 0.26.1
2024-03-03 08:19:50,141:INFO:               tbats: 1.1.3
2024-03-03 08:19:50,141:INFO:            pmdarima: 2.0.4
2024-03-03 08:19:50,141:INFO:              psutil: 5.9.0
2024-03-03 08:19:50,141:INFO:          markupsafe: 2.1.1
2024-03-03 08:19:50,141:INFO:             pickle5: Not installed
2024-03-03 08:19:50,141:INFO:         cloudpickle: 2.2.1
2024-03-03 08:19:50,141:INFO:         deprecation: 2.1.0
2024-03-03 08:19:50,141:INFO:              xxhash: 2.0.2
2024-03-03 08:19:50,141:INFO:           wurlitzer: Not installed
2024-03-03 08:19:50,141:INFO:PyCaret optional dependencies:
2024-03-03 08:19:50,232:INFO:                shap: 0.44.1
2024-03-03 08:19:50,232:INFO:           interpret: Not installed
2024-03-03 08:19:50,232:INFO:                umap: Not installed
2024-03-03 08:19:50,232:INFO:     ydata_profiling: Not installed
2024-03-03 08:19:50,232:INFO:  explainerdashboard: Not installed
2024-03-03 08:19:50,232:INFO:             autoviz: Not installed
2024-03-03 08:19:50,232:INFO:           fairlearn: Not installed
2024-03-03 08:19:50,232:INFO:          deepchecks: Not installed
2024-03-03 08:19:50,232:INFO:             xgboost: 2.0.3
2024-03-03 08:19:50,232:INFO:            catboost: 1.2.2
2024-03-03 08:19:50,232:INFO:              kmodes: Not installed
2024-03-03 08:19:50,232:INFO:             mlxtend: Not installed
2024-03-03 08:19:50,232:INFO:       statsforecast: Not installed
2024-03-03 08:19:50,232:INFO:        tune_sklearn: Not installed
2024-03-03 08:19:50,232:INFO:                 ray: Not installed
2024-03-03 08:19:50,232:INFO:            hyperopt: Not installed
2024-03-03 08:19:50,232:INFO:              optuna: 3.5.0
2024-03-03 08:19:50,232:INFO:               skopt: Not installed
2024-03-03 08:19:50,232:INFO:              mlflow: Not installed
2024-03-03 08:19:50,232:INFO:              gradio: Not installed
2024-03-03 08:19:50,232:INFO:             fastapi: Not installed
2024-03-03 08:19:50,232:INFO:             uvicorn: Not installed
2024-03-03 08:19:50,232:INFO:              m2cgen: Not installed
2024-03-03 08:19:50,232:INFO:           evidently: Not installed
2024-03-03 08:19:50,232:INFO:               fugue: Not installed
2024-03-03 08:19:50,232:INFO:           streamlit: Not installed
2024-03-03 08:19:50,232:INFO:             prophet: Not installed
2024-03-03 08:19:50,232:INFO:None
2024-03-03 08:19:50,232:INFO:Set up data.
2024-03-03 08:19:50,256:INFO:Set up folding strategy.
2024-03-03 08:19:50,256:INFO:Set up train/test split.
2024-03-03 08:19:50,274:INFO:Set up index.
2024-03-03 08:19:50,274:INFO:Assigning column types.
2024-03-03 08:19:50,292:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:19:50,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,383:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,383:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,612:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,612:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,612:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:19:50,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,691:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,691:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:19:50,770:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,772:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,772:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:19:50,842:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,842:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,921:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:50,922:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:50,922:INFO:Preparing preprocessing pipeline...
2024-03-03 08:19:50,929:INFO:Set up simple imputation.
2024-03-03 08:19:50,929:INFO:Set up polynomial features.
2024-03-03 08:19:50,929:INFO:Set up removing outliers.
2024-03-03 08:19:51,110:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:19:51,122:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                                              strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:19:51,122:INFO:Creating final display dataframe.
2024-03-03 08:19:53,551:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape      (17736, 406)
5   Transformed train set shape      (12222, 406)
6    Transformed test set shape       (5514, 406)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              377b
2024-03-03 08:19:53,662:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:53,671:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:53,767:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:19:53,773:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:19:53,773:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:19:53,773:INFO:setup() successfully completed in 5.57s...............
2024-03-03 08:22:21,301:INFO:PyCaret ClassificationExperiment
2024-03-03 08:22:21,301:INFO:Logging name: clf-default-name
2024-03-03 08:22:21,301:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:22:21,301:INFO:version 3.3.0
2024-03-03 08:22:21,301:INFO:Initializing setup()
2024-03-03 08:22:21,301:INFO:self.USI: e8ad
2024-03-03 08:22:21,301:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:22:21,301:INFO:Checking environment
2024-03-03 08:22:21,301:INFO:python_version: 3.11.5
2024-03-03 08:22:21,301:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:22:21,301:INFO:machine: AMD64
2024-03-03 08:22:21,301:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:22:21,301:INFO:Memory: svmem(total=8327905280, available=2158837760, percent=74.1, used=6169067520, free=2158837760)
2024-03-03 08:22:21,301:INFO:Physical Core: 4
2024-03-03 08:22:21,301:INFO:Logical Core: 8
2024-03-03 08:22:21,301:INFO:Checking libraries
2024-03-03 08:22:21,301:INFO:System:
2024-03-03 08:22:21,301:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:22:21,301:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:22:21,301:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:22:21,301:INFO:PyCaret required dependencies:
2024-03-03 08:22:21,301:INFO:                 pip: 23.2.1
2024-03-03 08:22:21,301:INFO:          setuptools: 68.0.0
2024-03-03 08:22:21,301:INFO:             pycaret: 3.3.0
2024-03-03 08:22:21,301:INFO:             IPython: 8.15.0
2024-03-03 08:22:21,301:INFO:          ipywidgets: 8.0.4
2024-03-03 08:22:21,301:INFO:                tqdm: 4.65.0
2024-03-03 08:22:21,301:INFO:               numpy: 1.24.3
2024-03-03 08:22:21,301:INFO:              pandas: 2.0.3
2024-03-03 08:22:21,301:INFO:              jinja2: 3.1.2
2024-03-03 08:22:21,301:INFO:               scipy: 1.11.1
2024-03-03 08:22:21,301:INFO:              joblib: 1.2.0
2024-03-03 08:22:21,301:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:22:21,301:INFO:                pyod: 1.1.3
2024-03-03 08:22:21,301:INFO:            imblearn: 0.12.0
2024-03-03 08:22:21,301:INFO:   category_encoders: 2.6.3
2024-03-03 08:22:21,301:INFO:            lightgbm: 4.3.0
2024-03-03 08:22:21,301:INFO:               numba: 0.57.1
2024-03-03 08:22:21,301:INFO:            requests: 2.31.0
2024-03-03 08:22:21,301:INFO:          matplotlib: 3.7.2
2024-03-03 08:22:21,301:INFO:          scikitplot: 0.3.7
2024-03-03 08:22:21,301:INFO:         yellowbrick: 1.5
2024-03-03 08:22:21,301:INFO:              plotly: 5.19.0
2024-03-03 08:22:21,301:INFO:    plotly-resampler: Not installed
2024-03-03 08:22:21,301:INFO:             kaleido: 0.2.1
2024-03-03 08:22:21,301:INFO:           schemdraw: 0.15
2024-03-03 08:22:21,301:INFO:         statsmodels: 0.14.0
2024-03-03 08:22:21,301:INFO:              sktime: 0.26.1
2024-03-03 08:22:21,301:INFO:               tbats: 1.1.3
2024-03-03 08:22:21,301:INFO:            pmdarima: 2.0.4
2024-03-03 08:22:21,301:INFO:              psutil: 5.9.0
2024-03-03 08:22:21,301:INFO:          markupsafe: 2.1.1
2024-03-03 08:22:21,301:INFO:             pickle5: Not installed
2024-03-03 08:22:21,301:INFO:         cloudpickle: 2.2.1
2024-03-03 08:22:21,301:INFO:         deprecation: 2.1.0
2024-03-03 08:22:21,301:INFO:              xxhash: 2.0.2
2024-03-03 08:22:21,301:INFO:           wurlitzer: Not installed
2024-03-03 08:22:21,301:INFO:PyCaret optional dependencies:
2024-03-03 08:22:21,301:INFO:                shap: 0.44.1
2024-03-03 08:22:21,301:INFO:           interpret: Not installed
2024-03-03 08:22:21,301:INFO:                umap: Not installed
2024-03-03 08:22:21,301:INFO:     ydata_profiling: Not installed
2024-03-03 08:22:21,301:INFO:  explainerdashboard: Not installed
2024-03-03 08:22:21,301:INFO:             autoviz: Not installed
2024-03-03 08:22:21,301:INFO:           fairlearn: Not installed
2024-03-03 08:22:21,301:INFO:          deepchecks: Not installed
2024-03-03 08:22:21,301:INFO:             xgboost: 2.0.3
2024-03-03 08:22:21,301:INFO:            catboost: 1.2.2
2024-03-03 08:22:21,301:INFO:              kmodes: Not installed
2024-03-03 08:22:21,301:INFO:             mlxtend: Not installed
2024-03-03 08:22:21,301:INFO:       statsforecast: Not installed
2024-03-03 08:22:21,301:INFO:        tune_sklearn: Not installed
2024-03-03 08:22:21,301:INFO:                 ray: Not installed
2024-03-03 08:22:21,301:INFO:            hyperopt: Not installed
2024-03-03 08:22:21,301:INFO:              optuna: 3.5.0
2024-03-03 08:22:21,301:INFO:               skopt: Not installed
2024-03-03 08:22:21,301:INFO:              mlflow: Not installed
2024-03-03 08:22:21,301:INFO:              gradio: Not installed
2024-03-03 08:22:21,301:INFO:             fastapi: Not installed
2024-03-03 08:22:21,301:INFO:             uvicorn: Not installed
2024-03-03 08:22:21,301:INFO:              m2cgen: Not installed
2024-03-03 08:22:21,301:INFO:           evidently: Not installed
2024-03-03 08:22:21,301:INFO:               fugue: Not installed
2024-03-03 08:22:21,301:INFO:           streamlit: Not installed
2024-03-03 08:22:21,301:INFO:             prophet: Not installed
2024-03-03 08:22:21,301:INFO:None
2024-03-03 08:22:21,301:INFO:Set up data.
2024-03-03 08:22:21,329:INFO:Set up folding strategy.
2024-03-03 08:22:21,329:INFO:Set up train/test split.
2024-03-03 08:22:21,350:INFO:Set up index.
2024-03-03 08:22:21,351:INFO:Assigning column types.
2024-03-03 08:22:21,371:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:22:21,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,409:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,437:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,441:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,512:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,512:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,512:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:22:21,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,582:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,582:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:22:21,692:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,702:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,702:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:22:21,772:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,772:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,844:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,844:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:21,844:INFO:Preparing preprocessing pipeline...
2024-03-03 08:22:21,854:INFO:Set up simple imputation.
2024-03-03 08:22:21,854:INFO:Set up polynomial features.
2024-03-03 08:22:21,854:INFO:Set up removing multicollinearity.
2024-03-03 08:22:21,854:INFO:Set up removing outliers.
2024-03-03 08:22:21,854:INFO:Set up feature selection.
2024-03-03 08:22:21,922:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:21,922:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:33,840:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:22:33,870:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=5,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-03-03 08:22:33,870:INFO:Creating final display dataframe.
2024-03-03 08:22:37,974:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape        (17736, 6)
5   Transformed train set shape        (12222, 6)
6    Transformed test set shape         (5514, 6)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18            Feature selection              True
19     Feature selection method           classic
20  Feature selection estimator          lightgbm
21  Number of features selected               0.2
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              e8ad
2024-03-03 08:22:38,121:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:38,129:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:38,232:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:22:38,232:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:22:38,239:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:22:38,241:INFO:setup() successfully completed in 17.03s...............
2024-03-03 08:23:12,011:INFO:Initializing compare_models()
2024-03-03 08:23:12,011:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, include=['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, 'include': ['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-03 08:23:12,011:INFO:Checking exceptions
2024-03-03 08:23:12,030:INFO:Preparing display monitor
2024-03-03 08:23:12,072:INFO:Initializing Extreme Gradient Boosting
2024-03-03 08:23:12,072:INFO:Total runtime is 0.0 minutes
2024-03-03 08:23:12,081:INFO:SubProcess create_model() called ==================================
2024-03-03 08:23:12,081:INFO:Initializing create_model()
2024-03-03 08:23:12,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:23:12,081:INFO:Checking exceptions
2024-03-03 08:23:12,081:INFO:Importing libraries
2024-03-03 08:23:12,081:INFO:Copying training dataset
2024-03-03 08:23:12,127:INFO:Defining folds
2024-03-03 08:23:12,129:INFO:Declaring metric variables
2024-03-03 08:23:12,133:INFO:Importing untrained model
2024-03-03 08:23:12,153:INFO:Extreme Gradient Boosting Imported successfully
2024-03-03 08:23:12,185:INFO:Starting cross validation
2024-03-03 08:23:12,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:24:38,527:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:42,935:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:43,106:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:43,725:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:51,992:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:53,559:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:55,097:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:24:55,808:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:25:09,957:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:25:12,225:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:25:12,243:INFO:Calculating mean and std
2024-03-03 08:25:12,244:INFO:Creating metrics dataframe
2024-03-03 08:25:12,244:INFO:Uploading results into container
2024-03-03 08:25:12,244:INFO:Uploading model into container now
2024-03-03 08:25:12,252:INFO:_master_model_container: 1
2024-03-03 08:25:12,252:INFO:_display_container: 2
2024-03-03 08:25:12,252:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-03 08:25:12,252:INFO:create_model() successfully completed......................................
2024-03-03 08:25:12,454:INFO:SubProcess create_model() end ==================================
2024-03-03 08:25:12,454:INFO:Creating metrics dataframe
2024-03-03 08:25:12,463:INFO:Initializing Random Forest Classifier
2024-03-03 08:25:12,463:INFO:Total runtime is 2.0065091689427694 minutes
2024-03-03 08:25:12,467:INFO:SubProcess create_model() called ==================================
2024-03-03 08:25:12,467:INFO:Initializing create_model()
2024-03-03 08:25:12,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:25:12,467:INFO:Checking exceptions
2024-03-03 08:25:12,467:INFO:Importing libraries
2024-03-03 08:25:12,467:INFO:Copying training dataset
2024-03-03 08:25:12,495:INFO:Defining folds
2024-03-03 08:25:12,495:INFO:Declaring metric variables
2024-03-03 08:25:12,504:INFO:Importing untrained model
2024-03-03 08:25:12,504:INFO:Random Forest Classifier Imported successfully
2024-03-03 08:25:12,519:INFO:Starting cross validation
2024-03-03 08:25:12,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:26:34,204:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:34,503:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:36,026:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:37,882:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:47,783:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:49,874:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:50,386:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:26:52,114:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:27:08,207:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:27:09,462:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:27:09,482:INFO:Calculating mean and std
2024-03-03 08:27:09,492:INFO:Creating metrics dataframe
2024-03-03 08:27:09,498:INFO:Uploading results into container
2024-03-03 08:27:09,504:INFO:Uploading model into container now
2024-03-03 08:27:09,504:INFO:_master_model_container: 2
2024-03-03 08:27:09,504:INFO:_display_container: 2
2024-03-03 08:27:09,505:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-03 08:27:09,505:INFO:create_model() successfully completed......................................
2024-03-03 08:27:09,631:INFO:SubProcess create_model() end ==================================
2024-03-03 08:27:09,631:INFO:Creating metrics dataframe
2024-03-03 08:27:09,644:INFO:Initializing CatBoost Classifier
2024-03-03 08:27:09,644:INFO:Total runtime is 3.9595378081003823 minutes
2024-03-03 08:27:09,644:INFO:SubProcess create_model() called ==================================
2024-03-03 08:27:09,644:INFO:Initializing create_model()
2024-03-03 08:27:09,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:27:09,653:INFO:Checking exceptions
2024-03-03 08:27:09,653:INFO:Importing libraries
2024-03-03 08:27:09,653:INFO:Copying training dataset
2024-03-03 08:27:09,684:INFO:Defining folds
2024-03-03 08:27:09,684:INFO:Declaring metric variables
2024-03-03 08:27:09,684:INFO:Importing untrained model
2024-03-03 08:27:09,694:INFO:CatBoost Classifier Imported successfully
2024-03-03 08:27:09,702:INFO:Starting cross validation
2024-03-03 08:27:09,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:29:07,597:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:10,865:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:11,907:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:39,315:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:40,971:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:43,921:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:57,695:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:29:59,026:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:30:28,807:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:30:31,337:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:30:31,352:INFO:Calculating mean and std
2024-03-03 08:30:31,360:INFO:Creating metrics dataframe
2024-03-03 08:30:31,360:INFO:Uploading results into container
2024-03-03 08:30:31,360:INFO:Uploading model into container now
2024-03-03 08:30:31,368:INFO:_master_model_container: 3
2024-03-03 08:30:31,368:INFO:_display_container: 2
2024-03-03 08:30:31,368:INFO:<catboost.core.CatBoostClassifier object at 0x0000013F5E5671D0>
2024-03-03 08:30:31,368:INFO:create_model() successfully completed......................................
2024-03-03 08:30:31,500:INFO:SubProcess create_model() end ==================================
2024-03-03 08:30:31,500:INFO:Creating metrics dataframe
2024-03-03 08:30:31,510:INFO:Initializing Light Gradient Boosting Machine
2024-03-03 08:30:31,510:INFO:Total runtime is 7.3239621758461 minutes
2024-03-03 08:30:31,510:INFO:SubProcess create_model() called ==================================
2024-03-03 08:30:31,510:INFO:Initializing create_model()
2024-03-03 08:30:31,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:30:31,510:INFO:Checking exceptions
2024-03-03 08:30:31,510:INFO:Importing libraries
2024-03-03 08:30:31,510:INFO:Copying training dataset
2024-03-03 08:30:31,543:INFO:Defining folds
2024-03-03 08:30:31,543:INFO:Declaring metric variables
2024-03-03 08:30:31,549:INFO:Importing untrained model
2024-03-03 08:30:31,552:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-03 08:30:31,559:INFO:Starting cross validation
2024-03-03 08:30:31,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:31:56,254:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:56,531:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:56,666:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:56,685:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:57,071:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:58,403:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:58,630:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:31:59,973:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:32:20,784:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:32:21,281:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:32:21,312:INFO:Calculating mean and std
2024-03-03 08:32:21,312:INFO:Creating metrics dataframe
2024-03-03 08:32:21,322:INFO:Uploading results into container
2024-03-03 08:32:21,325:INFO:Uploading model into container now
2024-03-03 08:32:21,325:INFO:_master_model_container: 4
2024-03-03 08:32:21,325:INFO:_display_container: 2
2024-03-03 08:32:21,325:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-03 08:32:21,325:INFO:create_model() successfully completed......................................
2024-03-03 08:32:21,472:INFO:SubProcess create_model() end ==================================
2024-03-03 08:32:21,472:INFO:Creating metrics dataframe
2024-03-03 08:32:21,488:INFO:Initializing Gradient Boosting Classifier
2024-03-03 08:32:21,488:INFO:Total runtime is 9.156926695505778 minutes
2024-03-03 08:32:21,492:INFO:SubProcess create_model() called ==================================
2024-03-03 08:32:21,492:INFO:Initializing create_model()
2024-03-03 08:32:21,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:32:21,492:INFO:Checking exceptions
2024-03-03 08:32:21,492:INFO:Importing libraries
2024-03-03 08:32:21,492:INFO:Copying training dataset
2024-03-03 08:32:21,521:INFO:Defining folds
2024-03-03 08:32:21,521:INFO:Declaring metric variables
2024-03-03 08:32:21,526:INFO:Importing untrained model
2024-03-03 08:32:21,533:INFO:Gradient Boosting Classifier Imported successfully
2024-03-03 08:32:21,547:INFO:Starting cross validation
2024-03-03 08:32:21,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:33:59,003:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:01,414:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:02,550:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:04,152:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:05,986:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:33,089:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:34,934:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:38,525:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:50,258:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:51,401:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:34:51,412:INFO:Calculating mean and std
2024-03-03 08:34:51,412:INFO:Creating metrics dataframe
2024-03-03 08:34:51,421:INFO:Uploading results into container
2024-03-03 08:34:51,421:INFO:Uploading model into container now
2024-03-03 08:34:51,421:INFO:_master_model_container: 5
2024-03-03 08:34:51,421:INFO:_display_container: 2
2024-03-03 08:34:51,421:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:34:51,421:INFO:create_model() successfully completed......................................
2024-03-03 08:34:51,532:INFO:SubProcess create_model() end ==================================
2024-03-03 08:34:51,532:INFO:Creating metrics dataframe
2024-03-03 08:34:51,549:INFO:Initializing create_model()
2024-03-03 08:34:51,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:34:51,549:INFO:Checking exceptions
2024-03-03 08:34:51,557:INFO:Importing libraries
2024-03-03 08:34:51,557:INFO:Copying training dataset
2024-03-03 08:34:51,581:INFO:Defining folds
2024-03-03 08:34:51,581:INFO:Declaring metric variables
2024-03-03 08:34:51,581:INFO:Importing untrained model
2024-03-03 08:34:51,581:INFO:Declaring custom model
2024-03-03 08:34:51,581:INFO:Gradient Boosting Classifier Imported successfully
2024-03-03 08:34:51,710:INFO:Cross validation set to False
2024-03-03 08:34:51,711:INFO:Fitting Model
2024-03-03 08:34:58,236:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-03-03 08:34:58,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011746 seconds.
2024-03-03 08:34:58,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-03 08:34:58,250:INFO:[LightGBM] [Info] Total Bins 35658
2024-03-03 08:34:58,254:INFO:[LightGBM] [Info] Number of data points in the train set: 12222, number of used features: 149
2024-03-03 08:34:58,256:INFO:[LightGBM] [Info] Start training from score -2.513288
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -2.764602
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -1.762730
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -3.424541
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -3.627168
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -1.318753
2024-03-03 08:34:58,258:INFO:[LightGBM] [Info] Start training from score -1.027788
2024-03-03 08:35:19,287:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:35:19,287:INFO:create_model() successfully completed......................................
2024-03-03 08:35:19,428:INFO:_master_model_container: 5
2024-03-03 08:35:19,428:INFO:_display_container: 2
2024-03-03 08:35:19,428:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:35:19,428:INFO:compare_models() successfully completed......................................
2024-03-03 08:35:57,627:INFO:Initializing compare_models()
2024-03-03 08:35:57,630:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, include=['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, 'include': ['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-03 08:35:57,630:INFO:Checking exceptions
2024-03-03 08:35:57,639:INFO:Preparing display monitor
2024-03-03 08:35:57,669:INFO:Initializing Extreme Gradient Boosting
2024-03-03 08:35:57,669:INFO:Total runtime is 0.0 minutes
2024-03-03 08:35:57,680:INFO:SubProcess create_model() called ==================================
2024-03-03 08:35:57,680:INFO:Initializing create_model()
2024-03-03 08:35:57,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F54AA6150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:35:57,680:INFO:Checking exceptions
2024-03-03 08:35:57,680:INFO:Importing libraries
2024-03-03 08:35:57,680:INFO:Copying training dataset
2024-03-03 08:35:57,710:INFO:Defining folds
2024-03-03 08:35:57,710:INFO:Declaring metric variables
2024-03-03 08:35:57,717:INFO:Importing untrained model
2024-03-03 08:35:57,728:INFO:Extreme Gradient Boosting Imported successfully
2024-03-03 08:35:57,739:INFO:Starting cross validation
2024-03-03 08:35:57,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:37:17,637:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:37:17,797:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:37:18,177:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:37:35,828:INFO:Initializing compare_models()
2024-03-03 08:37:35,828:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, include=['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, 'include': ['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-03 08:37:35,828:INFO:Checking exceptions
2024-03-03 08:37:35,844:INFO:Preparing display monitor
2024-03-03 08:37:35,888:INFO:Initializing Extreme Gradient Boosting
2024-03-03 08:37:35,888:INFO:Total runtime is 0.0 minutes
2024-03-03 08:37:35,896:INFO:SubProcess create_model() called ==================================
2024-03-03 08:37:35,896:INFO:Initializing create_model()
2024-03-03 08:37:35,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F634C3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:37:35,896:INFO:Checking exceptions
2024-03-03 08:37:35,896:INFO:Importing libraries
2024-03-03 08:37:35,896:INFO:Copying training dataset
2024-03-03 08:37:35,930:INFO:Defining folds
2024-03-03 08:37:35,930:INFO:Declaring metric variables
2024-03-03 08:37:35,937:INFO:Importing untrained model
2024-03-03 08:37:35,937:INFO:Extreme Gradient Boosting Imported successfully
2024-03-03 08:37:35,950:INFO:Starting cross validation
2024-03-03 08:37:36,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:38:55,711:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:38:56,189:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:38:56,218:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:38:56,565:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:00,021:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:07,477:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:07,829:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:08,032:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:22,657:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:22,943:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:39:22,955:INFO:Calculating mean and std
2024-03-03 08:39:22,955:INFO:Creating metrics dataframe
2024-03-03 08:39:22,955:INFO:Uploading results into container
2024-03-03 08:39:22,964:INFO:Uploading model into container now
2024-03-03 08:39:22,965:INFO:_master_model_container: 6
2024-03-03 08:39:22,965:INFO:_display_container: 3
2024-03-03 08:39:22,966:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-03 08:39:22,966:INFO:create_model() successfully completed......................................
2024-03-03 08:39:23,126:INFO:SubProcess create_model() end ==================================
2024-03-03 08:39:23,126:INFO:Creating metrics dataframe
2024-03-03 08:39:23,127:INFO:Initializing Random Forest Classifier
2024-03-03 08:39:23,127:INFO:Total runtime is 1.7873123049736024 minutes
2024-03-03 08:39:23,137:INFO:SubProcess create_model() called ==================================
2024-03-03 08:39:23,137:INFO:Initializing create_model()
2024-03-03 08:39:23,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F634C3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:39:23,137:INFO:Checking exceptions
2024-03-03 08:39:23,137:INFO:Importing libraries
2024-03-03 08:39:23,137:INFO:Copying training dataset
2024-03-03 08:39:23,157:INFO:Defining folds
2024-03-03 08:39:23,157:INFO:Declaring metric variables
2024-03-03 08:39:23,157:INFO:Importing untrained model
2024-03-03 08:39:23,167:INFO:Random Forest Classifier Imported successfully
2024-03-03 08:39:23,175:INFO:Starting cross validation
2024-03-03 08:39:23,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:40:31,591:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:36,678:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:36,848:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:38,968:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:48,650:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:50,207:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:52,075:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:40:53,727:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:41:06,235:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:41:08,517:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:41:08,542:INFO:Calculating mean and std
2024-03-03 08:41:08,542:INFO:Creating metrics dataframe
2024-03-03 08:41:08,547:INFO:Uploading results into container
2024-03-03 08:41:08,547:INFO:Uploading model into container now
2024-03-03 08:41:08,547:INFO:_master_model_container: 7
2024-03-03 08:41:08,547:INFO:_display_container: 3
2024-03-03 08:41:08,547:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-03 08:41:08,547:INFO:create_model() successfully completed......................................
2024-03-03 08:41:08,744:INFO:SubProcess create_model() end ==================================
2024-03-03 08:41:08,744:INFO:Creating metrics dataframe
2024-03-03 08:41:08,758:INFO:Initializing CatBoost Classifier
2024-03-03 08:41:08,758:INFO:Total runtime is 3.547822415828705 minutes
2024-03-03 08:41:08,766:INFO:SubProcess create_model() called ==================================
2024-03-03 08:41:08,766:INFO:Initializing create_model()
2024-03-03 08:41:08,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F634C3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:41:08,766:INFO:Checking exceptions
2024-03-03 08:41:08,766:INFO:Importing libraries
2024-03-03 08:41:08,766:INFO:Copying training dataset
2024-03-03 08:41:08,803:INFO:Defining folds
2024-03-03 08:41:08,806:INFO:Declaring metric variables
2024-03-03 08:41:08,808:INFO:Importing untrained model
2024-03-03 08:41:08,817:INFO:CatBoost Classifier Imported successfully
2024-03-03 08:41:08,824:INFO:Starting cross validation
2024-03-03 08:41:09,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:43:16,819:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:20,080:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:20,171:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:20,417:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:20,659:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:56,009:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:43:59,808:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:44:01,433:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:44:37,497:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:44:39,817:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:44:39,834:INFO:Calculating mean and std
2024-03-03 08:44:39,842:INFO:Creating metrics dataframe
2024-03-03 08:44:39,847:INFO:Uploading results into container
2024-03-03 08:44:39,847:INFO:Uploading model into container now
2024-03-03 08:44:39,847:INFO:_master_model_container: 8
2024-03-03 08:44:39,847:INFO:_display_container: 3
2024-03-03 08:44:39,847:INFO:<catboost.core.CatBoostClassifier object at 0x0000013F663640D0>
2024-03-03 08:44:39,847:INFO:create_model() successfully completed......................................
2024-03-03 08:44:40,035:INFO:SubProcess create_model() end ==================================
2024-03-03 08:44:40,035:INFO:Creating metrics dataframe
2024-03-03 08:44:40,047:INFO:Initializing Light Gradient Boosting Machine
2024-03-03 08:44:40,047:INFO:Total runtime is 7.069306759039561 minutes
2024-03-03 08:44:40,047:INFO:SubProcess create_model() called ==================================
2024-03-03 08:44:40,047:INFO:Initializing create_model()
2024-03-03 08:44:40,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F634C3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:44:40,047:INFO:Checking exceptions
2024-03-03 08:44:40,047:INFO:Importing libraries
2024-03-03 08:44:40,047:INFO:Copying training dataset
2024-03-03 08:44:40,076:INFO:Defining folds
2024-03-03 08:44:40,076:INFO:Declaring metric variables
2024-03-03 08:44:40,076:INFO:Importing untrained model
2024-03-03 08:44:40,084:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-03 08:44:40,096:INFO:Starting cross validation
2024-03-03 08:44:40,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:46:17,813:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:17,937:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:18,196:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:18,336:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:19,907:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:20,439:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:21,071:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:21,413:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:41,897:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:42,390:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:46:42,424:INFO:Calculating mean and std
2024-03-03 08:46:42,426:INFO:Creating metrics dataframe
2024-03-03 08:46:42,434:INFO:Uploading results into container
2024-03-03 08:46:42,434:INFO:Uploading model into container now
2024-03-03 08:46:42,434:INFO:_master_model_container: 9
2024-03-03 08:46:42,434:INFO:_display_container: 3
2024-03-03 08:46:42,439:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-03 08:46:42,439:INFO:create_model() successfully completed......................................
2024-03-03 08:46:42,651:INFO:SubProcess create_model() end ==================================
2024-03-03 08:46:42,651:INFO:Creating metrics dataframe
2024-03-03 08:46:42,664:INFO:Initializing Gradient Boosting Classifier
2024-03-03 08:46:42,664:INFO:Total runtime is 9.112923785050711 minutes
2024-03-03 08:46:42,666:INFO:SubProcess create_model() called ==================================
2024-03-03 08:46:42,666:INFO:Initializing create_model()
2024-03-03 08:46:42,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F634C3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:46:42,666:INFO:Checking exceptions
2024-03-03 08:46:42,666:INFO:Importing libraries
2024-03-03 08:46:42,666:INFO:Copying training dataset
2024-03-03 08:46:42,694:INFO:Defining folds
2024-03-03 08:46:42,694:INFO:Declaring metric variables
2024-03-03 08:46:42,701:INFO:Importing untrained model
2024-03-03 08:46:42,707:INFO:Gradient Boosting Classifier Imported successfully
2024-03-03 08:46:42,716:INFO:Starting cross validation
2024-03-03 08:46:42,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:48:39,378:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:48:39,616:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:48:41,554:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:48:43,813:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:17,520:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:23,180:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:23,386:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:23,909:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:51,997:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:52,526:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:49:52,542:INFO:Calculating mean and std
2024-03-03 08:49:52,544:INFO:Creating metrics dataframe
2024-03-03 08:49:52,546:INFO:Uploading results into container
2024-03-03 08:49:52,548:INFO:Uploading model into container now
2024-03-03 08:49:52,548:INFO:_master_model_container: 10
2024-03-03 08:49:52,548:INFO:_display_container: 3
2024-03-03 08:49:52,548:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:49:52,548:INFO:create_model() successfully completed......................................
2024-03-03 08:49:52,706:INFO:SubProcess create_model() end ==================================
2024-03-03 08:49:52,706:INFO:Creating metrics dataframe
2024-03-03 08:49:52,725:INFO:Initializing create_model()
2024-03-03 08:49:52,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F60EFE610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:49:52,725:INFO:Checking exceptions
2024-03-03 08:49:52,725:INFO:Importing libraries
2024-03-03 08:49:52,725:INFO:Copying training dataset
2024-03-03 08:49:52,745:INFO:Defining folds
2024-03-03 08:49:52,745:INFO:Declaring metric variables
2024-03-03 08:49:52,745:INFO:Importing untrained model
2024-03-03 08:49:52,745:INFO:Declaring custom model
2024-03-03 08:49:52,745:INFO:Gradient Boosting Classifier Imported successfully
2024-03-03 08:49:52,855:INFO:Cross validation set to False
2024-03-03 08:49:52,855:INFO:Fitting Model
2024-03-03 08:50:01,913:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-03-03 08:50:01,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012589 seconds.
2024-03-03 08:50:01,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-03 08:50:01,925:INFO:[LightGBM] [Info] Total Bins 35658
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Number of data points in the train set: 12222, number of used features: 149
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -2.513288
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -2.764602
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -1.762730
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -3.424541
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -3.627168
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -1.318753
2024-03-03 08:50:01,933:INFO:[LightGBM] [Info] Start training from score -1.027788
2024-03-03 08:50:28,318:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:50:28,318:INFO:create_model() successfully completed......................................
2024-03-03 08:50:28,618:INFO:_master_model_container: 10
2024-03-03 08:50:28,618:INFO:_display_container: 3
2024-03-03 08:50:28,620:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 08:50:28,620:INFO:compare_models() successfully completed......................................
2024-03-03 08:53:33,328:INFO:PyCaret ClassificationExperiment
2024-03-03 08:53:33,328:INFO:Logging name: clf-default-name
2024-03-03 08:53:33,328:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:53:33,328:INFO:version 3.3.0
2024-03-03 08:53:33,328:INFO:Initializing setup()
2024-03-03 08:53:33,328:INFO:self.USI: e71e
2024-03-03 08:53:33,328:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:53:33,328:INFO:Checking environment
2024-03-03 08:53:33,328:INFO:python_version: 3.11.5
2024-03-03 08:53:33,328:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:53:33,328:INFO:machine: AMD64
2024-03-03 08:53:33,328:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:53:33,328:INFO:Memory: svmem(total=8327905280, available=1776467968, percent=78.7, used=6551437312, free=1776467968)
2024-03-03 08:53:33,328:INFO:Physical Core: 4
2024-03-03 08:53:33,328:INFO:Logical Core: 8
2024-03-03 08:53:33,328:INFO:Checking libraries
2024-03-03 08:53:33,328:INFO:System:
2024-03-03 08:53:33,328:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:53:33,328:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:53:33,328:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:53:33,328:INFO:PyCaret required dependencies:
2024-03-03 08:53:33,328:INFO:                 pip: 23.2.1
2024-03-03 08:53:33,328:INFO:          setuptools: 68.0.0
2024-03-03 08:53:33,328:INFO:             pycaret: 3.3.0
2024-03-03 08:53:33,328:INFO:             IPython: 8.15.0
2024-03-03 08:53:33,328:INFO:          ipywidgets: 8.0.4
2024-03-03 08:53:33,328:INFO:                tqdm: 4.65.0
2024-03-03 08:53:33,328:INFO:               numpy: 1.24.3
2024-03-03 08:53:33,328:INFO:              pandas: 2.0.3
2024-03-03 08:53:33,328:INFO:              jinja2: 3.1.2
2024-03-03 08:53:33,328:INFO:               scipy: 1.11.1
2024-03-03 08:53:33,328:INFO:              joblib: 1.2.0
2024-03-03 08:53:33,328:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:53:33,328:INFO:                pyod: 1.1.3
2024-03-03 08:53:33,328:INFO:            imblearn: 0.12.0
2024-03-03 08:53:33,328:INFO:   category_encoders: 2.6.3
2024-03-03 08:53:33,328:INFO:            lightgbm: 4.3.0
2024-03-03 08:53:33,328:INFO:               numba: 0.57.1
2024-03-03 08:53:33,328:INFO:            requests: 2.31.0
2024-03-03 08:53:33,328:INFO:          matplotlib: 3.7.2
2024-03-03 08:53:33,328:INFO:          scikitplot: 0.3.7
2024-03-03 08:53:33,328:INFO:         yellowbrick: 1.5
2024-03-03 08:53:33,328:INFO:              plotly: 5.19.0
2024-03-03 08:53:33,328:INFO:    plotly-resampler: Not installed
2024-03-03 08:53:33,328:INFO:             kaleido: 0.2.1
2024-03-03 08:53:33,328:INFO:           schemdraw: 0.15
2024-03-03 08:53:33,328:INFO:         statsmodels: 0.14.0
2024-03-03 08:53:33,328:INFO:              sktime: 0.26.1
2024-03-03 08:53:33,328:INFO:               tbats: 1.1.3
2024-03-03 08:53:33,328:INFO:            pmdarima: 2.0.4
2024-03-03 08:53:33,328:INFO:              psutil: 5.9.0
2024-03-03 08:53:33,328:INFO:          markupsafe: 2.1.1
2024-03-03 08:53:33,328:INFO:             pickle5: Not installed
2024-03-03 08:53:33,328:INFO:         cloudpickle: 2.2.1
2024-03-03 08:53:33,328:INFO:         deprecation: 2.1.0
2024-03-03 08:53:33,328:INFO:              xxhash: 2.0.2
2024-03-03 08:53:33,328:INFO:           wurlitzer: Not installed
2024-03-03 08:53:33,328:INFO:PyCaret optional dependencies:
2024-03-03 08:53:33,328:INFO:                shap: 0.44.1
2024-03-03 08:53:33,328:INFO:           interpret: Not installed
2024-03-03 08:53:33,328:INFO:                umap: Not installed
2024-03-03 08:53:33,328:INFO:     ydata_profiling: Not installed
2024-03-03 08:53:33,328:INFO:  explainerdashboard: Not installed
2024-03-03 08:53:33,328:INFO:             autoviz: Not installed
2024-03-03 08:53:33,328:INFO:           fairlearn: Not installed
2024-03-03 08:53:33,328:INFO:          deepchecks: Not installed
2024-03-03 08:53:33,328:INFO:             xgboost: 2.0.3
2024-03-03 08:53:33,328:INFO:            catboost: 1.2.2
2024-03-03 08:53:33,328:INFO:              kmodes: Not installed
2024-03-03 08:53:33,328:INFO:             mlxtend: Not installed
2024-03-03 08:53:33,328:INFO:       statsforecast: Not installed
2024-03-03 08:53:33,328:INFO:        tune_sklearn: Not installed
2024-03-03 08:53:33,328:INFO:                 ray: Not installed
2024-03-03 08:53:33,328:INFO:            hyperopt: Not installed
2024-03-03 08:53:33,328:INFO:              optuna: 3.5.0
2024-03-03 08:53:33,328:INFO:               skopt: Not installed
2024-03-03 08:53:33,328:INFO:              mlflow: Not installed
2024-03-03 08:53:33,328:INFO:              gradio: Not installed
2024-03-03 08:53:33,328:INFO:             fastapi: Not installed
2024-03-03 08:53:33,328:INFO:             uvicorn: Not installed
2024-03-03 08:53:33,328:INFO:              m2cgen: Not installed
2024-03-03 08:53:33,328:INFO:           evidently: Not installed
2024-03-03 08:53:33,328:INFO:               fugue: Not installed
2024-03-03 08:53:33,328:INFO:           streamlit: Not installed
2024-03-03 08:53:33,328:INFO:             prophet: Not installed
2024-03-03 08:53:33,328:INFO:None
2024-03-03 08:53:33,328:INFO:Set up data.
2024-03-03 08:53:33,376:INFO:Set up folding strategy.
2024-03-03 08:53:33,376:INFO:Set up train/test split.
2024-03-03 08:53:33,398:INFO:Set up index.
2024-03-03 08:53:33,398:INFO:Assigning column types.
2024-03-03 08:53:33,418:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:53:33,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,488:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,488:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,556:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,556:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,556:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:53:33,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,627:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,627:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:53:33,705:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,705:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,705:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:53:33,778:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,778:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,848:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:33,856:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:33,856:INFO:Preparing preprocessing pipeline...
2024-03-03 08:53:33,864:INFO:Set up simple imputation.
2024-03-03 08:53:33,864:INFO:Set up polynomial features.
2024-03-03 08:53:33,864:INFO:Set up removing multicollinearity.
2024-03-03 08:53:33,864:INFO:Set up removing outliers.
2024-03-03 08:53:34,093:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:53:34,098:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:53:34,098:INFO:Creating final display dataframe.
2024-03-03 08:53:34,698:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape      (17736, 151)
5   Transformed train set shape      (12222, 151)
6    Transformed test set shape       (5514, 151)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              e71e
2024-03-03 08:53:34,783:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:34,783:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:34,856:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:53:34,864:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:53:34,864:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:53:34,865:INFO:setup() successfully completed in 1.77s...............
2024-03-03 08:55:15,051:INFO:PyCaret ClassificationExperiment
2024-03-03 08:55:15,051:INFO:Logging name: clf-default-name
2024-03-03 08:55:15,051:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:55:15,051:INFO:version 3.3.0
2024-03-03 08:55:15,051:INFO:Initializing setup()
2024-03-03 08:55:15,051:INFO:self.USI: 0578
2024-03-03 08:55:15,051:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:55:15,051:INFO:Checking environment
2024-03-03 08:55:15,051:INFO:python_version: 3.11.5
2024-03-03 08:55:15,052:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:55:15,052:INFO:machine: AMD64
2024-03-03 08:55:15,052:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:55:15,052:INFO:Memory: svmem(total=8327905280, available=2777251840, percent=66.7, used=5550653440, free=2777251840)
2024-03-03 08:55:15,052:INFO:Physical Core: 4
2024-03-03 08:55:15,052:INFO:Logical Core: 8
2024-03-03 08:55:15,052:INFO:Checking libraries
2024-03-03 08:55:15,052:INFO:System:
2024-03-03 08:55:15,053:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:55:15,053:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:55:15,053:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:55:15,053:INFO:PyCaret required dependencies:
2024-03-03 08:55:15,053:INFO:                 pip: 23.2.1
2024-03-03 08:55:15,053:INFO:          setuptools: 68.0.0
2024-03-03 08:55:15,053:INFO:             pycaret: 3.3.0
2024-03-03 08:55:15,053:INFO:             IPython: 8.15.0
2024-03-03 08:55:15,053:INFO:          ipywidgets: 8.0.4
2024-03-03 08:55:15,054:INFO:                tqdm: 4.65.0
2024-03-03 08:55:15,054:INFO:               numpy: 1.24.3
2024-03-03 08:55:15,054:INFO:              pandas: 2.0.3
2024-03-03 08:55:15,054:INFO:              jinja2: 3.1.2
2024-03-03 08:55:15,055:INFO:               scipy: 1.11.1
2024-03-03 08:55:15,055:INFO:              joblib: 1.2.0
2024-03-03 08:55:15,055:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:55:15,055:INFO:                pyod: 1.1.3
2024-03-03 08:55:15,055:INFO:            imblearn: 0.12.0
2024-03-03 08:55:15,055:INFO:   category_encoders: 2.6.3
2024-03-03 08:55:15,055:INFO:            lightgbm: 4.3.0
2024-03-03 08:55:15,055:INFO:               numba: 0.57.1
2024-03-03 08:55:15,055:INFO:            requests: 2.31.0
2024-03-03 08:55:15,055:INFO:          matplotlib: 3.7.2
2024-03-03 08:55:15,055:INFO:          scikitplot: 0.3.7
2024-03-03 08:55:15,055:INFO:         yellowbrick: 1.5
2024-03-03 08:55:15,055:INFO:              plotly: 5.19.0
2024-03-03 08:55:15,055:INFO:    plotly-resampler: Not installed
2024-03-03 08:55:15,055:INFO:             kaleido: 0.2.1
2024-03-03 08:55:15,055:INFO:           schemdraw: 0.15
2024-03-03 08:55:15,055:INFO:         statsmodels: 0.14.0
2024-03-03 08:55:15,055:INFO:              sktime: 0.26.1
2024-03-03 08:55:15,055:INFO:               tbats: 1.1.3
2024-03-03 08:55:15,055:INFO:            pmdarima: 2.0.4
2024-03-03 08:55:15,055:INFO:              psutil: 5.9.0
2024-03-03 08:55:15,055:INFO:          markupsafe: 2.1.1
2024-03-03 08:55:15,055:INFO:             pickle5: Not installed
2024-03-03 08:55:15,055:INFO:         cloudpickle: 2.2.1
2024-03-03 08:55:15,055:INFO:         deprecation: 2.1.0
2024-03-03 08:55:15,055:INFO:              xxhash: 2.0.2
2024-03-03 08:55:15,055:INFO:           wurlitzer: Not installed
2024-03-03 08:55:15,055:INFO:PyCaret optional dependencies:
2024-03-03 08:55:15,055:INFO:                shap: 0.44.1
2024-03-03 08:55:15,055:INFO:           interpret: Not installed
2024-03-03 08:55:15,055:INFO:                umap: Not installed
2024-03-03 08:55:15,055:INFO:     ydata_profiling: Not installed
2024-03-03 08:55:15,055:INFO:  explainerdashboard: Not installed
2024-03-03 08:55:15,055:INFO:             autoviz: Not installed
2024-03-03 08:55:15,056:INFO:           fairlearn: Not installed
2024-03-03 08:55:15,057:INFO:          deepchecks: Not installed
2024-03-03 08:55:15,057:INFO:             xgboost: 2.0.3
2024-03-03 08:55:15,057:INFO:            catboost: 1.2.2
2024-03-03 08:55:15,057:INFO:              kmodes: Not installed
2024-03-03 08:55:15,057:INFO:             mlxtend: Not installed
2024-03-03 08:55:15,057:INFO:       statsforecast: Not installed
2024-03-03 08:55:15,057:INFO:        tune_sklearn: Not installed
2024-03-03 08:55:15,057:INFO:                 ray: Not installed
2024-03-03 08:55:15,057:INFO:            hyperopt: Not installed
2024-03-03 08:55:15,057:INFO:              optuna: 3.5.0
2024-03-03 08:55:15,058:INFO:               skopt: Not installed
2024-03-03 08:55:15,058:INFO:              mlflow: Not installed
2024-03-03 08:55:15,058:INFO:              gradio: Not installed
2024-03-03 08:55:15,058:INFO:             fastapi: Not installed
2024-03-03 08:55:15,058:INFO:             uvicorn: Not installed
2024-03-03 08:55:15,058:INFO:              m2cgen: Not installed
2024-03-03 08:55:15,058:INFO:           evidently: Not installed
2024-03-03 08:55:15,058:INFO:               fugue: Not installed
2024-03-03 08:55:15,058:INFO:           streamlit: Not installed
2024-03-03 08:55:15,058:INFO:             prophet: Not installed
2024-03-03 08:55:15,058:INFO:None
2024-03-03 08:55:15,058:INFO:Set up data.
2024-03-03 08:55:15,086:INFO:Set up folding strategy.
2024-03-03 08:55:15,086:INFO:Set up train/test split.
2024-03-03 08:55:15,105:INFO:Set up index.
2024-03-03 08:55:15,106:INFO:Assigning column types.
2024-03-03 08:55:15,123:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:55:15,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,169:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,200:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,203:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,255:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,286:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,288:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,289:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:55:15,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,366:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,369:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:15,454:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,457:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,458:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:55:15,543:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,547:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,631:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,635:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:15,637:INFO:Preparing preprocessing pipeline...
2024-03-03 08:55:15,640:INFO:Set up simple imputation.
2024-03-03 08:55:15,640:INFO:Set up polynomial features.
2024-03-03 08:55:15,640:INFO:Set up removing multicollinearity.
2024-03-03 08:55:15,640:INFO:Set up removing outliers.
2024-03-03 08:55:15,640:INFO:Set up feature selection.
2024-03-03 08:55:15,722:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:15,725:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:22,036:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:55:22,058:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=13,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-03-03 08:55:22,058:INFO:Creating final display dataframe.
2024-03-03 08:55:23,511:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 14)
5   Transformed train set shape       (12222, 14)
6    Transformed test set shape        (5514, 14)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18            Feature selection              True
19     Feature selection method           classic
20  Feature selection estimator          lightgbm
21  Number of features selected               0.5
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              0578
2024-03-03 08:55:23,627:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:23,631:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:23,718:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:23,721:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:23,722:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:55:23,723:INFO:setup() successfully completed in 8.8s...............
2024-03-03 08:55:38,316:INFO:PyCaret ClassificationExperiment
2024-03-03 08:55:38,316:INFO:Logging name: clf-default-name
2024-03-03 08:55:38,317:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:55:38,317:INFO:version 3.3.0
2024-03-03 08:55:38,317:INFO:Initializing setup()
2024-03-03 08:55:38,317:INFO:self.USI: 1b73
2024-03-03 08:55:38,317:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:55:38,317:INFO:Checking environment
2024-03-03 08:55:38,317:INFO:python_version: 3.11.5
2024-03-03 08:55:38,317:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:55:38,317:INFO:machine: AMD64
2024-03-03 08:55:38,317:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:55:38,317:INFO:Memory: svmem(total=8327905280, available=2801741824, percent=66.4, used=5526163456, free=2801741824)
2024-03-03 08:55:38,317:INFO:Physical Core: 4
2024-03-03 08:55:38,317:INFO:Logical Core: 8
2024-03-03 08:55:38,317:INFO:Checking libraries
2024-03-03 08:55:38,317:INFO:System:
2024-03-03 08:55:38,317:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:55:38,317:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:55:38,318:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:55:38,318:INFO:PyCaret required dependencies:
2024-03-03 08:55:38,318:INFO:                 pip: 23.2.1
2024-03-03 08:55:38,318:INFO:          setuptools: 68.0.0
2024-03-03 08:55:38,318:INFO:             pycaret: 3.3.0
2024-03-03 08:55:38,318:INFO:             IPython: 8.15.0
2024-03-03 08:55:38,318:INFO:          ipywidgets: 8.0.4
2024-03-03 08:55:38,318:INFO:                tqdm: 4.65.0
2024-03-03 08:55:38,318:INFO:               numpy: 1.24.3
2024-03-03 08:55:38,318:INFO:              pandas: 2.0.3
2024-03-03 08:55:38,318:INFO:              jinja2: 3.1.2
2024-03-03 08:55:38,318:INFO:               scipy: 1.11.1
2024-03-03 08:55:38,318:INFO:              joblib: 1.2.0
2024-03-03 08:55:38,318:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:55:38,318:INFO:                pyod: 1.1.3
2024-03-03 08:55:38,318:INFO:            imblearn: 0.12.0
2024-03-03 08:55:38,318:INFO:   category_encoders: 2.6.3
2024-03-03 08:55:38,318:INFO:            lightgbm: 4.3.0
2024-03-03 08:55:38,318:INFO:               numba: 0.57.1
2024-03-03 08:55:38,319:INFO:            requests: 2.31.0
2024-03-03 08:55:38,319:INFO:          matplotlib: 3.7.2
2024-03-03 08:55:38,319:INFO:          scikitplot: 0.3.7
2024-03-03 08:55:38,319:INFO:         yellowbrick: 1.5
2024-03-03 08:55:38,319:INFO:              plotly: 5.19.0
2024-03-03 08:55:38,319:INFO:    plotly-resampler: Not installed
2024-03-03 08:55:38,319:INFO:             kaleido: 0.2.1
2024-03-03 08:55:38,319:INFO:           schemdraw: 0.15
2024-03-03 08:55:38,319:INFO:         statsmodels: 0.14.0
2024-03-03 08:55:38,319:INFO:              sktime: 0.26.1
2024-03-03 08:55:38,319:INFO:               tbats: 1.1.3
2024-03-03 08:55:38,319:INFO:            pmdarima: 2.0.4
2024-03-03 08:55:38,319:INFO:              psutil: 5.9.0
2024-03-03 08:55:38,319:INFO:          markupsafe: 2.1.1
2024-03-03 08:55:38,319:INFO:             pickle5: Not installed
2024-03-03 08:55:38,319:INFO:         cloudpickle: 2.2.1
2024-03-03 08:55:38,319:INFO:         deprecation: 2.1.0
2024-03-03 08:55:38,319:INFO:              xxhash: 2.0.2
2024-03-03 08:55:38,319:INFO:           wurlitzer: Not installed
2024-03-03 08:55:38,320:INFO:PyCaret optional dependencies:
2024-03-03 08:55:38,320:INFO:                shap: 0.44.1
2024-03-03 08:55:38,320:INFO:           interpret: Not installed
2024-03-03 08:55:38,320:INFO:                umap: Not installed
2024-03-03 08:55:38,320:INFO:     ydata_profiling: Not installed
2024-03-03 08:55:38,320:INFO:  explainerdashboard: Not installed
2024-03-03 08:55:38,320:INFO:             autoviz: Not installed
2024-03-03 08:55:38,320:INFO:           fairlearn: Not installed
2024-03-03 08:55:38,320:INFO:          deepchecks: Not installed
2024-03-03 08:55:38,320:INFO:             xgboost: 2.0.3
2024-03-03 08:55:38,320:INFO:            catboost: 1.2.2
2024-03-03 08:55:38,320:INFO:              kmodes: Not installed
2024-03-03 08:55:38,320:INFO:             mlxtend: Not installed
2024-03-03 08:55:38,320:INFO:       statsforecast: Not installed
2024-03-03 08:55:38,320:INFO:        tune_sklearn: Not installed
2024-03-03 08:55:38,320:INFO:                 ray: Not installed
2024-03-03 08:55:38,320:INFO:            hyperopt: Not installed
2024-03-03 08:55:38,320:INFO:              optuna: 3.5.0
2024-03-03 08:55:38,321:INFO:               skopt: Not installed
2024-03-03 08:55:38,321:INFO:              mlflow: Not installed
2024-03-03 08:55:38,321:INFO:              gradio: Not installed
2024-03-03 08:55:38,321:INFO:             fastapi: Not installed
2024-03-03 08:55:38,321:INFO:             uvicorn: Not installed
2024-03-03 08:55:38,321:INFO:              m2cgen: Not installed
2024-03-03 08:55:38,321:INFO:           evidently: Not installed
2024-03-03 08:55:38,321:INFO:               fugue: Not installed
2024-03-03 08:55:38,321:INFO:           streamlit: Not installed
2024-03-03 08:55:38,321:INFO:             prophet: Not installed
2024-03-03 08:55:38,321:INFO:None
2024-03-03 08:55:38,321:INFO:Set up data.
2024-03-03 08:55:38,352:INFO:Set up folding strategy.
2024-03-03 08:55:38,352:INFO:Set up train/test split.
2024-03-03 08:55:38,377:INFO:Set up index.
2024-03-03 08:55:38,378:INFO:Assigning column types.
2024-03-03 08:55:38,395:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:55:38,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,476:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,479:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,555:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,559:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,560:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:55:38,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,635:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,638:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:55:38,715:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,718:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,718:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:55:38,797:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,799:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,876:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,879:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:38,881:INFO:Preparing preprocessing pipeline...
2024-03-03 08:55:38,883:INFO:Set up simple imputation.
2024-03-03 08:55:38,883:INFO:Set up polynomial features.
2024-03-03 08:55:38,883:INFO:Set up removing multicollinearity.
2024-03-03 08:55:38,884:INFO:Set up removing outliers.
2024-03-03 08:55:38,884:INFO:Set up feature selection.
2024-03-03 08:55:38,956:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:38,964:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:45,232:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:55:45,252:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=21,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-03-03 08:55:45,252:INFO:Creating final display dataframe.
2024-03-03 08:55:46,779:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 22)
5   Transformed train set shape       (12222, 22)
6    Transformed test set shape        (5514, 22)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18            Feature selection              True
19     Feature selection method           classic
20  Feature selection estimator          lightgbm
21  Number of features selected               0.8
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              1b73
2024-03-03 08:55:46,883:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:46,886:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:46,967:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:55:46,970:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:55:46,971:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:55:46,972:INFO:setup() successfully completed in 8.8s...............
2024-03-03 08:56:51,938:INFO:PyCaret ClassificationExperiment
2024-03-03 08:56:51,938:INFO:Logging name: clf-default-name
2024-03-03 08:56:51,938:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:56:51,939:INFO:version 3.3.0
2024-03-03 08:56:51,939:INFO:Initializing setup()
2024-03-03 08:56:51,939:INFO:self.USI: 0477
2024-03-03 08:56:51,939:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:56:51,939:INFO:Checking environment
2024-03-03 08:56:51,939:INFO:python_version: 3.11.5
2024-03-03 08:56:51,939:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:56:51,939:INFO:machine: AMD64
2024-03-03 08:56:51,939:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:56:51,939:INFO:Memory: svmem(total=8327905280, available=2771255296, percent=66.7, used=5556649984, free=2771255296)
2024-03-03 08:56:51,939:INFO:Physical Core: 4
2024-03-03 08:56:51,939:INFO:Logical Core: 8
2024-03-03 08:56:51,940:INFO:Checking libraries
2024-03-03 08:56:51,941:INFO:System:
2024-03-03 08:56:51,941:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:56:51,941:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:56:51,941:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:56:51,941:INFO:PyCaret required dependencies:
2024-03-03 08:56:51,941:INFO:                 pip: 23.2.1
2024-03-03 08:56:51,941:INFO:          setuptools: 68.0.0
2024-03-03 08:56:51,941:INFO:             pycaret: 3.3.0
2024-03-03 08:56:51,941:INFO:             IPython: 8.15.0
2024-03-03 08:56:51,941:INFO:          ipywidgets: 8.0.4
2024-03-03 08:56:51,941:INFO:                tqdm: 4.65.0
2024-03-03 08:56:51,941:INFO:               numpy: 1.24.3
2024-03-03 08:56:51,941:INFO:              pandas: 2.0.3
2024-03-03 08:56:51,941:INFO:              jinja2: 3.1.2
2024-03-03 08:56:51,941:INFO:               scipy: 1.11.1
2024-03-03 08:56:51,941:INFO:              joblib: 1.2.0
2024-03-03 08:56:51,941:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:56:51,941:INFO:                pyod: 1.1.3
2024-03-03 08:56:51,941:INFO:            imblearn: 0.12.0
2024-03-03 08:56:51,941:INFO:   category_encoders: 2.6.3
2024-03-03 08:56:51,941:INFO:            lightgbm: 4.3.0
2024-03-03 08:56:51,941:INFO:               numba: 0.57.1
2024-03-03 08:56:51,941:INFO:            requests: 2.31.0
2024-03-03 08:56:51,941:INFO:          matplotlib: 3.7.2
2024-03-03 08:56:51,941:INFO:          scikitplot: 0.3.7
2024-03-03 08:56:51,941:INFO:         yellowbrick: 1.5
2024-03-03 08:56:51,941:INFO:              plotly: 5.19.0
2024-03-03 08:56:51,941:INFO:    plotly-resampler: Not installed
2024-03-03 08:56:51,941:INFO:             kaleido: 0.2.1
2024-03-03 08:56:51,941:INFO:           schemdraw: 0.15
2024-03-03 08:56:51,941:INFO:         statsmodels: 0.14.0
2024-03-03 08:56:51,941:INFO:              sktime: 0.26.1
2024-03-03 08:56:51,941:INFO:               tbats: 1.1.3
2024-03-03 08:56:51,941:INFO:            pmdarima: 2.0.4
2024-03-03 08:56:51,941:INFO:              psutil: 5.9.0
2024-03-03 08:56:51,941:INFO:          markupsafe: 2.1.1
2024-03-03 08:56:51,941:INFO:             pickle5: Not installed
2024-03-03 08:56:51,941:INFO:         cloudpickle: 2.2.1
2024-03-03 08:56:51,941:INFO:         deprecation: 2.1.0
2024-03-03 08:56:51,941:INFO:              xxhash: 2.0.2
2024-03-03 08:56:51,941:INFO:           wurlitzer: Not installed
2024-03-03 08:56:51,941:INFO:PyCaret optional dependencies:
2024-03-03 08:56:51,941:INFO:                shap: 0.44.1
2024-03-03 08:56:51,941:INFO:           interpret: Not installed
2024-03-03 08:56:51,941:INFO:                umap: Not installed
2024-03-03 08:56:51,941:INFO:     ydata_profiling: Not installed
2024-03-03 08:56:51,941:INFO:  explainerdashboard: Not installed
2024-03-03 08:56:51,941:INFO:             autoviz: Not installed
2024-03-03 08:56:51,941:INFO:           fairlearn: Not installed
2024-03-03 08:56:51,941:INFO:          deepchecks: Not installed
2024-03-03 08:56:51,941:INFO:             xgboost: 2.0.3
2024-03-03 08:56:51,941:INFO:            catboost: 1.2.2
2024-03-03 08:56:51,941:INFO:              kmodes: Not installed
2024-03-03 08:56:51,941:INFO:             mlxtend: Not installed
2024-03-03 08:56:51,941:INFO:       statsforecast: Not installed
2024-03-03 08:56:51,941:INFO:        tune_sklearn: Not installed
2024-03-03 08:56:51,941:INFO:                 ray: Not installed
2024-03-03 08:56:51,941:INFO:            hyperopt: Not installed
2024-03-03 08:56:51,941:INFO:              optuna: 3.5.0
2024-03-03 08:56:51,941:INFO:               skopt: Not installed
2024-03-03 08:56:51,941:INFO:              mlflow: Not installed
2024-03-03 08:56:51,941:INFO:              gradio: Not installed
2024-03-03 08:56:51,941:INFO:             fastapi: Not installed
2024-03-03 08:56:51,941:INFO:             uvicorn: Not installed
2024-03-03 08:56:51,941:INFO:              m2cgen: Not installed
2024-03-03 08:56:51,941:INFO:           evidently: Not installed
2024-03-03 08:56:51,941:INFO:               fugue: Not installed
2024-03-03 08:56:51,941:INFO:           streamlit: Not installed
2024-03-03 08:56:51,941:INFO:             prophet: Not installed
2024-03-03 08:56:51,941:INFO:None
2024-03-03 08:56:51,941:INFO:Set up data.
2024-03-03 08:56:51,965:INFO:Set up folding strategy.
2024-03-03 08:56:51,966:INFO:Set up train/test split.
2024-03-03 08:56:51,987:INFO:Set up index.
2024-03-03 08:56:51,988:INFO:Assigning column types.
2024-03-03 08:56:52,006:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:56:52,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,088:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,091:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,171:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,174:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,175:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:56:52,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,257:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,260:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:56:52,341:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,341:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,341:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:56:52,430:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,434:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,520:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:52,525:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:52,526:INFO:Preparing preprocessing pipeline...
2024-03-03 08:56:52,529:INFO:Set up simple imputation.
2024-03-03 08:56:52,529:INFO:Set up polynomial features.
2024-03-03 08:56:52,529:INFO:Set up removing multicollinearity.
2024-03-03 08:56:52,530:INFO:Set up removing outliers.
2024-03-03 08:56:52,706:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:56:52,714:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:56:52,714:INFO:Creating final display dataframe.
2024-03-03 08:56:53,136:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape      (17736, 151)
5   Transformed train set shape      (12222, 151)
6    Transformed test set shape       (5514, 151)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              0477
2024-03-03 08:56:53,235:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:53,241:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:53,333:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:56:53,336:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:56:53,338:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:56:53,338:INFO:setup() successfully completed in 1.54s...............
2024-03-03 08:58:00,793:INFO:PyCaret ClassificationExperiment
2024-03-03 08:58:00,793:INFO:Logging name: clf-default-name
2024-03-03 08:58:00,793:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:58:00,793:INFO:version 3.3.0
2024-03-03 08:58:00,793:INFO:Initializing setup()
2024-03-03 08:58:00,793:INFO:self.USI: e34d
2024-03-03 08:58:00,793:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:58:00,793:INFO:Checking environment
2024-03-03 08:58:00,794:INFO:python_version: 3.11.5
2024-03-03 08:58:00,794:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:58:00,794:INFO:machine: AMD64
2024-03-03 08:58:00,794:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:58:00,794:INFO:Memory: svmem(total=8327905280, available=2779529216, percent=66.6, used=5548376064, free=2779529216)
2024-03-03 08:58:00,794:INFO:Physical Core: 4
2024-03-03 08:58:00,794:INFO:Logical Core: 8
2024-03-03 08:58:00,794:INFO:Checking libraries
2024-03-03 08:58:00,794:INFO:System:
2024-03-03 08:58:00,794:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:58:00,794:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:58:00,794:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:58:00,794:INFO:PyCaret required dependencies:
2024-03-03 08:58:00,794:INFO:                 pip: 23.2.1
2024-03-03 08:58:00,794:INFO:          setuptools: 68.0.0
2024-03-03 08:58:00,794:INFO:             pycaret: 3.3.0
2024-03-03 08:58:00,794:INFO:             IPython: 8.15.0
2024-03-03 08:58:00,794:INFO:          ipywidgets: 8.0.4
2024-03-03 08:58:00,794:INFO:                tqdm: 4.65.0
2024-03-03 08:58:00,794:INFO:               numpy: 1.24.3
2024-03-03 08:58:00,795:INFO:              pandas: 2.0.3
2024-03-03 08:58:00,795:INFO:              jinja2: 3.1.2
2024-03-03 08:58:00,795:INFO:               scipy: 1.11.1
2024-03-03 08:58:00,795:INFO:              joblib: 1.2.0
2024-03-03 08:58:00,795:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:58:00,795:INFO:                pyod: 1.1.3
2024-03-03 08:58:00,795:INFO:            imblearn: 0.12.0
2024-03-03 08:58:00,795:INFO:   category_encoders: 2.6.3
2024-03-03 08:58:00,795:INFO:            lightgbm: 4.3.0
2024-03-03 08:58:00,795:INFO:               numba: 0.57.1
2024-03-03 08:58:00,795:INFO:            requests: 2.31.0
2024-03-03 08:58:00,795:INFO:          matplotlib: 3.7.2
2024-03-03 08:58:00,795:INFO:          scikitplot: 0.3.7
2024-03-03 08:58:00,796:INFO:         yellowbrick: 1.5
2024-03-03 08:58:00,796:INFO:              plotly: 5.19.0
2024-03-03 08:58:00,796:INFO:    plotly-resampler: Not installed
2024-03-03 08:58:00,796:INFO:             kaleido: 0.2.1
2024-03-03 08:58:00,796:INFO:           schemdraw: 0.15
2024-03-03 08:58:00,796:INFO:         statsmodels: 0.14.0
2024-03-03 08:58:00,796:INFO:              sktime: 0.26.1
2024-03-03 08:58:00,796:INFO:               tbats: 1.1.3
2024-03-03 08:58:00,796:INFO:            pmdarima: 2.0.4
2024-03-03 08:58:00,796:INFO:              psutil: 5.9.0
2024-03-03 08:58:00,796:INFO:          markupsafe: 2.1.1
2024-03-03 08:58:00,796:INFO:             pickle5: Not installed
2024-03-03 08:58:00,796:INFO:         cloudpickle: 2.2.1
2024-03-03 08:58:00,796:INFO:         deprecation: 2.1.0
2024-03-03 08:58:00,796:INFO:              xxhash: 2.0.2
2024-03-03 08:58:00,796:INFO:           wurlitzer: Not installed
2024-03-03 08:58:00,796:INFO:PyCaret optional dependencies:
2024-03-03 08:58:00,796:INFO:                shap: 0.44.1
2024-03-03 08:58:00,796:INFO:           interpret: Not installed
2024-03-03 08:58:00,796:INFO:                umap: Not installed
2024-03-03 08:58:00,796:INFO:     ydata_profiling: Not installed
2024-03-03 08:58:00,796:INFO:  explainerdashboard: Not installed
2024-03-03 08:58:00,796:INFO:             autoviz: Not installed
2024-03-03 08:58:00,796:INFO:           fairlearn: Not installed
2024-03-03 08:58:00,796:INFO:          deepchecks: Not installed
2024-03-03 08:58:00,796:INFO:             xgboost: 2.0.3
2024-03-03 08:58:00,797:INFO:            catboost: 1.2.2
2024-03-03 08:58:00,797:INFO:              kmodes: Not installed
2024-03-03 08:58:00,797:INFO:             mlxtend: Not installed
2024-03-03 08:58:00,797:INFO:       statsforecast: Not installed
2024-03-03 08:58:00,797:INFO:        tune_sklearn: Not installed
2024-03-03 08:58:00,797:INFO:                 ray: Not installed
2024-03-03 08:58:00,797:INFO:            hyperopt: Not installed
2024-03-03 08:58:00,797:INFO:              optuna: 3.5.0
2024-03-03 08:58:00,797:INFO:               skopt: Not installed
2024-03-03 08:58:00,798:INFO:              mlflow: Not installed
2024-03-03 08:58:00,798:INFO:              gradio: Not installed
2024-03-03 08:58:00,798:INFO:             fastapi: Not installed
2024-03-03 08:58:00,798:INFO:             uvicorn: Not installed
2024-03-03 08:58:00,798:INFO:              m2cgen: Not installed
2024-03-03 08:58:00,798:INFO:           evidently: Not installed
2024-03-03 08:58:00,798:INFO:               fugue: Not installed
2024-03-03 08:58:00,798:INFO:           streamlit: Not installed
2024-03-03 08:58:00,798:INFO:             prophet: Not installed
2024-03-03 08:58:00,798:INFO:None
2024-03-03 08:58:00,798:INFO:Set up data.
2024-03-03 08:58:00,818:INFO:Set up folding strategy.
2024-03-03 08:58:00,819:INFO:Set up train/test split.
2024-03-03 08:58:00,841:INFO:Set up index.
2024-03-03 08:58:00,842:INFO:Assigning column types.
2024-03-03 08:58:00,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:58:00,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:00,911:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:00,943:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:00,947:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:00,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:00,998:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:01,029:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:01,032:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:01,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:58:01,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:01,109:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:01,112:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:01,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:01,194:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:01,197:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:01,197:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:58:01,281:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:01,283:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:01,364:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:01,367:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:01,368:INFO:Preparing preprocessing pipeline...
2024-03-03 08:58:01,371:INFO:Set up simple imputation.
2024-03-03 08:58:01,371:INFO:Set up polynomial features.
2024-03-03 08:58:01,371:INFO:Set up removing multicollinearity.
2024-03-03 08:58:01,371:INFO:Set up removing outliers.
2024-03-03 08:58:07,547:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:58:07,550:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:58:07,550:INFO:Creating final display dataframe.
2024-03-03 08:58:10,065:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 83)
5   Transformed train set shape       (12222, 83)
6    Transformed test set shape        (5514, 83)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.8
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              e34d
2024-03-03 08:58:10,175:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:10,179:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:10,266:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:10,269:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:10,269:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:58:10,269:INFO:setup() successfully completed in 9.59s...............
2024-03-03 08:58:21,200:INFO:PyCaret ClassificationExperiment
2024-03-03 08:58:21,200:INFO:Logging name: clf-default-name
2024-03-03 08:58:21,201:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:58:21,201:INFO:version 3.3.0
2024-03-03 08:58:21,201:INFO:Initializing setup()
2024-03-03 08:58:21,201:INFO:self.USI: a4b6
2024-03-03 08:58:21,201:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:58:21,201:INFO:Checking environment
2024-03-03 08:58:21,201:INFO:python_version: 3.11.5
2024-03-03 08:58:21,201:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:58:21,201:INFO:machine: AMD64
2024-03-03 08:58:21,201:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:58:21,201:INFO:Memory: svmem(total=8327905280, available=2823069696, percent=66.1, used=5504835584, free=2823069696)
2024-03-03 08:58:21,201:INFO:Physical Core: 4
2024-03-03 08:58:21,201:INFO:Logical Core: 8
2024-03-03 08:58:21,201:INFO:Checking libraries
2024-03-03 08:58:21,201:INFO:System:
2024-03-03 08:58:21,201:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:58:21,201:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:58:21,201:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:58:21,201:INFO:PyCaret required dependencies:
2024-03-03 08:58:21,202:INFO:                 pip: 23.2.1
2024-03-03 08:58:21,202:INFO:          setuptools: 68.0.0
2024-03-03 08:58:21,202:INFO:             pycaret: 3.3.0
2024-03-03 08:58:21,202:INFO:             IPython: 8.15.0
2024-03-03 08:58:21,202:INFO:          ipywidgets: 8.0.4
2024-03-03 08:58:21,202:INFO:                tqdm: 4.65.0
2024-03-03 08:58:21,202:INFO:               numpy: 1.24.3
2024-03-03 08:58:21,202:INFO:              pandas: 2.0.3
2024-03-03 08:58:21,202:INFO:              jinja2: 3.1.2
2024-03-03 08:58:21,202:INFO:               scipy: 1.11.1
2024-03-03 08:58:21,202:INFO:              joblib: 1.2.0
2024-03-03 08:58:21,202:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:58:21,202:INFO:                pyod: 1.1.3
2024-03-03 08:58:21,202:INFO:            imblearn: 0.12.0
2024-03-03 08:58:21,202:INFO:   category_encoders: 2.6.3
2024-03-03 08:58:21,202:INFO:            lightgbm: 4.3.0
2024-03-03 08:58:21,202:INFO:               numba: 0.57.1
2024-03-03 08:58:21,202:INFO:            requests: 2.31.0
2024-03-03 08:58:21,202:INFO:          matplotlib: 3.7.2
2024-03-03 08:58:21,202:INFO:          scikitplot: 0.3.7
2024-03-03 08:58:21,202:INFO:         yellowbrick: 1.5
2024-03-03 08:58:21,202:INFO:              plotly: 5.19.0
2024-03-03 08:58:21,202:INFO:    plotly-resampler: Not installed
2024-03-03 08:58:21,203:INFO:             kaleido: 0.2.1
2024-03-03 08:58:21,203:INFO:           schemdraw: 0.15
2024-03-03 08:58:21,203:INFO:         statsmodels: 0.14.0
2024-03-03 08:58:21,203:INFO:              sktime: 0.26.1
2024-03-03 08:58:21,203:INFO:               tbats: 1.1.3
2024-03-03 08:58:21,203:INFO:            pmdarima: 2.0.4
2024-03-03 08:58:21,203:INFO:              psutil: 5.9.0
2024-03-03 08:58:21,203:INFO:          markupsafe: 2.1.1
2024-03-03 08:58:21,203:INFO:             pickle5: Not installed
2024-03-03 08:58:21,203:INFO:         cloudpickle: 2.2.1
2024-03-03 08:58:21,203:INFO:         deprecation: 2.1.0
2024-03-03 08:58:21,203:INFO:              xxhash: 2.0.2
2024-03-03 08:58:21,203:INFO:           wurlitzer: Not installed
2024-03-03 08:58:21,203:INFO:PyCaret optional dependencies:
2024-03-03 08:58:21,203:INFO:                shap: 0.44.1
2024-03-03 08:58:21,203:INFO:           interpret: Not installed
2024-03-03 08:58:21,203:INFO:                umap: Not installed
2024-03-03 08:58:21,203:INFO:     ydata_profiling: Not installed
2024-03-03 08:58:21,203:INFO:  explainerdashboard: Not installed
2024-03-03 08:58:21,203:INFO:             autoviz: Not installed
2024-03-03 08:58:21,203:INFO:           fairlearn: Not installed
2024-03-03 08:58:21,203:INFO:          deepchecks: Not installed
2024-03-03 08:58:21,203:INFO:             xgboost: 2.0.3
2024-03-03 08:58:21,203:INFO:            catboost: 1.2.2
2024-03-03 08:58:21,204:INFO:              kmodes: Not installed
2024-03-03 08:58:21,204:INFO:             mlxtend: Not installed
2024-03-03 08:58:21,204:INFO:       statsforecast: Not installed
2024-03-03 08:58:21,204:INFO:        tune_sklearn: Not installed
2024-03-03 08:58:21,204:INFO:                 ray: Not installed
2024-03-03 08:58:21,204:INFO:            hyperopt: Not installed
2024-03-03 08:58:21,204:INFO:              optuna: 3.5.0
2024-03-03 08:58:21,204:INFO:               skopt: Not installed
2024-03-03 08:58:21,204:INFO:              mlflow: Not installed
2024-03-03 08:58:21,204:INFO:              gradio: Not installed
2024-03-03 08:58:21,204:INFO:             fastapi: Not installed
2024-03-03 08:58:21,204:INFO:             uvicorn: Not installed
2024-03-03 08:58:21,204:INFO:              m2cgen: Not installed
2024-03-03 08:58:21,204:INFO:           evidently: Not installed
2024-03-03 08:58:21,205:INFO:               fugue: Not installed
2024-03-03 08:58:21,205:INFO:           streamlit: Not installed
2024-03-03 08:58:21,205:INFO:             prophet: Not installed
2024-03-03 08:58:21,206:INFO:None
2024-03-03 08:58:21,206:INFO:Set up data.
2024-03-03 08:58:21,228:INFO:Set up folding strategy.
2024-03-03 08:58:21,228:INFO:Set up train/test split.
2024-03-03 08:58:21,250:INFO:Set up index.
2024-03-03 08:58:21,250:INFO:Assigning column types.
2024-03-03 08:58:21,268:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:58:21,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,348:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,435:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,439:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,441:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:58:21,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,525:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,527:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:21,615:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,618:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,618:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:58:21,704:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,709:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,794:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:21,798:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:21,799:INFO:Preparing preprocessing pipeline...
2024-03-03 08:58:21,801:INFO:Set up simple imputation.
2024-03-03 08:58:21,803:INFO:Set up polynomial features.
2024-03-03 08:58:21,803:INFO:Set up removing multicollinearity.
2024-03-03 08:58:21,803:INFO:Set up removing outliers.
2024-03-03 08:58:28,073:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:58:28,080:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.75))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:58:28,080:INFO:Creating final display dataframe.
2024-03-03 08:58:30,770:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 61)
5   Transformed train set shape       (12222, 61)
6    Transformed test set shape        (5514, 61)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.75
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              a4b6
2024-03-03 08:58:30,946:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:30,951:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:31,109:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:31,113:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:31,113:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:58:31,114:INFO:setup() successfully completed in 10.03s...............
2024-03-03 08:58:35,812:INFO:PyCaret ClassificationExperiment
2024-03-03 08:58:35,812:INFO:Logging name: clf-default-name
2024-03-03 08:58:35,812:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-03 08:58:35,812:INFO:version 3.3.0
2024-03-03 08:58:35,813:INFO:Initializing setup()
2024-03-03 08:58:35,813:INFO:self.USI: 8936
2024-03-03 08:58:35,813:INFO:self._variable_keys: {'USI', 'idx', 'is_multiclass', 'data', 'fold_shuffle_param', '_ml_usecase', 'fold_groups_param', 'seed', 'exp_name_log', 'y_test', 'pipeline', 'exp_id', 'log_plots_param', 'X_test', 'X', 'y_train', 'logging_param', '_available_plots', 'target_param', 'fold_generator', 'y', 'fix_imbalance', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'html_param', 'n_jobs_param', 'memory'}
2024-03-03 08:58:35,813:INFO:Checking environment
2024-03-03 08:58:35,813:INFO:python_version: 3.11.5
2024-03-03 08:58:35,813:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-03 08:58:35,813:INFO:machine: AMD64
2024-03-03 08:58:35,813:INFO:platform: Windows-10-10.0.19045-SP0
2024-03-03 08:58:35,813:INFO:Memory: svmem(total=8327905280, available=2813829120, percent=66.2, used=5514076160, free=2813829120)
2024-03-03 08:58:35,813:INFO:Physical Core: 4
2024-03-03 08:58:35,813:INFO:Logical Core: 8
2024-03-03 08:58:35,813:INFO:Checking libraries
2024-03-03 08:58:35,813:INFO:System:
2024-03-03 08:58:35,813:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-03 08:58:35,813:INFO:executable: c:\Users\Janith\anaconda3\python.exe
2024-03-03 08:58:35,814:INFO:   machine: Windows-10-10.0.19045-SP0
2024-03-03 08:58:35,814:INFO:PyCaret required dependencies:
2024-03-03 08:58:35,814:INFO:                 pip: 23.2.1
2024-03-03 08:58:35,814:INFO:          setuptools: 68.0.0
2024-03-03 08:58:35,814:INFO:             pycaret: 3.3.0
2024-03-03 08:58:35,814:INFO:             IPython: 8.15.0
2024-03-03 08:58:35,814:INFO:          ipywidgets: 8.0.4
2024-03-03 08:58:35,814:INFO:                tqdm: 4.65.0
2024-03-03 08:58:35,814:INFO:               numpy: 1.24.3
2024-03-03 08:58:35,814:INFO:              pandas: 2.0.3
2024-03-03 08:58:35,814:INFO:              jinja2: 3.1.2
2024-03-03 08:58:35,814:INFO:               scipy: 1.11.1
2024-03-03 08:58:35,814:INFO:              joblib: 1.2.0
2024-03-03 08:58:35,814:INFO:             sklearn: 1.4.1.post1
2024-03-03 08:58:35,814:INFO:                pyod: 1.1.3
2024-03-03 08:58:35,814:INFO:            imblearn: 0.12.0
2024-03-03 08:58:35,814:INFO:   category_encoders: 2.6.3
2024-03-03 08:58:35,814:INFO:            lightgbm: 4.3.0
2024-03-03 08:58:35,814:INFO:               numba: 0.57.1
2024-03-03 08:58:35,814:INFO:            requests: 2.31.0
2024-03-03 08:58:35,814:INFO:          matplotlib: 3.7.2
2024-03-03 08:58:35,815:INFO:          scikitplot: 0.3.7
2024-03-03 08:58:35,815:INFO:         yellowbrick: 1.5
2024-03-03 08:58:35,815:INFO:              plotly: 5.19.0
2024-03-03 08:58:35,815:INFO:    plotly-resampler: Not installed
2024-03-03 08:58:35,815:INFO:             kaleido: 0.2.1
2024-03-03 08:58:35,815:INFO:           schemdraw: 0.15
2024-03-03 08:58:35,815:INFO:         statsmodels: 0.14.0
2024-03-03 08:58:35,815:INFO:              sktime: 0.26.1
2024-03-03 08:58:35,815:INFO:               tbats: 1.1.3
2024-03-03 08:58:35,815:INFO:            pmdarima: 2.0.4
2024-03-03 08:58:35,815:INFO:              psutil: 5.9.0
2024-03-03 08:58:35,815:INFO:          markupsafe: 2.1.1
2024-03-03 08:58:35,816:INFO:             pickle5: Not installed
2024-03-03 08:58:35,816:INFO:         cloudpickle: 2.2.1
2024-03-03 08:58:35,816:INFO:         deprecation: 2.1.0
2024-03-03 08:58:35,816:INFO:              xxhash: 2.0.2
2024-03-03 08:58:35,816:INFO:           wurlitzer: Not installed
2024-03-03 08:58:35,816:INFO:PyCaret optional dependencies:
2024-03-03 08:58:35,816:INFO:                shap: 0.44.1
2024-03-03 08:58:35,816:INFO:           interpret: Not installed
2024-03-03 08:58:35,816:INFO:                umap: Not installed
2024-03-03 08:58:35,816:INFO:     ydata_profiling: Not installed
2024-03-03 08:58:35,816:INFO:  explainerdashboard: Not installed
2024-03-03 08:58:35,816:INFO:             autoviz: Not installed
2024-03-03 08:58:35,816:INFO:           fairlearn: Not installed
2024-03-03 08:58:35,816:INFO:          deepchecks: Not installed
2024-03-03 08:58:35,816:INFO:             xgboost: 2.0.3
2024-03-03 08:58:35,816:INFO:            catboost: 1.2.2
2024-03-03 08:58:35,816:INFO:              kmodes: Not installed
2024-03-03 08:58:35,816:INFO:             mlxtend: Not installed
2024-03-03 08:58:35,816:INFO:       statsforecast: Not installed
2024-03-03 08:58:35,816:INFO:        tune_sklearn: Not installed
2024-03-03 08:58:35,816:INFO:                 ray: Not installed
2024-03-03 08:58:35,816:INFO:            hyperopt: Not installed
2024-03-03 08:58:35,816:INFO:              optuna: 3.5.0
2024-03-03 08:58:35,816:INFO:               skopt: Not installed
2024-03-03 08:58:35,816:INFO:              mlflow: Not installed
2024-03-03 08:58:35,816:INFO:              gradio: Not installed
2024-03-03 08:58:35,816:INFO:             fastapi: Not installed
2024-03-03 08:58:35,816:INFO:             uvicorn: Not installed
2024-03-03 08:58:35,816:INFO:              m2cgen: Not installed
2024-03-03 08:58:35,816:INFO:           evidently: Not installed
2024-03-03 08:58:35,816:INFO:               fugue: Not installed
2024-03-03 08:58:35,817:INFO:           streamlit: Not installed
2024-03-03 08:58:35,817:INFO:             prophet: Not installed
2024-03-03 08:58:35,817:INFO:None
2024-03-03 08:58:35,817:INFO:Set up data.
2024-03-03 08:58:35,838:INFO:Set up folding strategy.
2024-03-03 08:58:35,838:INFO:Set up train/test split.
2024-03-03 08:58:35,859:INFO:Set up index.
2024-03-03 08:58:35,860:INFO:Assigning column types.
2024-03-03 08:58:35,876:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-03 08:58:35,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:35,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:35,954:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:35,957:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-03 08:58:36,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:36,040:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:36,043:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,044:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-03 08:58:36,092:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:36,120:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:36,124:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-03 08:58:36,202:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:36,205:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,205:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-03 08:58:36,286:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:36,290:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,374:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:36,376:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:36,378:INFO:Preparing preprocessing pipeline...
2024-03-03 08:58:36,381:INFO:Set up simple imputation.
2024-03-03 08:58:36,381:INFO:Set up polynomial features.
2024-03-03 08:58:36,381:INFO:Set up removing multicollinearity.
2024-03-03 08:58:36,381:INFO:Set up removing outliers.
2024-03-03 08:58:36,593:INFO:Finished creating preprocessing pipeline.
2024-03-03 08:58:36,600:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Janith\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['X_Minimum', 'X_Maximum',
                                             'Y_Minimum', 'Y_Maximum',
                                             'Pixels_Areas', 'X_Perimeter',
                                             'Y_Perimeter', 'Sum_of_Luminosity',
                                             'Minimum_of_Luminosity',
                                             'Maximum_of_Luminosity',
                                             'Length_of_Conveyer',
                                             'TypeOfSteel_A300',
                                             'Ty...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05)))],
         verbose=False)
2024-03-03 08:58:36,600:INFO:Creating final display dataframe.
2024-03-03 08:58:37,159:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape       (18380, 28)
4        Transformed data shape       (17736, 83)
5   Transformed train set shape       (12222, 83)
6    Transformed test set shape        (5514, 83)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.8
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              8936
2024-03-03 08:58:37,264:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:37,267:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:37,381:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-03 08:58:37,383:INFO:Soft dependency imported: catboost: 1.2.2
2024-03-03 08:58:37,385:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-03-03 08:58:37,388:INFO:setup() successfully completed in 1.73s...............
2024-03-03 08:58:49,194:INFO:Initializing compare_models()
2024-03-03 08:58:49,194:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, include=['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, 'include': ['xgboost', 'rf', 'catboost', 'lightgbm', 'gbc'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-03 08:58:49,194:INFO:Checking exceptions
2024-03-03 08:58:49,212:INFO:Preparing display monitor
2024-03-03 08:58:49,261:INFO:Initializing Extreme Gradient Boosting
2024-03-03 08:58:49,278:INFO:Total runtime is 0.0002665996551513672 minutes
2024-03-03 08:58:49,285:INFO:SubProcess create_model() called ==================================
2024-03-03 08:58:49,287:INFO:Initializing create_model()
2024-03-03 08:58:49,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F60F037D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 08:58:49,287:INFO:Checking exceptions
2024-03-03 08:58:49,288:INFO:Importing libraries
2024-03-03 08:58:49,288:INFO:Copying training dataset
2024-03-03 08:58:49,364:INFO:Defining folds
2024-03-03 08:58:49,364:INFO:Declaring metric variables
2024-03-03 08:58:49,371:INFO:Importing untrained model
2024-03-03 08:58:49,376:INFO:Extreme Gradient Boosting Imported successfully
2024-03-03 08:58:49,388:INFO:Starting cross validation
2024-03-03 08:58:49,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 08:59:47,056:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:47,831:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:47,920:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:48,161:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:48,198:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:48,285:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:48,320:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 08:59:48,365:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:09,754:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:10,412:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:10,427:INFO:Calculating mean and std
2024-03-03 09:00:10,430:INFO:Creating metrics dataframe
2024-03-03 09:00:10,432:INFO:Uploading results into container
2024-03-03 09:00:10,432:INFO:Uploading model into container now
2024-03-03 09:00:10,432:INFO:_master_model_container: 1
2024-03-03 09:00:10,432:INFO:_display_container: 2
2024-03-03 09:00:10,433:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-03 09:00:10,433:INFO:create_model() successfully completed......................................
2024-03-03 09:00:10,700:INFO:SubProcess create_model() end ==================================
2024-03-03 09:00:10,700:INFO:Creating metrics dataframe
2024-03-03 09:00:10,710:INFO:Initializing Random Forest Classifier
2024-03-03 09:00:10,710:INFO:Total runtime is 1.3574770013491313 minutes
2024-03-03 09:00:10,714:INFO:SubProcess create_model() called ==================================
2024-03-03 09:00:10,715:INFO:Initializing create_model()
2024-03-03 09:00:10,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F60F037D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 09:00:10,715:INFO:Checking exceptions
2024-03-03 09:00:10,716:INFO:Importing libraries
2024-03-03 09:00:10,716:INFO:Copying training dataset
2024-03-03 09:00:10,745:INFO:Defining folds
2024-03-03 09:00:10,746:INFO:Declaring metric variables
2024-03-03 09:00:10,752:INFO:Importing untrained model
2024-03-03 09:00:10,756:INFO:Random Forest Classifier Imported successfully
2024-03-03 09:00:10,768:INFO:Starting cross validation
2024-03-03 09:00:10,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 09:00:54,345:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:57,676:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,461:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,494:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,517:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,519:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,612:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:00:58,696:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:01:12,391:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:01:12,852:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:01:12,872:INFO:Calculating mean and std
2024-03-03 09:01:12,874:INFO:Creating metrics dataframe
2024-03-03 09:01:12,877:INFO:Uploading results into container
2024-03-03 09:01:12,878:INFO:Uploading model into container now
2024-03-03 09:01:12,878:INFO:_master_model_container: 2
2024-03-03 09:01:12,878:INFO:_display_container: 2
2024-03-03 09:01:12,879:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-03-03 09:01:12,879:INFO:create_model() successfully completed......................................
2024-03-03 09:01:13,066:INFO:SubProcess create_model() end ==================================
2024-03-03 09:01:13,067:INFO:Creating metrics dataframe
2024-03-03 09:01:13,078:INFO:Initializing CatBoost Classifier
2024-03-03 09:01:13,079:INFO:Total runtime is 2.3969671169916786 minutes
2024-03-03 09:01:13,084:INFO:SubProcess create_model() called ==================================
2024-03-03 09:01:13,084:INFO:Initializing create_model()
2024-03-03 09:01:13,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F60F037D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 09:01:13,084:INFO:Checking exceptions
2024-03-03 09:01:13,084:INFO:Importing libraries
2024-03-03 09:01:13,085:INFO:Copying training dataset
2024-03-03 09:01:13,114:INFO:Defining folds
2024-03-03 09:01:13,114:INFO:Declaring metric variables
2024-03-03 09:01:13,121:INFO:Importing untrained model
2024-03-03 09:01:13,126:INFO:CatBoost Classifier Imported successfully
2024-03-03 09:01:13,137:INFO:Starting cross validation
2024-03-03 09:01:13,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 09:12:29,213:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:30,697:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:31,271:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:32,856:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:32,866:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:33,792:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:37,016:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:12:39,479:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:15:37,868:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:15:38,864:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:15:38,888:INFO:Calculating mean and std
2024-03-03 09:15:38,894:INFO:Creating metrics dataframe
2024-03-03 09:15:38,902:INFO:Uploading results into container
2024-03-03 09:15:38,903:INFO:Uploading model into container now
2024-03-03 09:15:38,904:INFO:_master_model_container: 3
2024-03-03 09:15:38,904:INFO:_display_container: 2
2024-03-03 09:15:38,904:INFO:<catboost.core.CatBoostClassifier object at 0x0000013F60E56A10>
2024-03-03 09:15:38,905:INFO:create_model() successfully completed......................................
2024-03-03 09:15:39,196:INFO:SubProcess create_model() end ==================================
2024-03-03 09:15:39,196:INFO:Creating metrics dataframe
2024-03-03 09:15:39,209:INFO:Initializing Light Gradient Boosting Machine
2024-03-03 09:15:39,209:INFO:Total runtime is 16.83246090014776 minutes
2024-03-03 09:15:39,216:INFO:SubProcess create_model() called ==================================
2024-03-03 09:15:39,217:INFO:Initializing create_model()
2024-03-03 09:15:39,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F60F037D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 09:15:39,218:INFO:Checking exceptions
2024-03-03 09:15:39,218:INFO:Importing libraries
2024-03-03 09:15:39,218:INFO:Copying training dataset
2024-03-03 09:15:39,251:INFO:Defining folds
2024-03-03 09:15:39,251:INFO:Declaring metric variables
2024-03-03 09:15:39,256:INFO:Importing untrained model
2024-03-03 09:15:39,262:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-03 09:15:39,272:INFO:Starting cross validation
2024-03-03 09:15:39,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 09:16:22,209:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:22,661:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:23,009:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:23,202:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:23,461:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:26,303:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:27,415:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:27,420:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:39,000:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:39,465:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:16:39,501:INFO:Calculating mean and std
2024-03-03 09:16:39,510:INFO:Creating metrics dataframe
2024-03-03 09:16:39,515:INFO:Uploading results into container
2024-03-03 09:16:39,518:INFO:Uploading model into container now
2024-03-03 09:16:39,519:INFO:_master_model_container: 4
2024-03-03 09:16:39,519:INFO:_display_container: 2
2024-03-03 09:16:39,519:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-03 09:16:39,519:INFO:create_model() successfully completed......................................
2024-03-03 09:16:39,751:INFO:SubProcess create_model() end ==================================
2024-03-03 09:16:39,752:INFO:Creating metrics dataframe
2024-03-03 09:16:39,768:INFO:Initializing Gradient Boosting Classifier
2024-03-03 09:16:39,768:INFO:Total runtime is 17.84177562793096 minutes
2024-03-03 09:16:39,773:INFO:SubProcess create_model() called ==================================
2024-03-03 09:16:39,774:INFO:Initializing create_model()
2024-03-03 09:16:39,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013F60F037D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 09:16:39,774:INFO:Checking exceptions
2024-03-03 09:16:39,774:INFO:Importing libraries
2024-03-03 09:16:39,774:INFO:Copying training dataset
2024-03-03 09:16:39,806:INFO:Defining folds
2024-03-03 09:16:39,806:INFO:Declaring metric variables
2024-03-03 09:16:39,811:INFO:Importing untrained model
2024-03-03 09:16:39,817:INFO:Gradient Boosting Classifier Imported successfully
2024-03-03 09:16:39,828:INFO:Starting cross validation
2024-03-03 09:16:39,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-03 09:23:00,776:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:05,615:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:06,242:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:10,442:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:10,840:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:11,218:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:12,649:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:23:13,633:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:26:40,896:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:26:45,739:WARNING:c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3767, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5877, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "c:\Users\Janith\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 5938, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n       'SigmoidOfAreas'],\n      dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-03 09:26:45,750:INFO:Calculating mean and std
2024-03-03 09:26:45,752:INFO:Creating metrics dataframe
2024-03-03 09:26:45,754:INFO:Uploading results into container
2024-03-03 09:26:45,755:INFO:Uploading model into container now
2024-03-03 09:26:45,755:INFO:_master_model_container: 5
2024-03-03 09:26:45,755:INFO:_display_container: 2
2024-03-03 09:26:45,756:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-03 09:26:45,756:INFO:create_model() successfully completed......................................
2024-03-03 09:26:45,917:INFO:SubProcess create_model() end ==================================
2024-03-03 09:26:45,917:INFO:Creating metrics dataframe
2024-03-03 09:26:45,947:INFO:Initializing create_model()
2024-03-03 09:26:45,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013F674564D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-03 09:26:45,948:INFO:Checking exceptions
2024-03-03 09:26:45,950:INFO:Importing libraries
2024-03-03 09:26:45,951:INFO:Copying training dataset
2024-03-03 09:26:45,976:INFO:Defining folds
2024-03-03 09:26:45,977:INFO:Declaring metric variables
2024-03-03 09:26:45,977:INFO:Importing untrained model
2024-03-03 09:26:45,977:INFO:Declaring custom model
2024-03-03 09:26:45,977:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-03 09:26:45,980:INFO:Cross validation set to False
2024-03-03 09:26:45,980:INFO:Fitting Model
2024-03-03 09:26:51,726:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-03-03 09:26:51,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.
2024-03-03 09:26:51,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-03-03 09:26:51,733:INFO:[LightGBM] [Info] Total Bins 19329
2024-03-03 09:26:51,735:INFO:[LightGBM] [Info] Number of data points in the train set: 12222, number of used features: 81
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -2.538865
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -2.775046
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -1.691419
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -3.424541
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -3.655251
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -1.328591
2024-03-03 09:26:51,737:INFO:[LightGBM] [Info] Start training from score -1.046485
2024-03-03 09:26:54,767:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-03 09:26:54,767:INFO:create_model() successfully completed......................................
2024-03-03 09:26:54,993:INFO:_master_model_container: 5
2024-03-03 09:26:54,993:INFO:_display_container: 2
2024-03-03 09:26:54,994:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-03 09:26:54,994:INFO:compare_models() successfully completed......................................
